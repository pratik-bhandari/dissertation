%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% OXFORD THESIS TEMPLATE

% Use this template to produce a standard thesis that meets the Oxford University requirements for DPhil submission
%
% Originally by Keith A. Gillow (gillow@maths.ox.ac.uk), 1997
% Modified by Sam Evans (sam@samuelevansresearch.org), 2007
% Modified by John McManigle (john@oxfordechoes.com), 2015
% Modified by Ulrik Lyngs (ulrik.lyngs@cs.ox.ac.uk), 2018-, for use with R Markdown
%
% Ulrik Lyngs, 25 Nov 2018: Following John McManigle, broad permissions are granted to use, modify, and distribute this software
% as specified in the MIT License included in this distribution's LICENSE file.
%
% John commented this file extensively, so read through to see how to use the various options.  Remember that in LaTeX,
% any line starting with a % is NOT executed.  Several places below, you have a choice of which line to use
% out of multiple options (eg draft vs final, for PDF vs for binding, etc.)  When you pick one, add a % to the beginning of
% the lines you don't want.


%%%%% PAGE LAYOUT
% The most common choices should be below.  You can also do other things, like replacing "a4paper" with "letterpaper", etc.

% This one formats for two-sided binding (ie left and right pages have mirror margins; blank pages inserted where needed):
%\documentclass[a4paper,twoside]{templates/ociamthesis}
% This one formats for one-sided binding (ie left margin > right margin; no extra blank pages):
%\documentclass[a4paper]{ociamthesis}
% This one formats for PDF output (ie equal margins, no extra blank pages):
%\documentclass[a4paper,nobind]{templates/ociamthesis}

% As you can see from the uncommented line below, oxforddown template uses the a4paper size, 
% and passes in the binding option from the YAML header in index.Rmd:
\documentclass[a4paper, nobind]{templates/ociamthesis}


%%%%% ADDING LATEX PACKAGES
% add hyperref package with options from YAML %
\usepackage[pdfpagelabels]{hyperref}
% handle long urls
\usepackage{xurl}
% change the default coloring of links to something sensible
\usepackage{xcolor}

\definecolor{mylinkcolor}{RGB}{0,0,139}
\definecolor{myurlcolor}{RGB}{0,0,139}
\definecolor{mycitecolor}{RGB}{0,33,71}

\hypersetup{
  hidelinks,
  colorlinks,
  linktocpage=true,
  linkcolor=mylinkcolor,
  urlcolor=myurlcolor,
  citecolor=mycitecolor
}



% add float package to allow manual control of figure positioning %
\usepackage{float}

% enable strikethrough
\usepackage[normalem]{ulem}

% use soul package for correction highlighting
\usepackage{color, soulutf8}
\definecolor{correctioncolor}{HTML}{CCCCFF}
\sethlcolor{correctioncolor}
\newcommand{\ctext}[3][RGB]{%
  \begingroup
  \definecolor{hlcolor}{#1}{#2}\sethlcolor{hlcolor}%
  \hl{#3}%
  \endgroup
}
\soulregister\ref7
\soulregister\cite7
\soulregister\citet7
\soulregister\autocite7
\soulregister\textcite7
\soulregister\pageref7

%%%%% FIXING / ADDING THINGS THAT'S SPECIAL TO R MARKDOWN'S USE OF LATEX TEMPLATES
% pandoc puts lists in 'tightlist' command when no space between bullet points in Rmd file,
% so we add this command to the template
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
 
% UL 1 Dec 2018, fix to include code in shaded environments

% User-included things with header_includes or in_header will appear here
% kableExtra packages will appear here if you use library(kableExtra)
\usepackage{booktabs}
\usepackage{longtable}
\usepackage{array}
\usepackage{multirow}
\usepackage{wrapfig}
\usepackage{float}
\usepackage{colortbl}
\usepackage{pdflscape}
\usepackage{tabu}
\usepackage{threeparttable}
\usepackage{threeparttablex}
\usepackage[normalem]{ulem}
\usepackage{makecell}
\usepackage{xcolor}


%UL set section header spacing
\usepackage{titlesec}
% 
\titlespacing\subsubsection{0pt}{24pt plus 4pt minus 2pt}{0pt plus 2pt minus 2pt}


%UL set whitespace around verbatim environments
\usepackage{etoolbox}
\makeatletter
\preto{\@verbatim}{\topsep=0pt \partopsep=0pt }
\makeatother


%%%%%%% PAGE HEADERS AND FOOTERS %%%%%%%%%
\usepackage{fancyhdr}
\setlength{\headheight}{15pt}
\fancyhf{} % clear the header and footers
\pagestyle{fancy}
\renewcommand{\chaptermark}[1]{\markboth{\thechapter. #1}{\thechapter. #1}}
\renewcommand{\sectionmark}[1]{\markright{\thesection. #1}} 
\renewcommand{\headrulewidth}{0pt}

\fancyhead[LO]{\emph{\leftmark}} 
\fancyhead[RE]{\emph{\rightmark}} 

% UL page number position 
\fancyfoot[C]{\emph{\thepage}} %regular pages
\fancypagestyle{plain}{\fancyhf{}\fancyfoot[C]{\emph{\thepage}}} %chapter pages


%%%%% SELECT YOUR DRAFT OPTIONS
% This adds a "DRAFT" footer to every normal page.  (The first page of each chapter is not a "normal" page.)

% IP feb 2021: option to include line numbers in PDF

% for line wrapping in code blocks
\usepackage{fancyvrb}
\usepackage{fvextra}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{breaklines=true, breakanywhere=true, commandchars=\\\{\}}

% This highlights (in blue) corrections marked with (for words) \mccorrect{blah} or (for whole
% paragraphs) \begin{mccorrection} . . . \end{mccorrection}.  This can be useful for sending a PDF of
% your corrected thesis to your examiners for review.  Turn it off, and the blue disappears.
\correctionstrue


%%%%% BIBLIOGRAPHY SETUP
% Note that your bibliography will require some tweaking depending on your department, preferred format, etc.
% If you've not used LaTeX before, I recommend reading a little about biblatex/biber and getting started with it.
% If you're already a LaTeX pro and are used to natbib or something, modify as necessary.
% Either way, you'll have to choose and configure an appropriate bibliography format...

% this enables pandoc citations
\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newlength{\csllabelwidth}
\setlength{\csllabelwidth}{3em}
\newlength{\cslentryspacingunit} % times entry-spacing
\setlength{\cslentryspacingunit}{\parskip}
\newenvironment{CSLReferences}[2] % #1 hanging-ident, #2 entry spacing
 {% don't indent paragraphs
  \setlength{\parindent}{0pt}
  % turn on hanging indent if param 1 is 1
  \ifodd #1
  \let\oldpar\par
  \def\par{\hangindent=\cslhangindent\oldpar}
  \fi
  % set entry spacing
  \setlength{\parskip}{1mm}
  \setlength{\baselineskip}{6mm}
 }%
 {}
\usepackage{calc}
\newcommand{\CSLBlock}[1]{#1\hfill\break}
\newcommand{\CSLLeftMargin}[1]{\parbox[t]{\csllabelwidth}{#1}}
\newcommand{\CSLRightInline}[1]{\parbox[t]{\linewidth - \csllabelwidth}{#1}\break}
\newcommand{\CSLIndent}[1]{\hspace{\cslhangindent}#1}




% Uncomment this if you want equation numbers per section (2.3.12), instead of per chapter (2.18):
%\numberwithin{equation}{subsection}


%%%%% THESIS / TITLE PAGE INFORMATION
% Everybody needs to complete the following:
\title{Interaction of top-down and bottom-up processes in degraded speech comprehension}
\author{Pratik Bhandari}
% \college{}
\dissertationasis{Dissertation}
\erlangung{zur Erlangung des akademischen Grades}
\doktor{eines Doktors der Philosophie}
\fakultat{der Fakultät HW}
\bereich{Bereich Empirische Humanwissenschaften}
\uds{der Universität des Saarlandes}
\address{aus Bhadrapur, Nepal}

% Master's candidates who require the alternate title page (with candidate number and word count)
% must also un-comment and complete the following three lines:

% Uncomment the following line if your degree also includes exams (eg most masters):
%\renewcommand{\submittedtext}{Submitted in partial completion of the}
% Your full degree name.  (But remember that DPhils aren't "in" anything.  They're just DPhils.)
\degree{}
% Term and year of submission, or date if your board requires (eg most masters)
\degreedate{Saarbrücken, 2022}


%%%%% YOUR OWN PERSONAL MACROS
% This is a good place to dump your own LaTeX macros as they come up.

% To make text superscripts shortcuts
	\renewcommand{\th}{\textsuperscript{th}} % ex: I won 4\th place
	\newcommand{\nd}{\textsuperscript{nd}}
	\renewcommand{\st}{\textsuperscript{st}}
	\newcommand{\rd}{\textsuperscript{rd}}

%%%%% THE ACTUAL DOCUMENT STARTS HERE
\begin{document}

%%%%% CHOOSE YOUR LINE SPACING HERE
% This is the official option.  Use it for your submission copy and library copy:
\setlength{\textbaselineskip}{22pt plus2pt}
% This is closer spacing (about 1.5-spaced) that you might prefer for your personal copies:
%\setlength{\textbaselineskip}{18pt plus2pt minus1pt}

% You can set the spacing here for the roman-numbered pages (acknowledgements, table of contents, etc.)
\setlength{\frontmatterbaselineskip}{17pt plus1pt minus1pt}

% UL: You can set the line and paragraph spacing here for the separate abstract page to be handed in to Examination schools
\setlength{\abstractseparatelineskip}{13pt plus1pt minus1pt}
\setlength{\abstractseparateparskip}{0pt plus 1pt}

% UL: You can set the general paragraph spacing here - I've set it to 2pt (was 0) so
% it's less claustrophobic
\setlength{\parskip}{2pt plus 1pt}

%
% Customise title page
%
\def\crest{{\includegraphics[width=2.2cm]{templates/beltcrest.png}}}
\renewcommand{\university}{}
\renewcommand{\submittedtext}{vorgelegt von}
\renewcommand{\thesistitlesize}{\fontsize{22pt}{28pt}\selectfont}
\renewcommand{\gapbeforecrest}{25mm}
\renewcommand{\gapaftercrest}{25mm}


% Leave this line alone; it gets things started for the real document.
\setlength{\baselineskip}{\textbaselineskip}


%%%%% CHOOSE YOUR SECTION NUMBERING DEPTH HERE
% You have two choices.  First, how far down are sections numbered?  (Below that, they're named but
% don't get numbers.)  Second, what level of section appears in the table of contents?  These don't have
% to match: you can have numbered sections that don't show up in the ToC, or unnumbered sections that
% do.  Throughout, 0 = chapter; 1 = section; 2 = subsection; 3 = subsubsection, 4 = paragraph...

% The level that gets a number:
\setcounter{secnumdepth}{2}
% The level that shows up in the ToC:
\setcounter{tocdepth}{2}


%%%%% ABSTRACT SEPARATE
% This is used to create the separate, one-page abstract that you are required to hand into the Exam
% Schools.  You can comment it out to generate a PDF for printing or whatnot.

% JEM: Pages are roman numbered from here, though page numbers are invisible until ToC.  This is in
% keeping with most typesetting conventions.
\begin{romanpages}

% Title page is created here
\maketitle

%%%%% DEDICATION
\begin{dedication}
  To baa-aamaa\\
  बा-आमाप्रति समर्पित
\end{dedication}

%%%%% ACKNOWLEDGEMENTS


\begin{acknowledgements}
 	Oh this is hard! PhD and the journey until here.
 How could I have done it without the wonderful people in my life?

 Jutta and Vera have been amazing mentors.
 The German word ``doktormutter'' describes what they have been to me, academically, better than the English word ``supervisor'' does.
 Words don't do justice:
 It is rare to find a supervisor who understands your

 The interdisciplinary discussions in Vera's lab have pushed me beyond my comfort zone to learn about different dimensions of human and machine language.
 It has been an honor and a pleasure to be her student, to have worked with her.
 I couldn't have learnt

 \begin{flushright}
 Pratik Bhandari \\
 Universität des Saarlandes,\\
 Saarbrücken \\
 10 March 2021
 \end{flushright}
\end{acknowledgements}



%%%%% PREFACE


\begin{preface}
 	It was never my prediction that I'd be a researcher.
 And here I am, writing this thesis, compiling my research on \emph{prediction}.
 Being the first person in my family to go to the university and achieve do a PhD is quite an overwhelming feeling.
 If I had to thank someone, it'd be my baa and aamai.
 And bhai who took care of them while I left home at 14.

 This thesis is not just the result of the 4 years of doctoral training in Saarland University.
 During my undergrad in the Institute of Medicine, Lekhnath sir ignited the fire of \emph{research} whatever it meant at that moment.
 It took me to work in the lab of Ramesh sir in University of Hyderabad.
 I can't thank him enough for molding my raw scientific thoughts into critical thinking and giving me the opportunity to explore all the frontires of cognitive science possible.
 Who'd have predicted that a speech-language pathologist cum audiologist from Nepal would be interested in doing a PhD in predictive processing?
 Thanks to David for introducing to this wonderful topic during my Masters at the BCBL.

 My life has always been about reducing uncertainty.
 Yet, the future has always been uncertain for me.
 Will I get a job after my Bachelors?
 Will I get a enrolled in a Masters program anywhere in the planet?
 Can I afford?
 How long till I get a PhD, if at all?

 It is hard to predict what happens next in life.
 Even now, I don't know what comes after PhD.
 And here I am writing a thesis on prediction.

 It has been a long journey.
 4 years in Germany, thousands of miles away from \emph{home}.

 moving from place to place ever since I was two years old.

 Include works that didn't go in the thesis.
\end{preface}



%%%%% ABSTRACT


\renewcommand{\abstracttitle}{Abstract}
\begin{abstract}
	It seems pretty easy to listen to and understand someone speaking.
However, our day-to-day conversations occur under adverse listening conditions.
For example, background noise comes from different sound sources, multiple people talk simultaneously (e.g., in a café), a poor signal connection distorts the voice of a person talking on the other end of a telephone call, and the list goes on.
Despite these adversities, most of the time, we communicate successfully.
One of the significant contributors to our ability to understand language in adverse listening conditions is \emph{predictive language processing}.

Humans are not passive consumers of language:
we use the information available to us from a context and predict the not-yet-encountered, upcoming linguistic events.
We do not wait for a speech signal to unfold completely to decode its meaning.
This feature of human language processing is critical in understanding speech in adverse listening conditions.

In this thesis, we investigated how listeners can use context information and form predictions while listening to speech at different levels of degradation.
The central theme of the thesis is the investigation of the interactions between top-down semantic predictions and bottom-up auditory processing in adverse listening conditions under the theoretical framework of predictive processing and the noisy channel model of communication.
There are numerous methods by which context information and speech degradation (adverse listening conditions) can be created and manipulated in an experimental setup.
We manipulated the context information by creating short Subject-Verb-Object sentences in German in which the verb of a sentence was predictive of its noun.
In addition to the context information, we examined the effect of strategic attention allocation as a top-down process.
Speech was degraded by noise-vocoding of clean speech.
In addition to noise-vocoding, we examined the effect of changes in the speech rate as another factor that influences the bottom-up processes.

In Chapter \ref{chapter-attention-prediction}, we first investigated the role of top-down attention regulation in listeners' ability to use the context information.
Our research question was whether the attention to the context is strictly necessary, regardless of the comprehenders hearing it, to generate predictions about an upcoming word in a sentence at different levels of degradation.
We showed that only when listeners attend to the context information can the semantic predictability of a sentence facilitate degraded speech comprehension.
Moreover, such facilitation was absent at severe degradation levels.
We further examined these findings in Chapter \ref{chapter-graded-prediction} and found that the facilitatory effect of predictability is observed only at a moderate level of speech degradation.
We tested the nature of the predictability effect and found that it is graded in nature and not all-or-nothing.
In other words, we found that listeners' prediction about an upcoming word is not restricted to only highly constraining sentence context;
instead, listeners predict the upcoming word depending on its probability of occurrence in a given context (e.g., cloze probability).
Finally, in Chapter \ref{chapter-speech-rate}, we examined if a change in speech rate --- which changes the processing time --- amplifies or reduces the contextual facilitation observed in Chapter \ref{chapter-graded-prediction}.
The results showed that listeners' comprehension of the moderately degraded speech is at its best at the normal speech rate:
Slowing down did not amplify the contextual facilitation.
However, on increasing the speech rate, processing of low but not high predictability sentences was impaired.
In the restricted processing time, the activation of target words in a less constraining sentence context was more difficult than in a highly constraining sentence context.

All these experiments conducted with German stimuli in native German-speaking young adults revealed that comprehension of degraded speech is predictive in nature:
language processing in a noisy channel is probabilistic and rational.
Listeners weigh top-down processes (lexical-semantic cues) and bottom-up auditory processes (acoustic-phonetic cues).
When the speech degradation is not severe, they can rely on the bottom-up input of an upcoming word (i.e., what they actually heard), regardless of the context information available to them.
When the speech is moderately degraded but intelligible enough, they generate predictions about the upcoming word from the context information.
In addition, the \emph{weighing} of lexical-semantic and acoustic-phonetic cues is also modulated by attention regulation and speech rate.

Taken together, this thesis contributes to the nuanced understanding of the dynamic interaction between top-down and bottom-up processes in speech comprehension.
\end{abstract}




\renewcommand{\abstractsecondtitle}{Zusammenfassung}
\begin{abstractsecond}
	Es scheint ziemlich einfach zu sein, jemandem beim Sprechen zuzuhören und ihn zu verstehen. Unsere täglichen Gespräche finden jedoch unter ungünstigen Bedingungen statt. Zum Beispiel kommen Hintergrundgeräusche von verschiedenen Schallquellen, mehrere Personen sprechen gleichzeitig (z. B. in einem Café), eine schlechte Signalverbindung verzerrt die Stimme des Gesprächspartners am anderen Ende des Telefons, und die Liste geht weiter. Trotz dieser Widrigkeiten kommunizieren wir in den meisten Fällen erfolgreich. Einer der wichtigsten Faktoren, der dazu beiträgt, dass wir Sprache auch unter ungünstigen Bedingungen verstehen können, ist die \emph{predictive language processing}.

In dieser Arbeit haben wir untersucht, wie Hörer Kontextinformationen nutzen und Vorhersagen treffen können, während sie Sprache auf verschiedenen Ebenen der Verschlechterung hören. Das zentrale Thema der Arbeit ist die Untersuchung der Wechselwirkungen zwischen semantischen Vorhersagen von oben nach unten und auditiver Verarbeitung von unten nach oben unter ungünstigen Hörbedingungen im theoretischen Rahmen der ``predictive processing'' und des ``noisy channel model of communication''. Es gibt zahlreiche Methoden, mit denen Kontextinformationen und Sprachverschlechterung (ungünstige Hörbedingungen) in einem Versuchsaufbau erzeugt und manipuliert werden können. Wir haben die Kontextinformationen manipuliert, indem wir kurze Subjekt-Verb-Objekt-Sätze auf Deutsch erstellt haben, in denen das Verb eines Satzes das Substantiv vorhersagt. Zusätzlich zur Kontextinformation untersuchten wir den Effekt der strategischen Aufmerksamkeitszuweisung als Top-down-Prozess. Die Sprache wurde durch ``noise-vocoding'' der reinen Sprache degradiert. Zusätzlich zur noise-vocoding untersuchten wir die Wirkung von Änderungen der Sprechgeschwindigkeit als weiteren Faktor, der die Bottom-up-Prozesse beeinflusst.

In Kapitel 5 untersuchten wir zunächst die Rolle der Top-down-Aufmerksamkeitsregulation für die Fähigkeit der Hörer, die Kontextinformationen zu nutzen. Unsere Forschungsfrage lautete, ob die Aufmerksamkeit auf den Kontext unabhängig von den Verstehern, die ihn hören, unbedingt erforderlich ist, um Vorhersagen über ein kommendes Wort in einem Satz auf verschiedenen Degradationsstufen zu treffen. Wir konnten zeigen, dass die semantische Vorhersagbarkeit eines Satzes nur dann zu einem besseren Sprachverständnis beiträgt, wenn die Hörer auf die Kontextinformationen achten. Darüber hinaus war eine solche Erleichterung bei schweren Degradationsstufen nicht vorhanden. Wir haben diese Ergebnisse in Kapitel 6 weiter untersucht und festgestellt, dass der erleichternde Effekt der Vorhersagbarkeit nur bei einem moderaten Grad der Sprachverschlechterung zu beobachten ist. Wir untersuchten die Art des Vorhersageeffekts und fanden heraus, dass er abgestuft ist und nicht alles oder nichts beinhaltet. Mit anderen Worten, wir fanden heraus, dass die Vorhersage der Hörer über ein kommendes Wort nicht nur auf einen stark einschränkenden Satzkontext beschränkt ist; stattdessen sagen die Hörer das kommende Wort in Abhängigkeit von der Wahrscheinlichkeit seines Auftretens in einem bestimmten Kontext voraus (z. B. ``cloze probability''). Schließlich untersuchten wir in Kapitel 7, ob eine Änderung der Sprechgeschwindigkeit - die die Verarbeitungszeit verändert - die in Kapitel 6 beobachtete kontextuelle Erleichterung verstärkt oder verringert. Die Ergebnisse zeigten, dass das Hörverstehen der mäßig verschlechterten Sprache bei normaler Sprechgeschwindigkeit am besten ist: Eine Verlangsamung verstärkte die kontextuelle Erleichterung nicht. Bei Erhöhung der Sprechgeschwindigkeit wurde jedoch die Verarbeitung von Sätzen mit geringer, aber nicht mit hoher Vorhersagbarkeit beeinträchtigt. In der begrenzten Verarbeitungszeit war die Aktivierung von Zielwörtern in einem weniger einschränkenden Satzkontext schwieriger als in einem stark einschränkenden Satzkontext.

All diese Experimente, die mit deutschen Stimuli an jungen Erwachsenen mit deutscher Muttersprache durchgeführt wurden, haben gezeigt, dass das Verstehen verschlechterter Sprache prädiktiver Natur ist: Die Sprachverarbeitung in einem verrauschten Kanal ist probabilistisch und rational. Die Hörer wägen Top-Down-Prozesse (lexikalisch-semantische Hinweise) und Bottom-Up-Hörprozesse (akustisch-phonetische Hinweise) ab. Wenn die Sprachverschlechterung nicht schwerwiegend ist, können sie sich auf den Bottom-up-Input eines kommenden Wortes verlassen (d.~h. auf das, was sie tatsächlich gehört haben), unabhängig von den ihnen zur Verfügung stehenden Kontextinformationen. Wenn die Sprache mäßig verschlechtert, aber verständlich genug ist, erstellen sie aus den Kontextinformationen Vorhersagen über das kommende Wort. Darüber hinaus wird die Gewichtung von lexikalisch-semantischen und akustisch-phonetischen Hinweisen auch durch die Aufmerksamkeitssteuerung und die Sprechgeschwindigkeit moduliert.

Insgesamt trägt diese Arbeit zu einem differenzierten Verständnis der dynamischen Interaktion zwischen Top-down- und Bottom-up-Prozessen beim Sprachverstehen bei.
\end{abstractsecond}


%%%%% MINI TABLES
% This lays the groundwork for per-chapter, mini tables of contents.  Comment the following line
% (and remove \minitoc from the chapter files) if you don't want this.  Un-comment either of the
% next two lines if you want a per-chapter list of figures or tables.

% This aligns the bottom of the text of each page.  It generally makes things look better.
\flushbottom

% This is where the whole-document ToC appears:
\tableofcontents

\listoffigures
	\mtcaddchapter
  	% \mtcaddchapter is needed when adding a non-chapter (but chapter-like) entity to avoid confusing minitoc

% Uncomment to generate a list of tables:
\listoftables
  \mtcaddchapter
%%%%% LIST OF ABBREVIATIONS
% This example includes a list of abbreviations.  Look at text/abbreviations.tex to see how that file is
% formatted.  The template can handle any kind of list though, so this might be a good place for a
% glossary, etc.
% First parameter can be changed eg to "Glossary" or something.
% Second parameter is the max length of bold terms.
\begin{mclistof}{List of Abbreviations}{3.2cm}

\item[HP]

High predictability

\item[MP]

Medium predictability

\item[LP]

Low predictability

\item[ch]

channels

\item[DE]

German

\item[EN]

English

\item[MEG]

Magnetoencephalography

\item[EEG]

Electroencephalography

\item[ERP]

Event Related Potential

\item[SPIN]

Speech In Noise

\item[G-SPIN]

German Speech In Noise

\item[SNR]

Signal to Noise Ratio

\item[PSOLA]

Pitch synchronous overlap add technique

\item[M]

Mean

\item[SD]

Standard deviation

\item[BOLD]

Blood Oxygen Level Dependent

\item[GPT-2]

Generative Pre-trained Transformer 2

\item[GPT-3]

Generative Pre-trained Transformer 3

\end{mclistof} 


% The Roman pages, like the Roman Empire, must come to its inevitable close.
\end{romanpages}

%%%%% CHAPTERS
% Add or remove any chapters you'd like here, by file name (excluding '.tex'):
\flushbottom

% all your chapters and appendices will appear here
\hypertarget{chapter-introduction}{%
\chapter{Introduction}\label{chapter-introduction}}

One of the features that distinguishes us, humans, from other species is our ability to communicate using verbal language (\protect\hyperlink{ref-Hauser2002}{Hauser et al., 2002}; \protect\hyperlink{ref-Lieberman2013}{Lieberman, 2013}; \protect\hyperlink{ref-Pinker2005a}{Pinker \& Jackendoff, 2005}).
We speak. We listen. We understand.
This seemingly straightforward path of communication goes through plenty of hindrances.
One of them is an adverse listening condition caused by background noise and speech distortion (e.g., \protect\hyperlink{ref-Chen2011}{Chen \& Loizou, 2011}; \protect\hyperlink{ref-Fontan2015}{Fontan et al., 2015}).
Human comprehenders rely on top-down predictive and bottom-up auditory processes to understand spoken language.
Language comprehension in adverse listening conditions is aptly described by the noisy channel model of communication (\protect\hyperlink{ref-Gibson2013}{Gibson et al., 2013}, \protect\hyperlink{ref-Gibson2019}{2019}; \protect\hyperlink{ref-Levy2008}{Levy, 2008}; \protect\hyperlink{ref-Shannon1948}{C. E. Shannon, 1948})
schematically represented in Figure \ref{fig:noisy-channel} below.

\begin{figure}[!htpb]

{\centering \includegraphics[width=0.9\linewidth]{figures/materials/noisy-channel} 

}

\caption{Schematic representation of the noisy channel model of communication}\label{fig:noisy-channel}
\end{figure}

The speaker produces an utterance \(u_i\) with a meaning \(m_i\) that she intends to send.
The utterance is encoded into a signal and sent through a channel of transmission.
During transmission, some external noise disrupts the signal.
The receiver (e.g., a listener) perceives the signal as \(u_p\) and decodes it to recover the meaning as \(m_p\).
The human language comprehension system is assumed to be engaged in optimal Bayesian decoding that uses all the sources of information
(e.g., prior semantic knowledge, context information, world knowledge, etc.)
and infers the intended meaning from the perceived utterance that it receives from a noisy channel of communication (\protect\hyperlink{ref-Gibson2013}{Gibson et al., 2013}; \protect\hyperlink{ref-Levy2008}{Levy, 2008}; cf. \protect\hyperlink{ref-Markman2011}{Markman \& Otto, 2011}).

For successful communication to occur, the message recovered by the listener must be approximately equal to the message intended to be sent by the speaker.
Let's take an example.
X sees a spherical object flying towards Y.
So, she intends to warn him about it: a ``spherical object which is played by two teams of 11 players each in a big playground'' is about to hit Y.
To convey this message, X utters BALL.
Due to external noise, X's (i.e., the speaker's) utterance is distorted, so Y (i.e., the listener) perceives the utterance as HALL.
The listener then interprets that the speaker's message is intended to point him to the ``building where lectures take place in their university'' they were trying to find.
(In this case of unsuccessful communication, or due to the listener wrongly identifying the speaker's intended message, Y gets hit by a ball.)

We assume that the goal of a listener is to identify the message \(m_i\) that is most likely from the perceived utterance \(u_p\), taking into account the external noise (\(N\)) and the prior likelihood of the speaker uttering \(u_i\).
This can be expressed formally as:

\begin{align} \label{eq:noisy-channel2}
\hat{m_p} &= \mathop{\mathrm{argmax}}\limits_{m_p} P(m_p,u_p,N,u_i,m_i)
\end{align}

This sequence of events from the intended message \(m_i\) to the perceived message \(m_p\) can be graphically represented in a Bayesian network (\protect\hyperlink{ref-Bruineberg2021}{Bruineberg et al., 2021}; \protect\hyperlink{ref-Darwiche2010}{Darwiche, 2010}; \protect\hyperlink{ref-Pearl1985}{Pearl, 1985}) in Figure \ref{fig:bayesian-network} (cf.~Figure \ref{fig:noisy-channel}).

\begin{figure}[!htpb]

{\centering \includegraphics[width=0.9\linewidth]{figures/materials/bayesian-network} 

}

\caption{Bayesian network representation of the noisy channel model of communication}\label{fig:bayesian-network}
\end{figure}

Figure \ref{fig:bayesian-network} models the dependencies among the events,
which shows that the external noise and the speaker's utterance are \emph{independent};
however, the listener's perception of the uttered message is also dependent on the noise.
The communication in the noisy channel, represented as a Bayesian network, can now be expressed as:

\begin{align} \label{eq:noisy-channel3}
\hat{m_p} &= \mathop{\mathrm{argmax}}\limits_{m_p} P(m_p | u_p) * P(u_p|u_i, N) * P(u_i | m_i) * P(m_i)
\end{align}

Equation \eqref{eq:noisy-channel3} can be interpreted easily from its corresponding representation in Figure \ref{fig:bayesian-network}.

It shows:

\begin{itemize}
\tightlist
\item
  \(P(m_p | u_p)\): the probability of inferring a meaning \(m_p\) (e.g., a building where lectures take place) from a perceived utterance \(u_p\) (e.g., hall)
\item
  \(P(u_p|u_i, N)\): bottom-up auditory information, i.e., the probability of the listener hearing a particular utterance \(u_p\) (e.g., hall) given that the speaker has uttered an utterance \(u_i\) (e.g., ball) in the noisy channel \(N\) (e.g., background noise, signal distortion, etc.)
\item
  \(P(u_i|m_i)P(m_i)\): prior information (e.g., top-down semantic knowledge, information about the speaker, etc.), i.e., the probability of a speaker uttering \(u_i\) with an intended message \(m_i\) with the probability that the intended message is \(m_i\)
\end{itemize}

The channel of transmission can become noisy due to factors like background noise present in a conversation,
a poor signal transmission of a telephone call that distorts the speaker's speech,
hearing loss of a listener,
hearing aid or cochlear implant worn by a listener, and so on.
To understand speech in such a noisy channel of communication, a listener puts different weights on the distorted bottom-up auditory input \(P(u_p|u_i, N)\) vs the prior information \(P(u_i|m_i)P(m_i)\) (e.g., context information).
This weighing of top-down and bottom-up processes is considered as a rational process in the models of probabilistic language processing in reading comprehension (\protect\hyperlink{ref-Levy2008}{Levy, 2008}; \protect\hyperlink{ref-Ryskin2018}{Ryskin et al., 2018}; see also \protect\hyperlink{ref-vanOs2021}{van Os et al., 2021} for an implementation of the rational approach in language comprehension in background noise).
In this thesis, we also investigate to what extent listeners use their priors from the context information when the signal is distorted at different levels.

Clean speech and reading comprehension studies have demonstrated that listeners and readers use prior knowledge and context information to form semantic predictions about the linguistic events yet to be encountered.

Let's take the following sentence, for example:

\begin{enumerate}
\def\labelenumi{(\arabic{enumi})}
\tightlist
\item
  The day was breezy so the boy went outside to fly a \_\_\_\label{kite}
\end{enumerate}

Most readers would expect the final word to be \emph{kite} in this sentence (\protect\hyperlink{ref-Delong2005}{DeLong et al., 2005}; cf. \protect\hyperlink{ref-Nieuwland2020a}{Nieuwland et al., 2020}). Here, the words up to the final word of the sentence provide a context:
A reader can utilize their knowledge about what a \emph{boy} would ideally do \emph{outside} on a \emph{breezy} day.
It leads the reader to predict that the sentence continuation is most likely \emph{kite} and not an improbable word like \emph{rocket}.
Similar results are observed in the auditory domain as well.
Listeners use context information from what they have heard and form predictions about an upcoming word (e.g., \protect\hyperlink{ref-Altmann2007}{Altmann \& Kamide, 2007}; \protect\hyperlink{ref-Ankener2019}{Ankener, 2019}).
That is, human language comprehension is predictive in nature, such that listeners engage in predictive language processing (Section \ref{predictive-language-processing}, \protect\hyperlink{ref-Kuperberg2016}{Kuperberg \& Jaeger, 2016}; \protect\hyperlink{ref-Pickering2018}{Pickering \& Gambi, 2018}).

In a noisy channel, listeners' engagement in predictive processing is influenced by the noise in the signal (\protect\hyperlink{ref-Obleser2007}{Obleser et al., 2007}; \protect\hyperlink{ref-Sheldon2008a}{Sheldon et al., 2008a}).
Based on the theoretical accounts of the noisy channel model of communication and the predictive language processing (\protect\hyperlink{ref-Christiansen2015}{Christiansen \& Chater, 2015}; \protect\hyperlink{ref-Ferreira2016}{Ferreira \& Lowder, 2016}; \protect\hyperlink{ref-Friston2020}{K. J. Friston, Parr, et al., 2020}; \protect\hyperlink{ref-Hale2001}{Hale, 2001}; \protect\hyperlink{ref-Levy2008}{Levy, 2008}; \protect\hyperlink{ref-Mcclelland1986}{McClelland \& Elman, 1986}; \protect\hyperlink{ref-Norris2016}{Norris et al., 2016}; \protect\hyperlink{ref-Pickering2018}{Pickering \& Gambi, 2018}),
this thesis investigates the interaction between top-down predictive and bottom-up auditory processes.
We examine how top-down predictive processes facilitate language comprehension in a noisy channel created by \protect\hyperlink{speech-processing}{acoustic degradation of speech},
and what the nature of such a facilitation is (e.g., probabilistic, deterministic).
We investigate the levels of noise in the signal for the effect of top-down predictive processes to be most efficient or facilitatory for language comprehension.
By manipulating different factors of top-down as well as bottom-up processes (e.g., speech rates, attention allocation to different parts of the speech stream),
we examine their role in aiding (or interfering) the comprehension of degraded speech.
While doing so, we address the following research goals.

\hypertarget{research-goals}{%
\section{Research goals}\label{research-goals}}

\begin{enumerate}
\def\labelenumi{(\arabic{enumi})}
\item
  \textbf{To replicate the predictability effect in a noisy channel}\\
  Almost all the disciplines of cognitive science --- anthropology, computer science, linguistics, neuroscience, and psychology --- are suffering the so-called replication crisis (\protect\hyperlink{ref-OSC2015}{Aarts et al., 2015}; \protect\hyperlink{ref-Cockburn2020}{Cockburn et al., 2020}; \protect\hyperlink{ref-Ebersole2016}{Ebersole et al., 2016}; \protect\hyperlink{ref-Minocher2021}{Minocher et al., 2021}; \protect\hyperlink{ref-Sanderson2008}{Sanderson \& Roberts, 2008}).
  The results of an experiment do not hold up consistently when another group of researchers conduct it again:
  For example, DeLong et al. (\protect\hyperlink{ref-Delong2005}{2005}) found that it was easier to process the article `an' when readers anticipated a phonologically congruent word `airplane' than when they anticipanted a phonologically incongruent word `kite'.
  But this effect was not replicated in a recent multi-lab collaborative study by Nieuwland et al. (\protect\hyperlink{ref-Nieuwland2020a}{2020}).
  The first goal of this thesis is to test if we can replicate the facilitatory effect of semantic predictability in language comprehension in a noisy channel (e.g., \protect\hyperlink{ref-Obleser2007}{Obleser et al., 2007}; \protect\hyperlink{ref-Sheldon2008a}{Sheldon et al., 2008a}).
  Replication of the predictability effect in comprehension of degraded speech
  will help gather evidence in favour of this \emph{effect of interest}.
  It will also provide a reliable foundation to test if (and how) other factors (e.g., speed of information processing) influence and interact with the facilitatory effect of predictability.
\item
  \textbf{To examine the nature of prediction}\\
  There are at least two schools of thought which argue that prediction is either all-or-nothing or probabilistic (\protect\hyperlink{ref-Coltheart2004}{Coltheart, 2004}; \protect\hyperlink{ref-Kuperberg2016}{Kuperberg \& Jaeger, 2016}; \protect\hyperlink{ref-Luke2016}{Luke \& Christianson, 2016}).
  These debates generally centre around reading comprehension and clean speech comprehension.
  The discussion about the nature of prediction in a noisy channel like degraded speech is sparse.
  Specifically, in degraded speech comprehension, only one study has empirically investigated the theoretical postulation that prediction is restricted only to highly predictable sentence endings (\protect\hyperlink{ref-Strauss2013}{Strauß et al., 2013}).
  Therefore, the second goal of this thesis is to examine the nature of the predictability effect.
  With carefully designed experiments and materials, this thesis aims to test the distinction between all-or-nothing and probabilistic predictions in degraded speech comprehension.
\item
  \textbf{To assess the boundary conditions of predictive language processing}\\
  Several authors claim that predictive processing is the fundamental nature of human cognition and, thus, by definition, also of language processing (\protect\hyperlink{ref-Clark2013}{A. Clark, 2013}; \protect\hyperlink{ref-Friston2020}{K. J. Friston, Parr, et al., 2020}; \protect\hyperlink{ref-Friston2020b}{K. J. Friston, Sajid, et al., 2020}; \protect\hyperlink{ref-Kuperberg2020}{Kuperberg, 2021}; \protect\hyperlink{ref-Lupyan2015}{Lupyan \& Clark, 2015}).
  At the same time, an increasing number of studies are showing boundary conditions and prerequisite conditions for predictive language processing (\protect\hyperlink{ref-Federmeier2010}{K. D. Federmeier et al., 2010}; \protect\hyperlink{ref-Huettig2019}{Huettig \& Guerra, 2019}; \protect\hyperlink{ref-Huettig2016}{Huettig \& Mani, 2016}; \protect\hyperlink{ref-Mishra2012}{Mishra et al., 2012}).
  For example, prediction can have different effects on unattended stimuli and attended stimuli (cf. \protect\hyperlink{ref-Kok2012}{Kok et al., 2012}).
  In a noisy channel (i.e., degraded speech), attention to a part of a speech stream can modulate or limit the predictability effect as different parts of the speech stream contain different linguistic units;
  each linguistic unit (e.g., each word in a sentence) carries its own meaning that serves the entire message (e.g., words serve in building the meaning of the entire sentence).
  Therefore, the third goal of this thesis is to examine the role of auditory attention that can act as a prerequisite for semantic predictions
  or limit the automaticity of predictive processing in degraded speech comprehension.\\
  This thesis aims to test whether attention to different parts of degraded speech stream aids or hampers facilitatory effects of top-down predictions.
\item
  \textbf{To test for the adaptation to degraded speech}\\
  Despite the difficulty in understanding speech in a noisy channel,
  listeners rapidly adapt to degraded speech (\protect\hyperlink{ref-Rosen1999}{Rosen et al., 1999}):
  Their performance improves over the course of the experiment.
  When the properties of speech vary in the dimension of both acoustic-phonetic cues as well as lexical-semantic cues,
  adaptation can be difficult.
  The fourth goal of this thesis is to examine if listeners adapt to degraded speech when both degradation level and predictability of speech are varied.
  We test if an adaptation to the bottom-up perceptual property of speech is influenced by its top-down semantic property.
\item
  \textbf{To examine the effect of speed speech rate}\\
  Unlike the visual scene that opens in the spatial dimension, speech signal flows in the temporal dimension.
  This challenges the listeners to process information at different speeds and timescales;
  more time is available to process the information in slow speech, while less time is available for fast speech (\protect\hyperlink{ref-Lerner2014}{Lerner et al., 2014}).
  Listeners build up the meaning representation as they process the speech to predict upcoming linguistic units.
  The fifth goal of this thesis is to examine whether a change in information flow, i.e., speech rate, affects the facilitatory effect of predictability.
  We test if an increase or decrease in speech rate impedes the intelligibility of speech over a noisy channel
  and whether it impedes or further aids the predictability effect in the noisy channel.
\item
  \textbf{To assess language comprehension considering the context}\\
  Different researchers have used different measurement metrics in the study of speech perception and language comprehension (\protect\hyperlink{ref-Amichetti2018}{Amichetti et al., 2018}; \protect\hyperlink{ref-Obleser2007}{Obleser et al., 2007}; \protect\hyperlink{ref-Peelle2013}{Peelle, 2013}; \protect\hyperlink{ref-Sheldon2008a}{Sheldon et al., 2008a}).
  The measurement is inconsistent across studies which becomes a problem, especially when the effect of context in comprehension is under discussion:
  cross-study comparison does not give a clear picture of the predictability effect in this case.
  Therefore, the sixth goal of this thesis is to establish and consistently use a sensitive metric for the measurement of language comprehension that takes into account whether participants (in)correctly use the context-evoking word in a sentence.
\end{enumerate}

Studies addressing the research goals outlined above will primarily contribute to elaborating and developing the existing theories of predictive language processing and furthering the understanding of spoken language comprehension in a noisy channel, especially degraded speech comprehension.
Below we present the contributions of the research presented in this thesis.

\hypertarget{research-contributions}{%
\section{Research contributions}\label{research-contributions}}

The research reported in this thesis examines theoretical questions of predictive language processing and its boundary conditions when spoken language comprehension takes place through a noisy channel.
It contributes to the studies of speech perception, language comprehension, predictive coding, language science, audiology, psycholinguistics, psychology, and, broadly, cognitive science.
In an applied setting, this informs translational/clinical researchers about language comprehension in \protect\hyperlink{distortion-degradation}{cochlear implantees}.

\begin{itemize}
\item
  \textbf{Graded effect of predictability}\\
  We replicate the previous finding of the predictability effect showing that predictability facilitates comprehension of degraded speech at moderate levels of degradation (e.g., \protect\hyperlink{ref-Obleser2007}{Obleser et al., 2007}).
  Additionally, in the current debate of all-or-nothing vs graded prediction, our findings indicate that prediction across the noisy channel of degraded speech is graded in nature
  rather than being restricted to a narrow space of highly predictable sentence endings.
  Goals 1 and 2 correspond to this research contribution brought about by the experiments described in Chapters \ref{chapter-attention-prediction} and \ref{chapter-graded-prediction}.
\item
  \textbf{Attention in predictive language processing}\\
  We show that predictive processing is not always automatic, and it cannot all by itself explain how listeners understand speech in a noisy channel.
  Although top-down predictions facilitate comprehension, we show that attention to the context is a prerequisite for such contextual facilitation.
  Only when listeners attend to the context information and form its meaning representation can the top-down predictions facilitate comprehension of degraded speech.
  Without proper attention to the context, predictability effects cannot be observed.
  Goal 3 corresponds to this research contribution brought about by the experiment described in Chapter \ref{chapter-attention-prediction}.
\item
  \textbf{Absence of perceptual adaptation}\\
  We show that listeners do not adapt to degraded speech when lexical-semantic cues are taken into consideration.
  This is in contrast with the previous findings of speech perception experiments, some of which disregard the trial-by-trial variation in sentence context (e.g., \protect\hyperlink{ref-Davis2005}{Davis et al., 2005}; \protect\hyperlink{ref-Erb2013}{Erb et al., 2013}).
  When listeners are engaged in a linguistic task in which the lexical cues vary on every trial,
  their cognitive resources are strained by lexical-semantic cues rather than acoustic-phonetic cues.
  Thus, they do not show any adaptation effect;
  every trial is effectively a novel trial for them.
  Goal 4 corresponds to this research contribution brought about by the experiments described mainly in Chapters \ref{chapter-graded-prediction} and \ref{chapter-speech-rate}.
\item
  \textbf{Change in information flow and its effect on top-down prediction}\\
  We show that different rates of information flow --- increase or decrease in the rate of speech --- have different effects on language comprehension.
  Intelligibility of speech decreases with both increase and decrease of speech rate.
  However, the increase in speech rate is particularly detrimental to comprehension of degraded speech as it increases the difficulty in processing sentences with less predictable endings.
  This is one of the few studies highlighting the role of speed of flow of information in the contextual facilitation of degraded speech.
  Goal 5 corresponds to this research contribution brought about by the experiment described in Chapter \ref{chapter-speech-rate}.
\item
  \textbf{A metric of language comprehension}\\
  We propose and successfully use a metric of language comprehension that reflects listeners' use of context information.
  This metric does not merely measure how many words are correctly identified.
  Instead, it considers the fact that in the study of the effect of predictability, how well a context is recognized should also be taken into account.
  Thus it measures word recognition accuracy in the sentences in which context is correctly recognized.
  Using such a metric improves the interpretation of contextual facilitation across studies, which is lacking in the extant literature.
  Goal 6 corresponds to this research contribution brought about by consistent use of this metric in Chapters \ref{chapter-graded-prediction} and \ref{chapter-speech-rate}.
\end{itemize}

\hypertarget{overview-of-the-thesis}{%
\section{Overview of the thesis}\label{overview-of-the-thesis}}

The central theme of this thesis is the study of predictive processing in language comprehension across a noisy channel.
On the grounds of predictive language processing and the noisy channel model of communication,
we investigate how and to what extent listeners use context information while listening to degraded speech.
We replicate and extend prior findings, which claim that predictability facilitates language comprehension at moderate levels of speech degradation.
Furthermore, the boundary conditions of predictive processing are tested, examining the effect of different rates of information flow in the predictability effect.
We test for the presence of perceptual adaptation and find evidence against the learning effect and adaptation to degraded speech.

\noindent
\textbf{Chapter \ref{chapter-background}} provides a background on the rest of the chapters.
It provides an overview of degraded speech comprehension and predictive language processing.
The current status of the debate on these topics is also presented.

\noindent
\textbf{Chapter \ref{chapter-methods}} describes the stimuli used in all the experiments in this thesis.
It describes the process of stimuli creation and speech processing, and provides an overview of online data collection.

\noindent
\textbf{Chapter \ref{chapter-stats}} describes the statistical tests employed for data analyses.
Binomial logistic mixed effects modelling is performed on the data from all the experiments.
This chapter provides a background on this statistical procedure
and how it is operated on the statistical software \texttt{R}.

\noindent
\textbf{Chapter \ref{chapter-attention-prediction}} presents two experiments that address the first and the third research goal.
These experiments are conducted to examine the predictability effect in degraded speech comprehension
and the role of auditory attention.
Participants in both experiments are presented with the speech degraded at different levels of degradation
and sentences of different levels of predictability.
Participants in Experiment 1 are asked to type in only the final word of a sentence;
this did not bind their attention to the sentence context.
In contrast, the participants in Experiment 2 are asked to type in the entire sentence that they heard, which required them to attend to the sentence context as well.
We replicate the previously reported predictability effects in the noisy channel only when participants attended to the entire sentence, including the context.
We show that top-down predictions cannot be generated at moderate levels of degradation when insufficient attention is given to context.
We discuss the limitation in the existing theories of predictive language processing, which commit to the automaticity of prediction.
We show the importance of \emph{attention} in language comprehension.
We end this chapter with the note that the measurement of language comprehension can be further refined
and the nature of the predictability effect tested.

\noindent
\textbf{Chapter \ref{chapter-graded-prediction}} addresses the first, the second, the fourth, and the sixth research goals.
The predictability effect partially replicated in Chapter \ref{chapter-attention-prediction} is further examined in this chapter.
We use a refined metric of measurement of language comprehension that takes into consideration whether listeners correctly identified the context.
We observe predictability effects at a moderate level of speech degradation, thereby consistently replicating the facilitatory effect of predictability.
We find the predictability effects to be graded in nature
and discuss it in the light of existing theories of predictive processing.
We also show that regardless of the certainty about the next-trial degradation level,
listeners do not adapt to degraded speech when its lexical-semantic property varies every trial.
At the end of this chapter, we note the intrinsic difficulty of processing degraded speech and open the question that the predictability effects could be further enhanced (or limited) with more (or less) time available to process the degraded speech.

\noindent
\textbf{Chapter \ref{chapter-speech-rate}} addresses the questions raised in Chapter \ref{chapter-graded-prediction}.
In two experiments, it addresses the fourth, the fifth, and the sixth research goals.
We use the same metric of measurement of language comprehension as Chapter \ref{chapter-graded-prediction}, which takes into account listeners' correct identification of the context.
Listeners are presented with the moderately degraded speech at which the predictability effect is observed in Chapter \ref{chapter-graded-prediction}.
In Experiment 1, the moderately degraded speech is presented at normal and fast speech rates.
In Experiment 2, the speech rates are normal and slow.
For fast speech, both intelligibility and the predictability effect are reduced, driven by the difficulty in processing words that are less predictable from the context.
Although more time is available to process the context of the degraded speech at a slow speech rate,
there is no increase in the facilitatory effect of predictability with a reduced speech rate;
instead, intelligibility is reduced in slow speech compared to normal speech.
This chapter reflects on the limitations of predictive processing driven by the constraints in cognitive resources.

\noindent
\textbf{Chapter \ref{chapter-conclusion}} summarizes the findings of all the studies.
It concludes with the closing remarks on the limitations of the the studies, theoretical and practical implications, and the direction for future research.

\noindent
\textbf{Chapter \ref{chapter-ethics}} presents ethical approval that was obtained to run the experiments on human subjects.
The source that provided funding to conduct the research presented in this thesis is disclosed.

\hypertarget{dissemination-of-research-findings}{%
\section{Dissemination of research findings}\label{dissemination-of-research-findings}}

Some of the findings reported in this thesis are presented and published elsewhere to disseminate scientific findings to a broader audience.
The presentations and publications that report on parts of the research described in this thesis are outlined below.

\textbf{Research articles}:

\begin{itemize}
\item
  Bhandari, P., Demberg, V., \& Kray, J.
  (\emph{under review}) Speaking fast and slow: How speech rate affects contextual facilitation in degraded speech comprehension.
\item
  Bhandari, P., Demberg, V., \& Kray, J.
  (2022).
  Predictability effects in degraded speech comprehension are reduced as a function of attention.
  \emph{Language and Cognition}, 1-18. \url{doi:10.1017/langcog.2022.16}
\item
  Bhandari, P., Demberg, V., \& Kray, J.
  (2021).
  Semantic predictability facilitates comprehension of degraded speech in a graded manner.
  \emph{Frontiers in Psychology}, 12:714485. \url{doi:10.3389/fpsyg.2021.714485}
\end{itemize}

\textbf{Conference presentations}:

\begin{itemize}
\item
  Bhandari, P., Demberg, V., \& Kray, J.
  (2022).
  The effect of speech rate on contextual facilitation of degraded speech comprehension.
  \emph{Architectures and Mechanisms for Language Processing}, 2022-09-07--2022-09-09.
\item
  Bhandari, P., Demberg, V., \& Kray, J.
  (2022).
  Predictability effects in degraded speech comprehension are reduced as function of attention.
  \emph{Architectures and Mechanisms for Language Processing}, 2022-09-07--2022-09-09.
\item
  Bhandari, P., Demberg, V., \& Kray, J.
  (2022).
  The effect of speech rate in comprehension of degraded speech.
  \emph{International Max Planck Research School (IMPRS) Conference}, 2022-06-01--2022-06-03.
\item
  Bhandari, P., Demberg, V., \& Kray, J.
  (2022).
  Predictability effects are reduced as a function of attention.
  \emph{Annual Convention of American Psychological Association}, 2022-05-25--2022-05-28.
\item
  Bhandari, P., Demberg, V., \& Kray, J.
  (2021).
  Predictability facilitates comprehension but not adaptation to degraded speech in a graded manner.
  \emph{Conference of the Society for the Neurobiology of Language}, 2021-10-05--2021-10-08.
\end{itemize}

\begin{itemize}
\tightlist
\item
  Bhandari, P., Demberg, V., \& Kray, J. (2021). Predictability facilitates comprehension of degraded speech in a graded manner. \emph{Annual Meeting of Cognitive Neuroscience Society}, 2021-03-13--2021-03-16.
\end{itemize}

\hypertarget{chapter-background}{%
\chapter{Background}\label{chapter-background}}

In the previous chapter, we outlined the theoretical background and the research goals of the studies in this dissertation.
We stated that the central theme of this thesis is to investigate the interaction between top-down predictive and bottom-up auditory processes in language comprehension.
Building on the noisy channel model of communication and predictive language processing,
the studies in this thesis manipulate the auditory processes \(P(u_p|u_i,N)\), and prior information \(P(u_i,m_i)\) in the form of semantic context available in a sentence.
In this chapter, we provide background on the noisy channel that was created and used to introduce variations in the bottom-up processing in the studies presented in this thesis.
We also elaborate on the predictive language processing in the noisy channel and the evidence of its limits and nature.
Understanding these fundamental concepts of top-down and bottom-up processes is essential for the chapters that follow;
these concepts are briefly reiterated in the following chapters wherever relevant.
Additionally, this chapter outlines the gaps in previous research that this thesis fills in.

\hypertarget{distortion-degradation}{%
\section{Speech distortion and degradation}\label{distortion-degradation}}

Most of the existing frameworks of spoken language comprehension are inspired by the experiments conducted with clean speech,
the condition of ``artificial normalcy'' (\protect\hyperlink{ref-Mattys2012}{Mattys et al., 2012}).
However, spoken language communication generally occurs outside the artificial normalcy, alongside different sources of noise and disruption.
Probabilistic models of language comprehension, like the noisy channel model of communication (\protect\hyperlink{ref-Gibson2013}{Gibson et al., 2013}, \protect\hyperlink{ref-Gibson2019}{2019}; \protect\hyperlink{ref-Levy2008}{Levy, 2008}; \protect\hyperlink{ref-Shannon1948}{C. E. Shannon, 1948}) in Figures \ref{fig:noisy-channel} and \ref{fig:bayesian-network} show that the speech signal uttered by the speaker gets disrupted and distorted due to the noise (\(u_i\rightarrow u_p\leftarrow N\)) .
Distortion can occur at these three points or sources: encoding, transmission, and decoding (\protect\hyperlink{ref-Mattys2012}{Mattys et al., 2012}).
Speech can be distorted while encoding the utterance \(u_i\) due to the variability in speakers' production, like accented or slow and fast speech.
Distortion can arise while decoding the signal \(u_p\) due to listener-related factors, like hearing loss or auditory processing disorder.
It can also result from an external noise that appears during the transmission, like ambient noise or poor transmission medium (e.g., distortion in the telephone line).
These different sources of distortion make a listening condition adverse by affecting the time and frequency-related properties/cues of the speech signal, i.e., temporal envelope cues and spectral details of speech, respectively.
The temporal envelope cues are the slow variations in the amplitude of the speech signal over time (\protect\hyperlink{ref-Moon2014}{Moon et al., 2014}; \protect\hyperlink{ref-Moon2014a}{Moon \& Hong, 2014}), while the spectral details are the frequency-specific information about the speech.
The temporal envelope cues reflect the prosodic information of the speech and are used in lexical-semantic and syntactic processing (\protect\hyperlink{ref-Greenberg1996}{Greenberg, 1996}; \protect\hyperlink{ref-Schneider2001}{Schneider \& Pichora-Fuller, 2001}; \protect\hyperlink{ref-Sheldon2008b}{Sheldon et al., 2008b}).
The spectral details provide information about the sound production reflecting the vocal tract's resonant properties, speech signal frequency range, energy distribution across frequency bands, etc. (\protect\hyperlink{ref-Roberts2011}{Roberts et al., 2011}; \protect\hyperlink{ref-Shannon1995}{Shannon et al., 1995}; \protect\hyperlink{ref-Shannon2004}{Shannon et al., 2004}).

In an experimental setup, a noisy channel can be created artificially by digital signal processing (see Section \ref{speech-processing}) to investigate the response of the speech perception system to distorted speech
and to study language comprehension in an adverse listening condition.
For example, signal compression or expansion acts upon the temporal property of the speech and makes it fast or slow (i.e., change its speed), and an optimal level of speech expansion/compression does not distort the spectral property of speech (see Section \ref{compression-expansion}).
In addition to speech compression and expansion in Chapter \ref{chapter-speech-rate},
throughout the studies in this thesis, we implement noise-vocoding to manipulate the spectral property of speech and create a noisy channel of communication.

Noise-vocoding removes the spectral details of the speech signal in a controlled manner, only leaving intact its temporal and periodicity cues (see Section \ref{noise-vocoding}).
This method of speech degradation was initially developed as a means to reduce the information in speech signals to be transmitted through the telephone line (\protect\hyperlink{ref-Vocoder1940}{Clendeninn, 1940}; \protect\hyperlink{ref-Dudley1939}{Dudley, 1939}).
Shannon and colleagues later modified and used this technique as an analogue to cochlear implants such that the number of channels used in a cochlear implant is similar to the number of noise-vocoding channels in terms of their speech output and intelligibility (\protect\hyperlink{ref-Loizou1999}{Loizou et al., 1999}; \protect\hyperlink{ref-Shannon1995}{Shannon et al., 1995}; \protect\hyperlink{ref-Shannon2004}{Shannon et al., 2004}; cf. \protect\hyperlink{ref-Orena2021}{Orena \& Colby, 2021}).
Therefore, in addition to being a method of speech distortion to parametrically vary and control the quality of speech signals in a graded manner,
noise-vocoding is also a method of distortion that is used to understand the speech perception and language comprehension in cochlear implantees (e.g., \protect\hyperlink{ref-Patro2020}{Patro \& Mendel, 2020}; \protect\hyperlink{ref-Shannon2004}{Shannon et al., 2004}; \protect\hyperlink{ref-Winn2016}{M. Winn, 2016})

One of the main factors that determine the intelligibility of degraded speech is the number of noise-vocoding channels.\footnote{Throughout this thesis, speech distortion by noise-vocoding is referred to as speech degradation, or spectral degradation of speech.}
The higher the number of noise-vocoding channels, the more the frequency-specific information available in the degraded speech,
and the higher the intelligibility compared to the speech that is degraded with a lesser number of noise-vocoding channels.
For example, listeners have been shown shown to rate 8-channel noise-vocoded speech to be more intelligible and less effortful than 2 channels noise-vocoded speech (e.g., \protect\hyperlink{ref-Obleser2011}{Obleser \& Kotz, 2011}; \protect\hyperlink{ref-Sohoglu2012}{Sohoglu et al., 2012}).
In our studies, we create a noisy channel with different degradation levels and intelligibility by noise-vocoding the speech signal through 1, 4, 6 and 8 channels.
The details of the artificial distortions are described in Chapter \ref{chapter-methods}.

\hypertarget{prediction-and-comprehension-of-degraded-speech}{%
\section{Prediction and comprehension of degraded speech}\label{prediction-and-comprehension-of-degraded-speech}}

In addition to the quality of speech signals, listeners rely on context information and form top-down predictions to understand speech in adverse listening conditions.
Below, we first review the role of predictions in language comprehension in general,
and then we discuss the role of top-down predictive processes in comprehension of degraded speech in particular.

\hypertarget{predictive-language-processing}{%
\subsection{Predictive language processing}\label{predictive-language-processing}}

Research from various domains of cognitive (neuro)science, like emotion, vision, odour, and proprioception (the sensation of one's body position and movement, \protect\hyperlink{ref-Tuthill2018}{Tuthill \& Azim, 2018}), has shown that perception and cognition can be described under the framework of predictive processing; they primarily operate by predicting upcoming events (\protect\hyperlink{ref-Clark2013}{A. Clark, 2013}; \protect\hyperlink{ref-Marques2018}{Marques et al., 2018}; \protect\hyperlink{ref-Seth2013}{Seth, 2013}; \protect\hyperlink{ref-Stadler2012}{Stadler et al., 2012}; cf. \protect\hyperlink{ref-Bowers2012}{Bowers \& Davis, 2012}; \protect\hyperlink{ref-Jones2011}{Jones \& Love, 2011}; \protect\hyperlink{ref-Pierce1987}{Pierce \& Ollason, 1987}).
Despite a long-standing scepticism and doubt about the usefulness of prediction in language processing (\protect\hyperlink{ref-Forster1981}{Forster, 1981}; \protect\hyperlink{ref-Jackendoff2002}{Jackendoff, 2002}; \protect\hyperlink{ref-VanPetten2012}{Van Petten \& Luka, 2012}),
human language comprehension too has been claimed to be predictive in nature from as early as the mid-twentieth century (e.g., \protect\hyperlink{ref-Mccullough1958}{McCullough, 1958}; \protect\hyperlink{ref-Miller1951}{Miller et al., 1951}; \protect\hyperlink{ref-Morton1964}{Morton, 1964})
which in recent days has received overwhelming support from computational linguistics, psycholinguistics and cognitive neuroscience of language (e.g., \protect\hyperlink{ref-Delong2005}{DeLong et al., 2005}; \protect\hyperlink{ref-Demberg2013}{Demberg et al., 2013}; \protect\hyperlink{ref-Heyselaar2021}{Heyselaar et al., 2021}; \protect\hyperlink{ref-Lupyan2015}{Lupyan \& Clark, 2015}; \protect\hyperlink{ref-Pickering2018}{Pickering \& Gambi, 2018}).
Empirical evidence from several studies suggests that readers and listeners predict upcoming words in a sentence when the words are predictable from the preceding context (\protect\hyperlink{ref-Kuperberg2016}{Kuperberg \& Jaeger, 2016}; \protect\hyperlink{ref-Nieuwland2019}{Nieuwland, 2019}; for reviews, \protect\hyperlink{ref-Staub2015}{Staub, 2015}).
For instance, predictable words are skipped and read faster than the words that are less predictable from the context (\protect\hyperlink{ref-Ehrlich1981}{Ehrlich \& Rayner, 1981}; \protect\hyperlink{ref-Frisson2005}{Frisson et al., 2005}; \protect\hyperlink{ref-Staub2011}{Staub, 2011}).
Applying the visual world paradigm, studies have demonstrated that individuals show anticipatory eye movements towards a picture of an object (e.g., \emph{cake}) that is predictable from the preceding sentence context (e.g., \emph{The boy will eat a\ldots{}}) even before hearing the final target word (\protect\hyperlink{ref-Altmann1999}{Altmann \& Kamide, 1999}; \protect\hyperlink{ref-Ankener2018}{Ankener et al., 2018}; \protect\hyperlink{ref-Kamide2003}{Kamide et al., 2003}).
Similar results have been observed in a virtual world setup with naturalistic scenes (e.g., \protect\hyperlink{ref-Heyselaar2021}{Heyselaar et al., 2021}).
The sentence-final word in a highly constraining sentence (e.g., \emph{``She dribbles a ball.''}) elicits a smaller N400 amplitude\footnote{N400 is a negative-going EEG component that peaks around 400 ms post-stimulus and is considered a neural marker of context-based semantic unexpectedness (\protect\hyperlink{ref-Kutas2011}{Kutas \& Federmeier, 2011}).} than a less constraining sentence (e.g., \emph{``She buys a ball.''}, \protect\hyperlink{ref-Federmeier2007}{K. Federmeier et al., 2007}; \protect\hyperlink{ref-Kutas1984}{Kutas \& Hillyard, 1984}).
Similarly, event-related words (e.g., \emph{``luggage''}) elicited reduced N400 compared to event-unrelated words (e.g., \emph{``vegetables''}), which were not predictable from the context (e.g., in the event of \emph{``travel''}, \protect\hyperlink{ref-Metusalem2012}{Metusalem et al., 2012}).
In sum, as the sentence context builds up, listeners make predictions about upcoming words in the sentence, and these, in turn, facilitate language comprehension.
That is, individuals use the context available to them to generate predictions that aids understanding of written and spoken language.

\hypertarget{but-what-is-prediction}{%
\subsubsection{But, what is prediction?}\label{but-what-is-prediction}}

\noindent
The history of \emph{prediction} in language science is rocky (\protect\hyperlink{ref-Husband2020}{Husband \& Bovolenta, 2020}).
People have been sceptical that language processing is predictive in nature.
Different people mean different things when they use the word prediction.
As Kuperberg \& Jaeger (\protect\hyperlink{ref-Kuperberg2016}{2016}) put it, \emph{prediction} has become a loaded term;
it is used alongside other similar terms like \emph{integration} (\protect\hyperlink{ref-Federmeier2007a}{K. D. Federmeier, 2007}), \emph{anticipation}, \emph{expectation} (\protect\hyperlink{ref-VanPetten2012}{Van Petten \& Luka, 2012}), \emph{preparedness} (\protect\hyperlink{ref-Ferreira2018}{Ferreira \& Chantavarin, 2018}), etc.

This thesis uses the word \emph{prediction} in the following minimal sense.
As a sentence unfolds, listeners encounter the context information in the sentence and form its meaning representation, i.e.,
an internal representation of the context.
Before they hear the next word, i.e., before they encounter new bottom-up information,
they generate an expectation\footnote{Henceforth, we use the word expectation and prediction interchangeably.
} about the new word based on the meaning representation of the context.
They could form a prediction about only the semantic feature of the next word,
or they could predict the exact word (meaning prediction vs word-form prediction).

In reading studies and clean speech comprehension, there are opposing views.
One view is that the comprehenders predictively preactivate the upcoming linguistic unit solely based on the top-down information (i.e., predictive \emph{preactivation}).
In contrast, the opposing view is that the comprehenders wait for the bottom-up information to activate the representation (e.g., phonological and semantic representation) of the new information and its neighbours\footnote{The Neighborhood Activation Model of Luce \& Pisoni (\protect\hyperlink{ref-Luce1998}{1998}) proposes that an auditory input of a word activates its neighbourhood words, which can be similar acoustically. The neighbourhood density is supposed to depend on the word frequency as well.},
then use the top-down information to select the best representation.
To clarify it further,
let's take the example sentence \emph{(1)} presented in Chapter \ref{chapter-introduction} on page \pageref{kite}:
\emph{The day was breezy so the boy went outside to fly a}\_\_\_.
Upon listening to this context, the listeners can form a high degree of belief that the next word will be `kite'.
Before even hearing it, listeners preactivate the representation of ``kite'' in their mental lexicon.
Alternatively, they could wait until they hear the auditory input ``kite'', which activates ``kite'' and its phonological (and semantic) neighbours in the mental lexicon,
then use the top-down information to select the most likely word that completes the sentence.
Either way, top-down processes facilitate comprehension.

While listening in an adverse condition, it is unlikely that a listener follows the latter strategy of waiting for the bottom-up input to activate the representations and then selecting the most likely one based on the top-down information (\protect\hyperlink{ref-Kuperberg2016}{Kuperberg \& Jaeger, 2016}).
When speech is distorted, it is difficult to form the context representation in the first place (cf.~cue-based retrieval, \protect\hyperlink{ref-Kaufeld2021}{Kaufeld, 2021}; \protect\hyperlink{ref-Martin2016}{Martin, 2016}).
Once a listener has formed a meaning representation of the context,
she cannot afford to again wait for the bottom-up input to activate phonological and semantic representations of upcoming words;
the uncertainty about the bottom-up information is persistent (see the phoneme restoration effect (\protect\hyperlink{ref-Warren1970}{Warren, 1970}), the McGurk effect (\protect\hyperlink{ref-McGurk1976}{McGurk \& MacDonald, 1976}), and the Ganong effect (\protect\hyperlink{ref-Ganong1980}{Ganong, 1980}) in speech perception).
Thus, once the listener has formed a representation of the context,
she uses this top-down information to predictively preactivate what the upcoming word can be.
Such predictive preactivation can take different forms:
it can be a probabilistic (graded) or deterministic (all-or-nothing) prediction.
These differences in the nature of prediction are discussed below.

\hypertarget{background-facilitatory-effect}{%
\subsection{Facilitatory effect of predictability}\label{background-facilitatory-effect}}

We have discussed above that individuals make predictions about not-yet-encountered linguistic units based on available context information as a sentence unfolds:
Top-down predictive and bottom-up perceptual processes interact dynamically in language comprehension.
When the bottom-up perceptual input is less reliable, for example, in an adverse listening condition, it has been shown that listeners rely more on top-down processes by narrowing down the predictions to smaller sets of semantic categories or words (\protect\hyperlink{ref-Corps2020}{Corps \& Rabagliati, 2020}; \protect\hyperlink{ref-Strauss2013}{Strauß et al., 2013}).
Obleser and colleagues (\protect\hyperlink{ref-Obleser2007}{Obleser et al., 2007}; \protect\hyperlink{ref-Obleser2010}{Obleser \& Kotz, 2010}), for instance, used sentences of two levels of semantic predictability (high and low) and systematically degraded speech signals by passing them through various numbers of noise-vocoding channels ranging from 1 to 32 in a series of behavioural and neuroimaging studies (see also \protect\hyperlink{ref-Hunter2018}{Hunter \& Pisoni, 2018}).
They found that semantic predictability facilitated language comprehension only at moderate levels of speech degradation.
That is, participants relied more on sentence context when the speech signal was degraded though \emph{intelligible enough} than when it was not degraded or highly degraded.
At such moderate levels of speech degradation, word recognition accuracy was found to be higher for words in high predictability sentences than the words in low predictability sentences (\protect\hyperlink{ref-Obleser2010}{Obleser \& Kotz, 2010}).
For the extremes, i.e., when the speech signal was highly degraded (making the speech almost entirely unintelligible) or when it was the least degraded (rendering the speech intelligible),
the word recognition accuracy was similar across both levels of sentence predictability, meaning that predictability did not facilitate language comprehension.
Sheldon et al. (\protect\hyperlink{ref-Sheldon2008b}{2008b}) estimated that for both younger and older adults, the number of noise-vocoding channels required to achieve 50\% accuracy varied as a function of sentence context.
A higher number of channels (i.e., more bottom-up information) was required in less constraining sentences to achieve the same level of accuracy as highly constraining sentences.
They also concluded that word recognition is facilitated by predictability and sentence context when the speech is degraded.
Taken together, these studies conclude that at moderate levels of degradation, participants rely more on the top-down predictions generated by a sentence context and less on the bottom-up perceptual processing of an unclear, less reliable, and degraded speech signal (\protect\hyperlink{ref-Obleser2014}{Obleser, 2014}).
However, these studies are agnostic about the nature of prediction, i.e., if it is probabilistic or deterministic.

\hypertarget{nature-of-prediction}{%
\subsubsection{Nature of prediction}\label{nature-of-prediction}}

\noindent
A debate in the literature on predictive language processing pertains to this question: Is prediction probabilistic, or is it an all-or-nothing phenomenon?
For instance, the garden path phenomenon was explained as a parser's irreversible prediction about the sentence structure;
if its predicted parsing fails (or if it turns out to be incorrect), then the parser reanalyzes the sentence and reformulates another prediction (e.g., \protect\hyperlink{ref-Ferreira1986}{Ferreira \& Clifton Jr, 1986}; see also \protect\hyperlink{ref-Demberg2013}{Demberg et al., 2013}; \protect\hyperlink{ref-Slattery2013}{Slattery et al., 2013}).
In recent days, the support for the probabilistic nature of prediction comes, for example, from ERP studies that show an inverse and graded relationship between the magnitude of the N400 effect evoked by a word and its predictability measured by cloze probability\footnote{Cloze probability of a word is the proportion of participants who provide that word as the next word of a sentence, in an offline norming task, given the preceding words of the sentence (\protect\hyperlink{ref-Staub2015a}{Staub et al., 2015}; \protect\hyperlink{ref-Taylor1953}{Taylor, 1953}). Its value ranges from 0 to 1.} (e.g., \protect\hyperlink{ref-Delong2005}{DeLong et al., 2005}; \protect\hyperlink{ref-Federmeier2007b}{K. D. Federmeier et al., 2007}), or \emph{surprisal}\footnote{Surprisal is a measure of the change in probability mass (or simply put, the change in expectation) as predictions are proven wrong with an encounter of new words in a sentence, discourse, etc. (\protect\hyperlink{ref-Hale2001}{Hale, 2001}; \protect\hyperlink{ref-Smith2008}{N. J. Smith \& Levy, 2008}).} (\protect\hyperlink{ref-Frank2015}{Frank et al., 2015}; cf. \protect\hyperlink{ref-Brothers2015}{Brothers et al., 2015}).

These discussions come from reading studies and spoken language comprehension in clear speech.
Although a few frameworks of language processing speculate that language comprehension in adverse listening conditions can be predictive (e.g., \protect\hyperlink{ref-Lowder2016}{Lowder \& Ferreira, 2016}; \protect\hyperlink{ref-Ryskin2018}{Ryskin et al., 2018}),
so far, only Strauß et al. (\protect\hyperlink{ref-Strauss2013}{2013}) have investigated the nature of prediction in degraded speech comprehension.
They proposed an ``expectancy searchlight model'', which suggests that listeners form \emph{narrowed expectations} from a restricted semantic space only when the sentence endings are highly predictable.
They rule out the graded nature of predictability.
However, their approach to predictability was confounded by verb-noun association
(discussed in Chapter \ref{chapter-graded-prediction}).
In contrast to their study, we systematically vary the predictability of the target word
and examine the graded vs probabilistic nature of prediction in degraded speech comprehension.
We argue that the facilitatory effect of predictability is graded in nature;
it is not an all-or-nothing phenomenon focused solely on highly predictable sentence endings.

\hypertarget{limits-of-pp}{%
\subsection{Limits of predictive language processing}\label{limits-of-pp}}

It is important to note and acknowledge that the ubiquity and universality of predictive language processing have not gone unquestioned (\protect\hyperlink{ref-Huettig2016}{Huettig \& Mani, 2016}).
Apart from the debate on the nature of prediction, which we will come to later in this chapter, there is compelling evidence that questions the necessity of prediction in language comprehension.
For example, Mishra et al. (\protect\hyperlink{ref-Mishra2012}{2012}) showed that literacy is a critical factor that limits listeners' predictions about an upcoming word.
In a visual world paradigm study, they found that individuals with lower literacy showed less anticipatory eye movements than those with higher literacy.
They bolstered their finding in a neuroimaging study claiming that learning to read fundamentally changes the neural circuitry (\protect\hyperlink{ref-Hervais2019}{Hervais-Adelman et al., 2019}).
It is, therefore, plausible that such structural change in the brain manifests in linguistic behaviour.
Similarly, Scholman et al. (\protect\hyperlink{ref-Scholman2020}{2020}) demonstrated that reading experience is predictive of readers' sensitivity to discourse signals available in the context for predictiong upcoming content.
Cognitive ageing is also reported as a limiting factor in generating predictions (\protect\hyperlink{ref-Federmeier2002}{K. Federmeier et al., 2002}; \protect\hyperlink{ref-Federmeier2010}{K. D. Federmeier et al., 2010}).
Another line of argument that critiques predictive processing comes from the observations of Huettig \& Guerra (\protect\hyperlink{ref-Huettig2019}{2019}).
They analyzed participants' anticipatory eye movements in the visual world paradigm and showed that listeners predict the target word only in an artificial setup --- long preview time (4000ms) and slow speech (cf. \protect\hyperlink{ref-Fernandez2020}{Fernandez et al., 2020}; \protect\hyperlink{ref-Heyselaar2021}{Heyselaar et al., 2021}).
When presented with a short preview time (1000ms), such anticipatory eye movements were not significant towards the picture of the target word.

In this thesis, we study additional top-down and bottom-up processes that can interact with and potentially limit the facilitatory effect of predictability.
For example, current theories of predictive processing are poor in explaining the role of \emph{attention} in semantic prediction (e.g., \protect\hyperlink{ref-Christiansen2015}{Christiansen \& Chater, 2015}; \protect\hyperlink{ref-Ferreira2016}{Ferreira \& Lowder, 2016}; \protect\hyperlink{ref-Friston2020b}{K. J. Friston, Sajid, et al., 2020}; \protect\hyperlink{ref-Kuperberg2016}{Kuperberg \& Jaeger, 2016}; \protect\hyperlink{ref-Pickering2018}{Pickering \& Gambi, 2018}).
For example, in their prediction-by-production account, Pickering \& Gambi (\protect\hyperlink{ref-Pickering2018}{2018}) emphasize that listeners use their speech production mechanism in speech perception and comprehension to predict what their interlocutor will say next.
Their framework attempts to paint a big picture of prediction --- using the motor system ---
but it does not consider how a listener's strategy of attending to only a part of a speech stream in adverse listening conditions influences linguistic predictions.
We argue that attention to context information is critical in forming semantic predictions,
especially in degraded speech comprehension (cf. \protect\hyperlink{ref-Kok2012}{Kok et al., 2012}).
By manipulating listeners' attention allocation to parts of a speech stream and information content in the sentences, we show that attention to context information is a prerequisite for the listeners to generate predictions.
We also investigate the effect of bottom-up processes, like speech rate, on top-down processes (i.e., predictability effect in degraded speech comprehension).
The extant findings on the effects of speech rate on the facilitatory effect of predictability have been mixed both in clear and degraded speech comprehension (e.g., \protect\hyperlink{ref-Aydelott2004}{Aydelott \& Bates, 2004}; \protect\hyperlink{ref-Goy2013}{Goy et al., 2013}; \protect\hyperlink{ref-Iwasaki2002}{Iwasaki et al., 2002}; \protect\hyperlink{ref-Winn2021}{M. B. Winn \& Teece, 2021}).
We demonstrate a scope for current theories of predictive language processing to incorporate
the instances of varying predictability effects at fast and slow speech rates and the effects of attention on degraded speech comprehension.

\hypertarget{background-adaptation}{%
\section{Adaptation to degraded speech}\label{background-adaptation}}

Listeners quickly adapt to novel speech with artificial acoustic distortions (\protect\hyperlink{ref-Dupoux1997}{Dupoux \& Green, 1997}).
Repeated exposure to distorted speech improves listeners' comprehension improves over time (\protect\hyperlink{ref-Guediche2014}{Guediche et al., 2014}; for reviews, see \protect\hyperlink{ref-Samuel2009}{Samuel \& Kraljic, 2009}).
When the noise condition, like speech degradation level, is constant throughout the experiment, listeners adapt to it, and the performance (e.g., word recognition) improves with as little as 20 minutes of exposure (\protect\hyperlink{ref-Rosen1999}{Rosen et al., 1999}).
For example, Davis et al. (\protect\hyperlink{ref-Davis2005}{2005}) presented listeners with 6-channel noise-vocoded speech and found an increase in the proportion of correctly reported words over the course of the experiment.
Similarly, Erb et al. (\protect\hyperlink{ref-Erb2013}{2013}) presented participants with 4-channel noise-vocoded speech and reached a similar conclusion.
In these experiments, only one speech degradation level (6- or 4-channel noise-vocoded speech) was presented in one block.
There was no uncertainty about the next-trial speech degradation from the participants' perspective.
In contrast to our study, semantic feature (i.e., target word predictability) was not varied.
When multiple types or levels of degraded speech signals are presented in a (pseudo-)randomized order within a block, a listener is uncertain about the signal quality of any upcoming trial.
This can influence perceptual adaptation such that
it might be totally absent with the change in the characteristics of the auditory signals throughout an experiment (\protect\hyperlink{ref-Mattys2012}{Mattys et al., 2012}).
In addition, trial-by-trial variability in the characteristics of distorted speech can impair word recognition (\protect\hyperlink{ref-Sommers1994}{Sommers et al., 1994}; see also \protect\hyperlink{ref-Dahan2006}{Dahan \& Magnuson, 2006}).
Only a limited number of studies have looked at how the (un)certainty about next-trial speech quality and semantic features influence adaptation.
For example, in a word-recognition task, Vaden et al. (\protect\hyperlink{ref-Vaden2013}{2013}) presented words at +3dB SNR and +10dB SNR in a pseudo-random order;
the goal was to minimize the certainty about the noise level within the block.
They report that the magnitude and coherence of the activity in the cingulo-opercular network facilitated comprehension of noisy speech in a subsequent trial,
however, we cannot make a firm conclusion about perceptual adaptation \emph{per se} from their studies as they do not report the performance change throughout the experiment.
Similarly, Obleser and colleagues (\protect\hyperlink{ref-Hartwigsen2015}{Hartwigsen et al., 2015}; \protect\hyperlink{ref-Obleser2007}{Obleser et al., 2007}; \protect\hyperlink{ref-Obleser2010}{Obleser \& Kotz, 2010}) also presented listeners with noise-vocoded sentences (ranging from 2 to 32 channels noise-vocoding) in a pseudo-randomized order but did not report the presence or absence of perceptual adaptation.
Their findings are primarily focused on the interaction of lexical-semantic and acoustic-phonetic cues in speech perception.
On the one hand, repeated exposure is shown to lead to perceptual adaptation to degraded speech.
On the other hand, uncertainty about speech quality is speculated to impair word recognition.
We argue that a trial-by-trial variation in a higher-level semantic feature of speech hinders listeners' perceptual system from retuning itself to adapt to the lower-level auditory features of the degraded speech (cf. \protect\hyperlink{ref-Nahum2008}{Nahum et al., 2008}).
In contrast to prior studies, we show that listeners do not adapt to degraded speech despite repeated exposure to the same degraded speech
as long as its semantic predictability is uncertain.

\hypertarget{summary}{%
\section{Summary}\label{summary}}

In this chapter, we provided an overview of the concepts that will be repeated in the following chapters.
We introduced the concept of speech distortion and degradation.
Digital signal processing methods used in this process will be discussed in Chapter \ref{chapter-methods} (Section \ref{speech-processing}).
Importantly, we provided an overview of how predictive language processing aids language comprehension,
as well as its limitations.
We discussed perceptual adaptation to degraded speech and the role of uncertainty about next-trial in adaptation.
At each step, we presented the motivation behind the studies in this thesis
and the gaps in the literature these studies fill in.
In the next chapter, we will discuss the methods that are common in all the experiments (Chapters 5, 6, and 7) in developing materials and collecting data.

\hypertarget{chapter-methods}{%
\chapter{General methods}\label{chapter-methods}}

\chaptermark{Methods}

This chapter provides an overview of the experimental materials used in the experiments described in Chapters 5, 6, and 7.
Sentences used as experimental material were common in all the experiments,
and the signal processing method was also common.
Here, we also present an overview of online data collection.

\hypertarget{experimental-materials}{%
\section{Experimental materials}\label{experimental-materials}}

As a part of a study in the research project A4 of SFB1102, sentences of different levels of predictability were created.
Digital recordings of the sentences were degraded by noise-vocoding and used in all experiments reported in this thesis.
The speech was also distorted by its compression and expansion.
Below we briefly describe how the sentences of different levels of predictability were obtained
and what methodology was used to create distorted versions of the speech.

\hypertarget{stimulus-sentences}{%
\subsection{Stimulus sentences}\label{stimulus-sentences}}

With an aim to create sentences of three levels of predictability (low, medium, and high), a triplet of 120 sentences --- a total of 360 sentences --- were created from 120 nouns.
Out of 120 nouns, 6 were repeated.
All sentences were in present tense consisting of pronoun, verb, determiner, and object.
These sentences were in Subject-Verb-Object form (e.g., \emph{Er fängt den Ball}. EN: He catches the ball.).
Some of these sentences were taken from Obleser \& Kotz (\protect\hyperlink{ref-Obleser2010}{2010}).
For each sentence, cloze probability ratings were collected from a group of young adults (n = 60; age range = 18 -- 30 years).
Mean cloze probabilities of low, medium and high probability sentences are shown in Table \ref{cloze-table} and
the distribution of cloze probability across low, medium, and high predictability sentences is shown in Figure \ref{fig:cloze-distribution}.
The cloze probabilities of the target words in each sentence are shown in Appendix A.

\begin{table}[ht]
\begin{center}
\caption{Cloze probabilities of high, medium and low predictability sentences} 
\label{cloze-table} 
\vskip 0.12in
\begin{tabular}{c c c}
\toprule
 & \multicolumn{2}{c}{Cloze probability} \\
\cmidrule(l){2-3}
Predictability & Mean $\pm$ SD & Range \\
\midrule
Low & 0.022 $\pm$ 0.027 & 0.00 – 0.09 \\
Medium & 0.274 $\pm$ 0.134 & 0.1 – 0.55 \\
High & 0.752 $\pm$ 0.123 & 0.56 – 1.00 \\
\bottomrule
\end{tabular}
\end{center}
\end{table}

\begin{figure}

{\centering \includegraphics[width=0.9\linewidth]{figures/materials/cloze-distribution} 

}

\caption{Distribution of cloze probability ratings of target words in low, medium and high predictability sentences}\label{fig:cloze-distribution}
\end{figure}

\hypertarget{speech-processing}{%
\subsection{Speech processing}\label{speech-processing}}

All 360 sentences were spoken by a female native speaker of German at a normal rate.
The recordings were digitized at 44.1kHz with 32-bit linear encoding.
Spoken sentences used in Chapters 5, 6, 7, and 8 were degraded by noise-vocoding.
In addition to degradation by noise-vocoding, the sentences were distorted by compression and expansion of speech signal in Chapter 7.

\hypertarget{noise-vocoding}{%
\subsubsection{Noise-vocoding}\label{noise-vocoding}}

Noise-vocoding is used to parametrically vary and control the speech quality in a graded manner.
It distorts a speech signal by dividing it into specific frequency bands corresponding to the number of vocoder channels.
The frequency bands are analogous to the electrodes of a cochlear implant (\protect\hyperlink{ref-Loizou1999}{Loizou et al., 1999}; \protect\hyperlink{ref-Shannon1995}{Shannon et al., 1995}; \protect\hyperlink{ref-Shannon2004}{Shannon et al., 2004}).
The amplitude envelope, i.e., the fluctuations of amplitude within each frequency band, is extracted, and the spectral information within it is replaced by noise.
This noise-filtering makes the vocoded speech difficult to understand, although its temporal characteristics and periodicity of perceptual cues are preserved (\protect\hyperlink{ref-Rosen1999}{Rosen et al., 1999}).

The spectral degradation conditions of 1, 4, 6, and 8 channels were achieved for each of the 360 recorded sentences using a customized script originally written by Darwin (\protect\hyperlink{ref-Darwin2005}{2005}) in Praat software (\protect\hyperlink{ref-Praat2001}{Boersma, 2001}).
The speech signal was divided into 1, 4, 6, and 8 frequency bands between 70 and 9,000Hz.
The boundary frequencies were approximately logarithmically spaced following cochlear-frequency position functions (\protect\hyperlink{ref-Erb2014}{Erb, 2014}; \protect\hyperlink{ref-Greenwood1990}{Greenwood, 1990}; \protect\hyperlink{ref-Rosen1999}{Rosen et al., 1999}).
The amplitude envelope of each band was extracted and applied to band-pass filtered white noise in the same frequency ranges;
the upper and lower bounds for band extraction are specified in Table \ref{frequencies}.
Modulated noise bands were then combined to produce a degraded speech.
Scaling was performed to equate the root-mean-square value of the original undistorted speech and the final degraded speech.
This resulted in four levels of degradation: 1-, 4-, 6-, and 8-channel noise-vocoded speech.

Spectrograms of clear speech and noise-vocoded speech for the sentence \emph{Er löest die Aufgabe} are shown in Figure \ref{fig:vocoding-spectrogram}. It shows that with a decrease in the number of noise-vocoding channels, the information in speech signal reduces and becomes noise-like.

\begin{figure}[!htpb]

{\centering \includegraphics[width=0.9\linewidth]{figures/materials/aufgabe_clear} \includegraphics[width=0.9\linewidth]{figures/materials/aufgabe_8bands} \includegraphics[width=0.9\linewidth]{figures/materials/aufgabe_6bands} \includegraphics[width=0.9\linewidth]{figures/materials/aufgabe_4bands} \includegraphics[width=0.9\linewidth]{figures/materials/aufgabe_1band} 

}

\caption{Spectrograms of clear speech, and degraded speech arranged with a decreasing number of noise-vocoding channels (8, 6, 4 and 1 band) for the sentence `Er löest die Aufgabe.' }\label{fig:vocoding-spectrogram}
\end{figure}

\begin{table}[H]
\begin{center}
\tiny
\caption{Boundary frequencies (in Hz) for 1, 4, 6 and 8 channels noise-vocoding conditions} 
\label{frequencies} 
\vskip 0.12in
\begin{tabular}{llllllllll} 
\hline
Number of channels     &    Boundary frequencies \\
\hline
1   &   70    &   9000   &     &     &       &       &        &       &   \\

4   &   70    &   423   &   1304  &   3504  &   9000    &       &        &       &   \\

6   &   70    &   268   &   633   &   1304  &   2539    &   4813    &    9000    &       &   \\

8   &   70    &   207   &   423   &   764   &   1304    &   2156    &    3504    &   5634    &   9000\\
\hline
\end{tabular} 
\end{center} 
\end{table}

The primary motivation to degrade speech signals by noise-vocoding is twofold:
On the practical side, noise-vocoding simulates the frequency selectivity with a cochlear implant or sensory-neural hearing loss.
This provides insight into speech perception and language comprehension in special populations (older adults with hearing loss, patients with cochlear implants).
On the experimental side, noise-vocoding preserves the temporal periodicity cues of the speech;
we can investigate the importance of specific suprasegmental cues in speech perception.
Noise-vocoding reduces the fine structure cues that carry the pitch-related suprasegmental information
and allows the study of temporal amplitude envelope cues, which carry the suprasegmental information involved in lexical processing;
noise-vocoding preserves these cues.
It also provides a control over speech intelligibility by varying the number of vocoder channels.

\hypertarget{compression-expansion}{%
\subsubsection{Speech compression and expansion}\label{compression-expansion}}

Temporal compression and expansion are used as a method to simulate fast and slow speech and
to study the effect of acoustic degradation (which is the change in speech rate) and increase or decrease in information flow.
As early as the mid-twentieth century, investigators have reported that intelligibility does not drop significantly when speech is speeded up to 2 times the normal speech rate (e.g., \protect\hyperlink{ref-Garvey1953}{Garvey, 1953}).
Speech rate was increased by chopping physical tapes.
Digital algorithms like the pitch-synchronous overlap-add technique (PSOLA, \protect\hyperlink{ref-Charpentier1986}{Charpentier \& Stella, 1986}; \protect\hyperlink{ref-Moulines1990}{Moulines \& Charpentier, 1990}) developed in the 1980s and later (e.g., \protect\hyperlink{ref-Verhelst1993}{Verhelst \& Roelands, 1993}) now allow us to speed up and slow down the speech rate in a controlled fashion.
In Chapter 7, we used Praat software that utilizes a uniform time-compression algorithm (PSOLA) to create slow and fast speech with the compression factor of 1.35 and 0.65, respectively.
A schematic representation of waveforms of different speech rates --- normal, slow and fast --- is shown in Figure \ref{fig:speech-rate}.

\begin{figure}[!htpb]

{\centering \includegraphics[width=0.9\linewidth]{figures/materials/aufgabe_fast} \includegraphics[width=0.9\linewidth]{figures/materials/aufgabe_normal} \includegraphics[width=0.9\linewidth]{figures/materials/aufgabe_slow} 

}

\caption{Schematic representation of waveforms of fast, normal, and slow speech rates for the sentence `Er löest die Aufgabe' with the duration of each speech rates in second. Note the circled portion of the waveform, which examplifies that PSOLA eliminates and duplicates the parts of the original waveform to create fast and slow speech respectively.}\label{fig:speech-rate}
\end{figure}

PSOLA creates fast or slow speech in three steps: analysis, modification, and synthesis (\protect\hyperlink{ref-Charpentier1986}{Charpentier \& Stella, 1986}; \protect\hyperlink{ref-Taleb2020}{Taleb, 2020}).
In the analysis step, it first sets pitch marks in an audio file and then creates segments of it
(i.e., it segments the signal into successive analysis windows centred around those pitch marks).
Then in the modification step, depending on the time-compression/expansion factor, it deletes (or duplicates) those segments and sets a new set of pitch marks.
Finally, in the synthesis step, it adds the new segments back to the audio file (i.e., it rearranges the analysis window) and creates fast or slow speech as required.
The distortion of phonemic properties of speech signals are minimal when accelerating and slowing down within the range of factor 2 or below (\protect\hyperlink{ref-Moulines1990}{Moulines \& Charpentier, 1990}; cf. \protect\hyperlink{ref-Longster2003}{Longster, 2003}).

We create fast and slow versions of 120 high and 120 low predictability sentences.
These 480 recordings are then passed through 4 channels noise-vocoding to use as experimental materials.
As discussed \protect\hyperlink{research-goals}{earlier}, the main aim of manipulating this bottom-up process is to investigate the effect of change in the rate of information flow (i.e., change in the speech rate) on the top-down processes of contextual facilitation in degraded speech comprehension.

\hypertarget{data-collection-on-the-web}{%
\section{Data collection on the web}\label{data-collection-on-the-web}}

Traditionally, behavioural experiments with human participants are conducted in a laboratory setup.
In recent years, there has been a surge of experiments that are conducted on the web (\protect\hyperlink{ref-Reips2021}{Reips, 2021}).
The first generation of online experiments to study human cognition began in the mid-1990s (for reviews, \protect\hyperlink{ref-Musch2000}{Musch \& Reips, 2000}) with the advent of the internet (\protect\hyperlink{ref-Bernerslee1992}{Berners-Lee et al., 1992}).
Welch \& Krantz (\protect\hyperlink{ref-Welch1996}{1996}) was the first online experiment that was conducted in 1995 as a part of tutorials in auditory perception (\protect\hyperlink{ref-Musch2000}{Musch \& Reips, 2000}).
In their survey of researchers, Musch \& Reips (\protect\hyperlink{ref-Musch2000}{2000}) discovered that until 2000, there were already at least two psycholinguistics experiments conducted online,
one of which studied the effect of context in shallow vs deep encoding of words.
Despite the difficulty in conducting online experiments and scepticism of journals towards publishing results of online experiments,
Musch \& Reips (\protect\hyperlink{ref-Musch2000}{2000}) expressed optimism:

\begin{quote}
At the moment, the number of Web experiments is still small, but a rapid growth can be predicted on the basis of the present results.
We would not be surprised if within the next few years, a fair proportion of psychological experiments will be conducted on the Web. (p.~85)
\end{quote}

By 2022, there has been significant growth in online experiments as technical and technological barriers are greatly reduced.
There are many software and online platforms which psychologists and psycholinguists can use with minimal knowledge of computer programming
to design, host and run their experiments and retrieve these data in a fairly structured format (\protect\hyperlink{ref-Anwylirvine2020}{A. L. Anwyl-Irvine et al., 2020}; \protect\hyperlink{ref-Peirce2019}{Peirce et al., 2019}; \protect\hyperlink{ref-Prolific}{Prolific, 2014}; see also, \protect\hyperlink{ref-Anwylirvine2021}{A. Anwyl-Irvine et al., 2021}; \protect\hyperlink{ref-Eyal2021}{Eyal et al., 2021}).
Online experiments have demonstrated advantages over laboratory experiments (\protect\hyperlink{ref-Gadiraju2017}{Gadiraju et al., 2017}; \protect\hyperlink{ref-Johnson2021}{Johnson et al., 2021}).
For example, a large pool of participants is available online, which is usually not possible in laboratory experiments.
Similarly, the participants in online experiments are more diverse than in laboratory experiments.
Considering these advantages, psychologists and psycholinguists have conducted online experiments for almost three decades.
Scientists who only conducted laboratory experiments and occasional online experiments were forced to conduct their experiments almost exclusively on the web due to the restrictions imposed by covid-19 lockdown (\protect\hyperlink{ref-Gagne2021}{Gagné \& Franzen, 2021}; \protect\hyperlink{ref-Reips2021}{Reips, 2021}).
Since Welch \& Krantz (\protect\hyperlink{ref-Welch1996}{1996})'s auditory perception experiment, a number of experiments have been conducted online in the auditory domain (\protect\hyperlink{ref-Leensen2013}{Leensen \& Dreschler, 2013}; \protect\hyperlink{ref-Seow2022}{Seow \& Hauser, 2022}; \protect\hyperlink{ref-vanOs2021}{van Os et al., 2021}; \protect\hyperlink{ref-Woods2017}{Woods et al., 2017}) replicating laboratory findings (e.g., \protect\hyperlink{ref-Cooke2021}{Cooke \& Garcia Lecumberri, 2021}).
The experiments reported in this thesis were also conducted online.

Initially, our experiments were designed to be conducted both in the laboratory and online.
As the laboratory was shut down due to covid-19 pandemic-related lockdown (M. Schmitt, personal communication, March 16, 2020), we moved the laboratory experiments to the online platform.
We recruited participants online via Prolific Academic (\protect\hyperlink{ref-Prolific}{Prolific, 2014}).
We used Prolific's filters to recruit only native speakers of German residing in Germany
who reported not having any hearing loss, speech-language disorder, or cognitive impairment.
Participants were redirected to the experiments that were designed and hosted in Lingoturk (\protect\hyperlink{ref-Pusse2016}{Pusse et al., 2016}).
Lingoturk is a local hosting platform that manages crowdsourcing experiments --- it runs the experiments and stores the data.
We report the details of each experiment in Chapters 5, 6, and 7.

\hypertarget{chapter-stats}{%
\chapter{General statistical approach}\label{chapter-stats}}

\chaptermark{Statistics}

\hypertarget{linear-mixed-effects-models}{%
\section{Linear mixed effects models}\label{linear-mixed-effects-models}}

As the name suggests, the linear mixed effects model (LME) is a linear regression model that consists of both fixed and random effects.
It allows modelling the underlying structure of the data, which includes
the standard fixed effects like the levels of speech degradation and the levels of target word predictability,
as well as random effects like items and participants.
These random effects are assumed to be random samples drawn from the general population.
In this thesis, the dependent variable (an \emph{outcome} or a \emph{response} variable) is binary (correct vs incorrect response).
So, we use binomial logistic mixed effects models with crossed random effects to model the data (\protect\hyperlink{ref-Baayen2008}{Baayen et al., 2008}).

A linear mixed effects model can be written as:

\begin{align} \label{eq:mixed-effects1}
y = \alpha + u_{\alpha} + w_{\alpha} +
    (\beta_{1} + u_{\beta_{1}} + w_{\beta_{1}})\cdot {x_1} + \nonumber\\
    (\beta_{2} + u_{\beta_{2}} + w_{\beta_{2}})\cdot {x_2} + ... + \nonumber\\
    (\beta_{n} + u_{\beta_{n}} + w_{\beta_{n}})\cdot {x_n} 
\end{align}

where,

\begin{itemize}
\tightlist
\item
  \(y\) is the dependent variable, like participant's response (correct vs.~incorrect)
\item
  \(\alpha\) is the Intercept.
\item
  Fixed effects: \(\beta_{1}, \beta_{2}, ..., \beta_{n}\) are the coefficients (or effects) of \(x_1, x_2, ...,x_n\).
\item
  \(\boldsymbol{u} = \langle u_{\alpha}, u_{\beta_1}, u_{\beta_2}, ..., u_{\beta_n} \rangle\) : Varying intercept and slopes for random effect term like, \emph{subject}.
\item
  \(\boldsymbol{w} = \langle w_{\alpha}, w_{\beta_1}, w_{\beta_2}, ..., w_{\beta_n} \rangle\) : Varying intercept and slopes for random effect term like, \emph{item}.
\end{itemize}

In contrast to linear regression models, mixed effects models allow to simultaneously account for the effects of two random variables, like item and participants.
The variance in the categorical dependent variable is also preserved, which would otherwise be eliminated by averaging in linear regression models.
We discuss these issues and the motivation to use the mixed effects model in this thesis in more detail below in this chapter.

\hypertarget{linear-regression-and-its-limitations}{%
\subsection{Linear regression and its limitations}\label{linear-regression-and-its-limitations}}

In linear regression, a dependent variable (or an \emph{outcome}) is modelled as a function of one or more independent predictor variables (\emph{factors} or \emph{explanatory} variables).
That is, an outcome \(y\) is modelled as a function of explanatory variables \(x_1, x_2, x_3..., x_n\), and an error term \(\varepsilon\).

\begin{align} \label{eq:linear-regression}
y =
\alpha + 
\beta_{1}\cdot{x_1} + 
\beta_{2}\cdot{x_2} + ... +
\beta_{n}\cdot{x_n} + \varepsilon 
\end{align}

Analysis of Variance (ANOVA), also a form of linear regression (\protect\hyperlink{ref-Chatterjee2012}{Chatterjee \& Hadi, 2012}; \protect\hyperlink{ref-Vasishth2022}{Vasishth et al., 2022}), compares the means and variances of two or more conditions.
As expressed in Equation \eqref{eq:linear-regression}, regression models can only model fixed effects.
Although ANOVA can account for one random effect at a time, it still averages out the variance in the second random effect.
These problems of using ANOVA in language sciences have been pointed out as early as the 1960s (\protect\hyperlink{ref-Clark1973}{H. H. Clark, 1973}; \protect\hyperlink{ref-Coleman1964}{Coleman, 1964}).
We elaborate on them in the context of the data of our experiments as follows.

\hypertarget{modeling-two-random-effects-simultaneously-and-variability-in-the-data}{%
\subsubsection{Modeling two random effects simultaneously, and Variability in the data}\label{modeling-two-random-effects-simultaneously-and-variability-in-the-data}}

As mentioned above, a simple linear regression model, including ANOVA, does not model the effect of two random effects simultaneously, which a mixed effects model does.
In the traditional ANOVA approach, researchers often run two separate regression models (\protect\hyperlink{ref-Lorch1990}{Lorch \& Myers, 1990}) by averaging raw data across participants, and items.
Averaging eliminates the variability in the data.
Additionally, comparing the means of a categorical variable (correct vs incorrect responses) even when transformed into accuracy or proportion scale is hard to interpret sensibly compared to a continuous variable like reaction time (for discussion, see \protect\hyperlink{ref-Bolker2009}{Bolker et al., 2009}; \protect\hyperlink{ref-Jaeger2008}{Jaeger, 2008}).
The statistical remedy for these problems in analyzing the data of our experiments is to apply mixed effects models.

\hypertarget{non-independence-of-observations}{%
\subsubsection{Non-independence of observations}\label{non-independence-of-observations}}

Some of the assumptions made for regression models are violated in our data.
One of them is the non-independence of observations, i.e., all data points are independent of one another.
This assumption is violated in an unbalanced design, and sometimes even for a balanced design.
The same participant responds to multiple trials of the same experimental condition within an experiment.
Although the design itself is balanced, after the removal of outliers and trials which are not appropriate for comprehension measures (for details, see Section \ref{chapter-6-measurement}),
the number of trials in the analysis is unequal for each participant, item, and experimental condition.
This inequality or unbalance introduces a bias in the regression model (\protect\hyperlink{ref-Jaeger2008}{Jaeger, 2008}).
A mixed effects model is best suited for such unbalanced data.

\hypertarget{common-mean-for-each-predictor}{%
\subsubsection{Common mean for each predictor}\label{common-mean-for-each-predictor}}

An intrinsic property or feature of the linear regression model is that it assumes a common mean for each predictor.
It has been shown that this is, in fact, not true in the actual data:
the effect of a predictor can vary depending on random variables like participant or item.
Mixed effects models take into account such inter-participant and inter-item variability present in the data.
For example, in mixed effects models,
the random effects term with only varying intercept, e.g., participant as an intercept, assumes that if there are 100 participants, then the mean accuracy of those 100 participants is only a subset of possible global accuracies drawn from a set of the population mean.
When a slope, e.g., levels of predictability, is included in the random effects structure in addition to the varying intercept (e.g., participants), then the model assumes that the effect of predictability on response accuracy varies across participants.
Such variance across participants (or across items) is present in the real data
and can be modelled in a mixed effects model but not in a linear regression model.

\hypertarget{bounded-output-variable}{%
\subsubsection{Bounded output variable}\label{bounded-output-variable}}

Linear models assume an output variable to not be bounded within a narrow range and to be on a continuous scale.
In our data, the output variable (correct vs incorrect response) has bounded outcomes on \([0,1]\).
To fit a linear model, it can be transformed into a proportion scale.
Even though it is a continuous variable, the proportion scale (i.e., response accuracy) has a range (0,1).
Additionally, the transformation of discrete variables brings a host of problems that we have already discussed above (e.g., loss of variability by averaging raw data).
Binomial logistic mixed effects models, on the other hand, transform\footnote{Such transformation is brought about by a generalized linear mixed effects model with a canonical logit link function (\protect\hyperlink{ref-Malik2020}{Malik et al., 2020}).} the output variable into a \emph{logit} scale, \(\log\) with base \(e\), i.e.~\(\ln\), with a range \((-\infty, +\infty)\).
Therefore, these mixed effects models do not violate the model assumptions regarding the range of the outcome variables.

Thus, Equation \eqref{eq:mixed-effects1} can also be written as:

\begin{align} \label{eq:mixed-effects2}
\ln (\frac{p}{1-p}) = \alpha + u_{\alpha} + w_{\alpha} +
                      (\beta_{1} + u_{\beta_{1}} + w_{\beta_{1}})\cdot {x_1} + \nonumber\\
                      (\beta_{2} + u_{\beta_{2}} + w_{\beta_{2}})\cdot {x_2} + \nonumber\\
                      ... + (\beta_{n} + u_{\beta_{n}} + w_{\beta_{n}})\cdot {x_n} 
\end{align}

This is equivalent to,

\begin{align} \label{eq:logit-to-prob}
p = {\frac{exp(\ln(\frac{p}{1-p}))}{1 + exp (\ln(\frac{p}{1-p}))}}
\end{align}

where,

\begin{align} \label{eq:logiteq}
\ln(\frac{p}{1-p}) =
{logit}(p)
\end{align}

Log-odds of correct response obtained from Equation \eqref{eq:mixed-effects2} can also be transformed into the probability of correct response.
Equations \eqref{eq:logit-to-prob} and \eqref{eq:logiteq} provide the relationship between probability, logits (or log-odds), and odds (\(\frac{p}{1-p}\)).

We have presented the advantages of mixed effects models over linear (regression) models.
We use the binomial logistic mixed effects model as the statistical analysis tool in all experiments reported in this thesis.
Below we discuss how the model that best fits our data was selected.

\hypertarget{analysis-main}{%
\section{Model selection and Running mixed effects models in R}\label{analysis-main}}

The underlying structure of given data can be explained by different approximate statistical models.
We intend to select a model that best fits our data.
`Best fit' can be objectively measured by Akaike Information Criterion, Bayesian Information Criterion, and Likelihood Ratio Test, among others (\protect\hyperlink{ref-Akaike1973}{Akaike, 1973}; \protect\hyperlink{ref-Schwarz1978}{Schwarz, 1978}).

In this thesis,
we first build a complex (or maximal) model by including all predictors (target word predictability, speech degradation level, speech rate),
their interactions, and co-variates (e.g., trial number) in the fixed effects (cf. \protect\hyperlink{ref-Bondell2010}{Bondell et al., 2010}).
The model is fitted with a maximal random effects structure that includes random intercepts for each participant and item (\protect\hyperlink{ref-Barr2013}{Barr et al., 2013}).
By-participant and by-item slopes included in the model are discussed in the Analysis sections of Chapters 5, 6, and 7.

Model selection was based on the backward-selection heuristics on the fixed effects (cf. \protect\hyperlink{ref-Matuschek2017}{Matuschek et al., 2017}).
To find the best fitting model for the data,
non-significant higher-order interactions were excluded from the fixed-effects structure in a stepwise manner.
Similarly, random effects not supported by the data that explained zero variance according to singular value decomposition were excluded to prevent overparameterization (\protect\hyperlink{ref-Bates2015a}{Bates, Kliegl, et al., 2015}).
This gave a more parsimonious model, which was then extended separately with: i) item-related correlation parameters, ii) participant-related correlation parameters, and iii) both item- and participant-related correlation parameters.
Among the parsimonious model and extended models,
the model with the smallest AIC was selected as the best fitting model for our data (\protect\hyperlink{ref-Grueber2011}{Grueber et al., 2011}; \protect\hyperlink{ref-Richards2011}{Richards et al., 2011}).

Data preprocessing and analyses were performed in R-Studio (Version 3.6.1; R Core Team, 2019; Version 3.6.3; R Core Team 2020; Version 4.1.3; R Core Team, 2022).
Accuracy was analyzed with Generalized Linear Mixed Models (GLMMs) with lmerTest (\protect\hyperlink{ref-Kuznetsova2017}{Kuznetsova et al., 2017}) and lme4 (\protect\hyperlink{ref-Bates2015}{Bates, Mächler, et al., 2015}) packages.
Binary responses (correct responses coded as 1 and incorrect responses coded as 0) for all participants were fit with a binomial logistic mixed effects model.
Contrast coding of each factor and the model description are presented in the Analysis section of the chapters that follow.

\hypertarget{summary-1}{%
\section{Summary}\label{summary-1}}

In this chapter, we introduced the statistical tool used for data analysis in this thesis.
We discussed the limitations of traditional linear regression-based models like ANOVA
and outlined the motivations for using mixed effects models.
To capture the variability of our data without averaging out across participants or items,
and to account for the effect of two (or more) random effects --- participant and item --- simultaneously,
we fit mixed effects models to our data.\\
Details of each dataset corresponding to each experiment are presented in Chapters 5, 6, and 7.

\hypertarget{chapter-attention-prediction}{%
\chapter{Predictability effects of degraded speech are reduced as a function of attention}\label{chapter-attention-prediction}}

\chaptermark{Attention-prediction interplay}

In adverse listening conditions, when the bottom-up perceptual input is degraded, listeners tend to rely upon context information and form top-down semantic predictions,
which provides contextual facilitation in understanding the degraded speech.
Importantly, it is also affected by the allocation of attention to the context in a top-down manner.
The aim of this study was to examine the role of attention in understanding linguistic information in an adverse listening condition, i.e., when the speech was degraded.
To assess the role of attention, we varied task instructions in two experiments in which participants were instructed to listen to short sentences and thereafter to type in the last word they heard or to type in the whole sentence.
We were interested in how these task instructions influence the interplay between top-down predictions and bottom-up perceptual processes during language comprehension.
The sentences varied in the degree of predictability (low, medium, and high) as well as in the levels of speech degradation (1-, 4-, 6-, and 8-channel noise-vocoding).
Results indicated better word recognition for highly predictable sentences for moderate, though not for high, levels of speech degradation, but only when attention was directed to the whole sentence.

\hypertarget{introduction}{%
\section{Introduction}\label{introduction}}

When there is noise in the signal,
listeners overcome the difficulty of understanding speech by using context information.
The `context information' can be information in a given situation about a topic of conversation, semantic and syntactic information of a sentence structure, world knowledge, visual information, or even information about neighbouring phonemes (\protect\hyperlink{ref-Altmann2007}{Altmann \& Kamide, 2007}; \protect\hyperlink{ref-Kaiser2004}{Kaiser \& Trueswell, 2004}; \protect\hyperlink{ref-Knoeferle2005}{Knoeferle et al., 2005}; \protect\hyperlink{ref-Xiang2015}{Xiang \& Kuperberg, 2015}; for reviews, see \protect\hyperlink{ref-Ryskin2021}{Ryskin \& Fang, 2021}; \protect\hyperlink{ref-Stilp2020}{Stilp, 2020}).
For example, in the \emph{phoneme restoration effect} (\protect\hyperlink{ref-Samuel1996}{Samuel, 1996}; \protect\hyperlink{ref-Warren1970}{Warren, 1970}), a phoneme of one or more words in a sentence is replaced with white noise or a coughing sound.
Participants are unable to notice such `noisy' words in a sentence, as they perceptually restore the missing sound in those words from the context information.
To utilize the context information in a sentence, listeners must attend to it and build a meaning representation of what has been said.

Processing and comprehending degraded speech is more effortful and requires more attentional resources than clear speech (\protect\hyperlink{ref-Eckert2016}{Eckert et al., 2016}; \protect\hyperlink{ref-Hunter2018}{Hunter \& Pisoni, 2018}; \protect\hyperlink{ref-Peelle2018}{Peelle, 2018}; \protect\hyperlink{ref-Wild2012}{Wild et al., 2012}).
In this chapter, we examine how attention modulates the predictability effects brought about by context information at different levels of spectral degradation of speech.
We address the existing unclarity in the literature regarding the distribution of attentional resources in an adverse listening condition:
On the one hand, listeners can attend throughout the whole stream of speech and may thereby profit from the context information to predict sentence endings.
On the other hand, listeners can focus their attention on linguistic material at a particular time point in the speech stream and, as a result, miss critical parts of the sentence context.
If the goal is to understand a specific word in an utterance, there is a trade-off between allocating attentional resources to the perception of that word and allocating resources also to understanding the linguistic context and generating predictions.

The study reported in this chapter was conducted to investigate how the allocation of attentional resources induced by different task instructions influences language comprehension and, in particular, the use of context information in communication through a noisy channel, i.e., when the speech is degraded.
To examine the role of attention on predictive processing under degraded speech, we ran two experiments in which we manipulated the task instructions.
In \protect\hyperlink{experiment1a}{Experiment 1}, participants were instructed to repeat only the final word of the sentence they heard,
while in \protect\hyperlink{experiment1b}{Experiment 2}, they were instructed to repeat the whole sentence, drawing attention to the entire sentence, including the context.
In both experiments, we varied the degree of predictability of sentence endings as well as the degree of speech degradation.

\hypertarget{background}{%
\section{Background}\label{background}}

As we have discussed earlier in \protect\hyperlink{chapter-introduction}{Chapters 1} and \protect\hyperlink{chapter-background}{2}, it is generally agreed upon that human language processing is predictive in nature,
and comprehenders generate expectations about upcoming linguistic materials based on the context available to them (for reviews, see \protect\hyperlink{ref-Kuperberg2016}{Kuperberg \& Jaeger, 2016}; \protect\hyperlink{ref-Nieuwland2019}{Nieuwland, 2019}; \protect\hyperlink{ref-Pickering2018}{Pickering \& Gambi, 2018}; \protect\hyperlink{ref-Staub2015}{Staub, 2015}).
When the bottom-up speech signal is less informative in an adverse listening condition, listeners tend to rely more on top-down lexical-semantic cues from the context to support speech perception and language comprehension (\protect\hyperlink{ref-Amichetti2018}{Amichetti et al., 2018}; \protect\hyperlink{ref-Ganong1980}{Ganong, 1980}; \protect\hyperlink{ref-McGurk1976}{McGurk \& MacDonald, 1976}; \protect\hyperlink{ref-Obleser2010}{Obleser \& Kotz, 2010}; \protect\hyperlink{ref-Sheldon2008b}{Sheldon et al., 2008b}; \protect\hyperlink{ref-Warren1970}{Warren, 1970}).
However, it is not just the quality of speech signal that determines and influences the reliance and use of predictive processing;
attention to the auditory input is essential too.
Auditory attention allows a listener to focus on the speech signal of interest (for reviews, see \protect\hyperlink{ref-Fritz2007}{Fritz et al., 2007}; \protect\hyperlink{ref-Lange2013}{Lange, 2013}).
For instance, a listener can attend to and derive information from one stream of sound among many competing streams, as demonstrated in the well-known \emph{cocktail party effect} (\protect\hyperlink{ref-Cherry1953}{Cherry, 1953}; \protect\hyperlink{ref-Hafter2007}{Hafter et al., 2007}).
When a participant is instructed to attend to only one of the two or more competing speech streams in a diotic or dichotic presentation, response accuracy to the attended speech stream is higher than to the unattended speech (e.g., \protect\hyperlink{ref-Toth2020}{Tóth et al., 2020}).
Similarly, when a listener is presented with a stream of tones (e.g., musical notes varying in pitch, pure tones of different harmonics) but attends to any one of the tones appearing at a specified time point, this is reflected in a larger amplitude of N1\footnote{N1 or N100 is a negative-going EEG component that peaks around 100 ms post-stimulus. It is considered as a neural marker of auditory selective attention (\protect\hyperlink{ref-Naatanen1987}{Näätänen \& Picton, 1987}; \protect\hyperlink{ref-Thornton2007}{Thornton et al., 2007}).} (e.g., \protect\hyperlink{ref-Lange2010}{Lange \& Röder, 2010}; see also, \protect\hyperlink{ref-Sanders2008}{Sanders \& Astheimer, 2008}).
Hence, listeners can draw attention to and process one among multiple competing speech streams,
as well as orient their attention in the temporal dimension within an unfolding sound stream.

So far, most previous studies have investigated listeners' attention within a single speech stream using acoustic cues like accentuation and prosodic emphasis.
For example, J. Li et al. (\protect\hyperlink{ref-Li2014}{2014}) examined whether the comprehension of critical words in a sentence context was influenced by a linguistic attention probe such as ``ba'' presented together with an accented or a de-accented critical word.
The N1 amplitude was larger for words with such an attention probe than for words without a probe.
These findings support the view that attention can be flexibly directed either by instructions towards a specific signal or by linguistic probes (\protect\hyperlink{ref-Li2017}{X. Li et al., 2017}; see also \protect\hyperlink{ref-Brunelliere2019}{Brunellière et al., 2019}).
Thus, listeners are able to select a part or segment of a stream of auditory stimuli to selectively allocate their attention to.

The findings on the interplay of attention and prediction mentioned above come from studies, most of which used a stream of clean speech or multiple streams of clean speech in their experiments.
They are not informative about the attention-prediction interplay in degraded speech comprehension.
Specifically, we do not know what role attention to a segment of the speech stream plays in the contextual facilitation of degraded speech comprehension.
The studies that report predictability effects in degraded speech comprehension do not systematically examine the role of attention (e.g., \protect\hyperlink{ref-Amichetti2018}{Amichetti et al., 2018}; \protect\hyperlink{ref-Obleser2010}{Obleser \& Kotz, 2010}; \protect\hyperlink{ref-Sheldon2008b}{Sheldon et al., 2008b}).
Their conclusion that \emph{semantic predictability facilitates comprehension of degraded speech} is based on listeners' attention to the entire sentence,
which is not compared to any other experimental condition manipulating attentional allocation.
Therefore, in two experiments, we examined whether context-based semantic predictions are automatic during effortful listening to degraded speech when participants are instructed to report either only the final word of the sentence or the entire sentence.
We varied the task instructions to the listeners from \protect\hyperlink{experiment1a}{Experiment 1} to \protect\hyperlink{experiment1b}{Experiment 2}, which required them to differentially attend to the target word not binding the context or including the context.
We hypothesized that when listeners pay attention only to the contextually predicted target word, they do not form top-down predictions, i.e., there should not be a facilitatory effect of target word predictability.
In contrast, when listeners attend to the whole sentence, they do form expectations such that the facilitatory effect of target word predictability will be observed replicating the prior behavioural findings (e.g., \protect\hyperlink{ref-Obleser2010}{Obleser \& Kotz, 2010}).

\hypertarget{experiment1a}{%
\section{Experiment 1}\label{experiment1a}}

This experiment was designed such that processing the context was not strictly necessary for the task.
Listeners were asked to report the noun of the sentence that they heard, which was in the final position of the sentence.
This instruction did not require listeners to pay attention to the context which preceded the target word.

\hypertarget{methods}{%
\subsection{Methods}\label{methods}}

\hypertarget{participants}{%
\subsubsection{Participants}\label{participants}}

We recruited 50 participants online via Prolific Academic (\protect\hyperlink{ref-Prolific}{Prolific, 2014}).
One participant whose response accuracy was less than 50\% across all experimental conditions was removed.
Among the remaining 49 participants (\(M\) age \(\pm SD=23.31\pm 3.53\) years; age range = 18-30 years), 27 were male, and 22 were female.
All participants were native speakers of German and did not have any speech-language disorder, hearing loss, or neurological disorder (all self-reported).
All participants received 6.20 Euro as monetary compensation for their participation in the approximately 40 minutes long experiment.

\hypertarget{materials}{%
\subsubsection{Materials}\label{materials}}

Materials used in the experiment were created by the method described in Chapter \ref{chapter-methods} (Section \ref{experimental-materials}).
That is, there were 120 unique sentences in each of these three categories: low predictability, medium predictability and high predictability.
Mean cloze probabilities of the target words of low, medium and high predictability sentences were \(0.022\pm0.027\) (\(M\pm SD\); range = 0.00-0.09), \(0.274\pm0.134\) (\(M\pm SD\); range = 0.1-0.55), and \(0.752\pm0.123\) (\(M\pm SD\); range = 0.56-1.00) respectively.
All 360 sentences were then noise-vocoded through 1, 4, 6, and 8 channels to create degraded speech.

\hypertarget{procedure}{%
\subsubsection{Procedure}\label{procedure}}

Participants were asked to use headphones or earphones.
A sample of vocoded speech not used in the practice trial or the main experiment was provided so that the participants could adjust the volume to their preferred level of comfort at the beginning of the experiment.
The participants were instructed to listen to the sentences and type in the target word (noun) using the keyboard.
The time for typing in the response was not limited.
They were informed at the beginning of the experiment that some of the sentences would be `noisy' and not easy to understand.
In these cases, guessing was encouraged.
Eight practice trials with different levels of speech degradation were given to familiarize the participants with the task before presenting all 120 experimental trials with an intertrial interval of 1,000 ms.

Each participant had to listen to 40 high predictability, 40 medium predictability, and 40 low predictability sentences.
Levels of speech degradation were also balanced across each predictability level so that for each of the three predictability conditions (high, medium, and low predictability), ten 1-channel, ten 4-channel, ten 6-channel, and ten 8-channel noise-vocoded sentences were presented, resulting in 12 experimental lists.
The sentences in each list were pseudo-randomized so that no more than three sentences of the same degradation and predictability condition appeared consecutively.
The lists are presented in Appendix B.

\hypertarget{analyses}{%
\subsection{Analyses}\label{analyses}}

Out of 5880 trials from 49 participants, there were only five correct responses, one each from 5 participants at 1-channel.
Therefore, the 1-channel speech degradation condition was excluded from the analyses.

Accuracy was analyzed using Generalized Linear Mixed Models (GLMMs) following the procedure described in Chapter \ref{chapter-stats} (Section \ref{analysis-main}) with lmerTest (\protect\hyperlink{ref-Kuznetsova2017}{Kuznetsova et al., 2017}) and lme4 (\protect\hyperlink{ref-Bates2015}{Bates, Mächler, et al., 2015}) packages.
Binary responses (categorical: correct and incorrect) for all participants were fit with a \protect\hyperlink{binomial-logistic-mixed-effects-model}{binomial linear mixed-effects model}.
Correct responses were coded as 1, and incorrect responses were coded as 0.
Number of channels (categorical: 4-channel, 6-channel, and 8-channel noise-vocoding), target word predictability (categorical: high predictability sentences, medium predictability sentences, low predictability sentences), and the interaction of number of channels and target word predictability were included in the fixed effects.

We fitted a model with a maximal random effects structure that included random intercepts for each participant and item (\protect\hyperlink{ref-Barr2013}{Barr et al., 2013}).
Both by-participant and by-item random slopes were included for number of channels, target word predictability, and their interaction,
which was supported by the experiment design.
Based on the previous findings on perceptual adaptation (e.g., \protect\hyperlink{ref-Cooke2022}{Cooke et al., 2022}; \protect\hyperlink{ref-Davis2005}{Davis et al., 2005}; \protect\hyperlink{ref-Erb2013}{Erb et al., 2013}), we further added trial number (centred) in the fixed effect structure to control for whether the listeners adapted to the degraded speech.
We applied treatment contrast for number of channels (8-channel as a baseline) and sliding difference contrast for target word predictability (low predictability vs medium predictability and low predictability vs high predictability).

\hypertarget{results-and-discussion}{%
\subsection{Results and discussion}\label{results-and-discussion}}

Mean response accuracies (in percentage) for all experimental conditions aggregated across all participants and items are shown in Table \ref{summary1a} and Figure \ref{fig:figure1a}.
It shows that accuracy increases with an increase in the number of noise-vocoding channels, i.e., with the decrease in speech degradation.
However, accuracy does not increase with an increase in target word predictability.
These observations aligned with the results of the statistical analyses (Table \ref{results1a}).

\begin{longtable}[]{@{}lllc@{}}
\caption{Response accuracy (mean and standard error of the mean) across all levels of speech degradation and target word predictability in Experiment 1}
\label{summary1a}
\tabularnewline
\toprule
Number of channels & Target word predictability & Mean & Standard
error \\
\midrule
\endfirsthead
\toprule
Number of channels & Target word predictability & Mean & Standard
error \\
\midrule
\endhead
4 & High & 62.65 & 2.24 \\
& Medium & 63.43 & 2.03 \\
& Low & 63.99 & 1.83 \\
\midrule
6 & High & 95.60 & 0.94 \\
& Medium & 95.54 & 1.05 \\
& Low & 95.16 & 1.10 \\
\midrule
8 & High & 98.16 & 0.84 \\
& Medium & 96.75 & 1.04 \\
& Low & 97.91 & 0.97 \\
\bottomrule
\end{longtable}

\begin{figure}

{\centering \includegraphics[width=0.95\linewidth]{figures/results-fig/expt-1a} 

}

\caption{Mean response accuracy across all conditions in Experiment 1. Accuracy increased only with an increase in the number of noise-vocoding channels. There is no change in accuracy with an increase or decrease in target word predictability. Error bars represent the standard error of the means.}\label{fig:figure1a}
\end{figure}

There was a significant main effect of number of channels, indicating that response accuracy for the 8-channel vocoded speech was higher than for both
4-channel (\(\beta\) = -3.50, SE = .22, \emph{z}(4,410) = -16.19, \emph{p} \textless{} .001)
and 6-channel vocoded speech (\(\beta\) = -.70, SE = .21, \emph{z}(4,410) = -3.29, \emph{p} = .001),
that is, when the number of channels increased to 8, listeners gave more correct responses (see Figure \ref{fig:figure1a}).
There was, however, no significant main effect of target word predictability
(\(\beta\) = .30, SE = .36, \emph{z}(4,410) = .84, \emph{p} = .40, and \(\beta\) = .50,SE = .43, \emph{z}(4,410) = 1.16, \emph{p} = .25),
and no interaction between number of channels and target word predictability (all \emph{p}s \textgreater{} .05).
There was also no significant main effect of trial number
(\(\beta\) = .001, SE = .002, \emph{z}(4,410) = .48, \emph{p} = .63) suggesting that the listeners' performance did not improve over time.
These results indicated a decrease in response accuracy with an increase in speech degradation from the 8-channel to the 6-channel noise-vocoding condition and from the 8-channel to the 4-channel noise-vocoding condition.
However, response accuracy did not increase with an increase in target word predictability, and the interaction between number of channels and target word predictability was also absent,
in contrast to previous findings (e.g., \protect\hyperlink{ref-Obleser2007}{Obleser et al., 2007}; \protect\hyperlink{ref-Obleser2011}{Obleser \& Kotz, 2011}; see also \protect\hyperlink{ref-Hunter2018}{Hunter \& Pisoni, 2018}).
These results suggest that the task instruction, which asked participants to report only the final word, indeed led to neglecting the context.
Although participants were able to neglect the context, there was still uncertainty about the speech quality of each subsequent trial;
hence, they could not adapt to the different levels of degraded speech.

To confirm that the predictability effect (or contextual facilitation) is replicable and dependent on attentional focus, we conducted a second experiment in which we changed the task instruction to draw participants' attention to decoding the whole sentence.

\begin{table}[ht]
\begin{center}
\caption{Estimated effects of the model accounting for the correct word recognition in Experiment 1}
\label{results1a} 
\vskip 0.12in
\begin{tabular}[]{@{}lrrrr@{}}
\toprule
Fixed effects & Estimate & Std. Error & \emph{z} value & \emph{p}
value \\
\midrule
Intercept & 4.17 & .25 & 16.73 & \textless.001 \\
\\
Noise condition (4-channel) & -3.50 & .22 & -16.19 & \textless.001 \\
\\
Noise condition (6-channel) & -.70 & .21 & -3.29 & \textless.001 \\
\\
Target word predictability (Low-Medium) & .30 & .36 & .84 & .40 \\
\\
Target word predictability (High-Low) & .50 & .43 & 1.16 & .25 \\
\\
Noise condition (4-channel) $\times$ & -.22 & .39 & -.57 & .57 \\
Target word predictability (Low-Medium) \\
\\
Noise condition (6-channel) $\times$ & -.34 & .44 & -.76 & .44 \\
Target word predictability (Low-Medium) \\
\\
Noise condition (4-channel) $\times$ & -.54 & .45 & -1.18 & .24 \\
Target word predictability (High-Low) \\
\\
Noise condition (6-channel) $\times$ & .04 & .50 & .09 & .03 \\
Target word predictability (High-Low) \\
\\
Trial number & .001 & .002 & .48 & .63 \\
\bottomrule
\end{tabular} 
\end{center} 
\end{table}

\hypertarget{experiment1b}{%
\section{Experiment 2}\label{experiment1b}}

Following up on Experiment 1, we conducted Experiment 2 on a separate group of participants with a different task instruction.
This experiment was intended to test the hypothesis that the facilitatory effect of top-down predictions is observed only when the listeners' attention is unrestricted so that the context information is also included within the listener's attentional focus.

\hypertarget{methods-1}{%
\subsection{Methods}\label{methods-1}}

\hypertarget{participants-and-materials}{%
\subsubsection{Participants and Materials}\label{participants-and-materials}}

We recruited a new group of 48 participants (\(M\) age \(\pm SD = 24.44 \pm 3.5\) years; age range = 18-31 years; 32 males) online via Prolific Academic.
The same stimuli were used as in Experiment 1.

\hypertarget{procedure-1}{%
\subsubsection{Procedure}\label{procedure-1}}

Participants were presented with sentences at a comfortable volume level.
They were asked to use headphones or earphones, and a prompt was presented before the experiment began to adjust the volume to their level of comfort.
Eight practice trials were presented, followed by 120 experimental trials.
In contrast to Experiment 1, the participants were instructed to report the entire sentence, instead of reporting only the sentence-final word, by typing in what they heard.
We did not limit the response time.

\hypertarget{analyses-1}{%
\subsection{Analyses}\label{analyses-1}}

We followed the same data analysis procedure as in Experiment 1.
The 1-channel speech degradation condition was excluded from the analysis.
For the analysis and results of the two experiments to be comparable,
we did not consider whether listeners reported other words in a sentence correctly;
only the final words of the sentences (target words) were considered as either correct or incorrect responses.
As in Experiment 1, we report the results from the maximal model supported by the design.

\hypertarget{results-and-discussion-1}{%
\subsection{Results and discussion}\label{results-and-discussion-1}}

Mean response accuracy for different conditions is shown in Table \ref{summary1b} and Figure \ref{fig:figure1b}.
We found that accuracy increased when the number of noise-vocoding channels increased, as well as when the target word predictability increased.
The results of the statistical analysis confirmed these observations (Table \ref{results1b}).

\begin{longtable}[]{@{}lllc@{}}
\caption{Response accuracy (mean and standard error of the mean) across all levels of speech degradation and target word predictability in Experiment 2}
\label{summary1b}
\tabularnewline
\toprule
Number of channels & Target word predictability & Mean & Standard
error \\
\midrule
\endfirsthead
\toprule
Number of channels & Target word predictability & Mean & Standard
error \\
\midrule
\endhead
4 & High & 62.71 & 2.14 \\
& Medium & 59.58 & 1.88 \\
& Low & 58.13 & 1.88 \\
\midrule
6 & High & 96.88 & 0.93 \\
& Medium & 92.29 & 1.21 \\
& Low & 91.46 & 1.12 \\
\midrule
8 & High & 98.54 & 0.86 \\
& Medium & 95.21 & 1.19 \\
& Low & 95.00 & 1.23 \\
\bottomrule
\end{longtable}

\begin{figure}

{\centering \includegraphics[width=0.95\linewidth]{figures/results-fig/expt-1b} 

}

\caption{Mean response accuracy across all conditions in Experiment 2. Accuracy increased with an increase in number of noise-vocoding channels and target word predictability. Error bars represent the standard error of the means.}\label{fig:figure1b}
\end{figure}

We again found a main effect of number of channels, such that response accuracy at 8-channel was higher than for both 4-channel
(\(\beta\) = -3.51, SE = .24, \emph{z}(4,320) = -14.64, \emph{p} \textless{} .001),
and 6-channel noise-vocoding (\(\beta\) = -.65, SE = .22, \emph{z}(4,320) = -2.93, \emph{p} = .003).
Similar to Experiment 1, the main effect of trial number was not significant
(\(\beta\) = .002, SE = .002, \emph{z}(4,320) = 1.11, \emph{p} = .27) indicating that the response accuracy did not increase over the course of the experiment.

In contrast to Experiment 1, there was also a main effect of target word predictability: Response accuracy in high predictability sentences was significantly higher than in low predictability sentences
(\(\beta\) = 1.42, SE = .47, \emph{z}(4,320) = 3.02, \emph{p} = .003).
We also found a statistically significant interaction between speech degradation and target word predictability
(\(\beta\) = -1.14, SE = .50, \emph{z}(4,320) = -2.30, \emph{p} = .02).
Subsequent subgroup analyses of each channel condition showed that the interaction was driven by the difference in response accuracy between high predictability sentences and low predictability sentences
in the 8-channel (\(\beta\) = 1.42, SE = .62, \emph{z}(1,440) = 2.30, \emph{p} = 0.02)
and 6-channel noise-vocoding conditions (\(\beta\) = 1.14, SE = 0.34, \emph{z}(1,440) = 3.31, \emph{p} \textless{} .001);
at 4 channel, the difference in response accuracy between high and low predictability sentences was not significant
(\(\beta\) = .28, SE = .18, \emph{z}(1,440) = 1.59, \emph{p} = .11).

In contrast to Experiment 1, these results indicate an effect of target word predictability;
that is, response accuracy was higher when the target word predictability was high as compared to low.
Also, the interaction between target word predictability and speech degradation, which was not observed in Experiment 1,
showed that semantic predictability facilitated the comprehension of degraded speech already at moderate levels (like 6- or 8-channel).
In line with the findings from Experiment 1, response accuracy was better with a higher number of channels.

\begin{table}[ht]
\begin{center}
\caption{Estimated effects of the model accounting for the correct word recognition in Experiment 2}
\label{results1b} 
\vskip 0.12in
\begin{tabular}[]{@{}lrrrr@{}}
\toprule
Fixed effects & Estimate & Std. Error & \emph{z} value & \emph{p}
value \\
\midrule
Intercept & 4.09 & .24 & 16.79 & \textless.001 \\
\\
Noise condition (4-channel) & -3.51 & .24 & -14.64 & \textless.001 \\
\\
Noise condition (6-channel) & -.65 & .22 & -2.93 & .003 \\
\\
Target word predictability (Low-Medium) & -.08 & .34 & -.23 & .82 \\
\\
Target word predictability (High-Low) & 1.42 & .47 & 3.02 & .003 \\
\\
Noise condition (4-channel) $\times$ & .02 & .38 & .05 & .96 \\
Target word predictability (Low-Medium) \\
\\
Noise condition (6-channel) $\times$ & -.13 & .43 & -.31 & .76 \\
Target word predictability (Low-Medium) \\
\\
Noise condition (4-channel) $\times$ & -1.14 & .50 & -2.30 & .02 \\
Target word predictability (High-Low) \\
\\
Noise condition (6-channel) $\times$ & -.23 & .57 & -.41 & .68 \\
Target word predictability (High-Low) \\
\\
Trial number & .002 & .002 & 1.11 & .27 \\
\bottomrule
\end{tabular} 
\end{center} 
\end{table}

We combined the data from both experiments in a single analysis to test whether participants' response accuracy changes across the experiments,
that is, to test whether the difference between experimental manipulations is statistically significant.
We ran a binomial linear mixed-effects model on response accuracy and followed the same procedure as in Experiments 1 and 2.
A full random effects structure supported by the study design was modelled.
The model summary is shown in Table 6.
The model revealed no significant main effect of experimental group
(\(\beta\) = .04, SE = .26, \emph{z}(8,730) = .15, \emph{p} = .88), indicating that the overall response accuracy did not change with the change in instructions from Experiment 1 to Experiment 2.
However, the critical interaction between experimental group and target word predictability was statistically significant
(\(\beta\) = .46, SE = .20, \emph{z}(8,730) = 2.34, \emph{p} = .02).
That is, the effect of predictability was larger in the group that was asked to type in the whole sentence (Experiment 2) than in the group that was asked to type only the sentence-final target word (Experiment 1).
Together, these findings suggest that the change in task instruction, which draws attention either to the entire sentence or only to the final word, is critical to whether the context information is used under degraded speech.
Nonetheless, degraded speech comprehension is not reduced by binding listeners' attention allocation to one part of the speech stream.
The model summary is shown in Table \ref{results1ab}.

\begin{table}[h!]
\begin{center}
\caption{Estimated effects of the best-fitting model accounting for the correct word recognition in both experiments}
\label{results1ab} 
\vskip 0.12in
\begin{tabular}[]{@{}lrrrr@{}}
\toprule
Fixed effects & Estimate & Std. Error & \emph{z} value & \emph{p}
value \\
\midrule
Intercept & 4.19 & .20 & 20.72 & \textless.001 \\
\\
Noise condition (4-channel) & -3.56 & .20 & -18.19 & \textless.001 \\
\\
Noise condition (6-channel) & -.59 & .18 & -3.28 & .001 \\
\\
Target word predictability (Low-Medium) & .13 & .26 & .50 & .62 \\
\\
Target word predictability (High-Low) & .98 & .34 & 2.93 & \textless.003 \\
\\
Experimental group & .04 & .26 & .15 & .88 \\
\\
Noise condition (4-channel) $\times$ & -.12 & .29 & -.40 & .69 \\
Target word predictability (Low-Medium) \\
\\
Noise condition (6-channel) $\times$ & -.30 & .34 & -.87 & .38 \\
Target word predictability (Low-Medium) \\
\\
Noise condition (4-channel) $\times$ & -.84 & .35 & -2.42 & .02 \\
Target word predictability (High-Low) \\
\\
Noise condition (6-channel) $\times$ & -.11 & .38 & -.29 & .77 \\
Target word predictability (High-Low) \\
\\
Noise condition (4-channel) $\times$ & -.10 & .25 & -.41 & .68 \\
Experimental group \\
\\
Noise condition (6-channel) $\times$ & -.10 & .28 & -.36 & .72 \\
Experimental group \\
\\
Target word predictability (High-Low) $\times$ & -.47 & .20 & 2.34 & .02 \\
Experimental group \\
\\
Trial number & .001 & .001 & .93 & .35 \\
\bottomrule
\end{tabular} 
\end{center} 
\end{table}

\hypertarget{conclusion}{%
\section{Conclusion}\label{conclusion}}

The main goals of the present study were to investigate whether online semantic predictions are formed in comprehension of degraded speech when task instructions encourage attention to the processing of the context information or only to the critical target word.
The results of two experiments revealed that attentional processes clearly modulate the use of context information for predicting sentence endings when the speech signal is degraded.

In contrast to the first experiment, the results of the second experiment show an interaction between target word predictability and degraded speech.
This is in line with existing studies that found a facilitatory effect of predictability at different levels of speech degradation when the participants were instructed to pay attention to the entire sentence (e.g., \protect\hyperlink{ref-Obleser2007}{Obleser et al., 2007}).
Obleser and colleagues reported that at the 8-channel noise-vocoded speech, key word recognition\footnote{Notice the difference in measurement metrics. Obleser et al. (\protect\hyperlink{ref-Obleser2007}{2007}) calculated response accuracy as the number of correct keywords identified, while we calculated it as the correct identification of the sentence-final target word.} was higher in high predictability sentences than in low predictability sentences.
Listeners were required to attend to the entire sentence in those studies as well.
Therefore, the findings of Experiment 2 replicate this facilitatory effect of predictability that was observed in Obleser and colleagues' behavioural experiments.

The important new finding that our study adds to the present literature is that this effect of semantic predictability (i.e., contextual facilitation of degraded speech comprehension) may be weakened or lost when listeners are instructed to report only the final word of the sentence that they heard (Experiment 1).
The lack of predictability effect (or contextual facilitation) can most likely be attributed to listeners not successfully decoding the meaning of the verb of the sentence, as the verb is the primary predictive cue in our stimuli (e.g., Sie \emph{jongliert} die Bälle) for the target word (noun: \emph{Bälle}).
Findings from auditory attention literature also support this explanation:
When listeners' attention is focused on one feature of an auditory stimulus and the rest are not attended to, then they are not accessed (filter mechanism, \protect\hyperlink{ref-Lange2013}{Lange, 2013}; change detection, \protect\hyperlink{ref-Sanford2006}{Sanford et al., 2006}; \protect\hyperlink{ref-Sturt2004}{Sturt et al., 2004})

Hence, this small change in task instructions from Experiment 1 to Experiment 2 sheds light on the role of top-down attenion regulation in using context for language comprehension in adverse listening conditions.
In a noisy channel created by degraded speech, language comprehension is generally effortful, so focusing attention on only a part of the speech signal seems beneficial in order to enhance stimulus decoding.
However, the results of this study also show that this comes at the cost of neglecting the context information that could be beneficial for language comprehension.
Our findings hence demonstrate that there is a trade-off between the use of context for generating top-down predictions vs focusing all attention on a target word.
Specifically, the engagement in the use of context and generation of top-down predictions may change as a function of attention (see also \protect\hyperlink{ref-Li2014}{J. Li et al., 2014}).
This claim is also corroborated by the significant change in predictability effects (or contextual facilitation) from Experiment 1 to Experiment 2 in the combined dataset.

Findings from the irrelevant-speech paradigm also support our conclusion.
It has been shown that the predictability of unattended speech has no effect on the main experimental task (e.g., memorization of auditorily presented digits).
Wöstmann \& Obleser (\protect\hyperlink{ref-Wostmann2016}{2016}) did not find predictability effects when the participants ignored the degraded speech (see also \protect\hyperlink{ref-Ellermeier2015}{Ellermeier et al., 2015}).
An alternative explanation of `participants neglecting the context' could be that the participants did not listen to the context at all,
or they heard but did not process the context.
However, irrelevant-speech paradigm studies show that listeners cannot avoid listening to the speech presented to them;
to-be-ignored speech has been shown to interfere with the main experimental task (e.g., \protect\hyperlink{ref-LeCompte1995}{Lecompte, 1995}).
It is not implausible that the listeners listened to the context but did not do deep processing (cf. \protect\hyperlink{ref-Ferreira2016}{Ferreira \& Lowder, 2016}).
This is not incompatible with our first explanation, as in either case, attention to the final word leaves the listeners with limited resources to process and form a representation of the context information.

Considering the theoretical accounts of predictive language processing (\protect\hyperlink{ref-Friston2020}{K. J. Friston, Parr, et al., 2020}; \protect\hyperlink{ref-Kuperberg2016}{Kuperberg \& Jaeger, 2016}; \protect\hyperlink{ref-Mcclelland1986}{McClelland \& Elman, 1986}; \protect\hyperlink{ref-Norris2016}{Norris et al., 2016}; \protect\hyperlink{ref-Pickering2018}{Pickering \& Gambi, 2018}), one would expect that listeners automatically form top-down predictions about upcoming linguistic stimuli based on prior context.
Also, when speech is degraded, top-down predictions render a benefit in word recognition and language comprehension (e.g., \protect\hyperlink{ref-Sheldon2008a}{Sheldon et al., 2008a}, \protect\hyperlink{ref-Sheldon2008b}{2008b}).
Results of our study revealed new theoretical insights by showing that this is not always the case.
Top-down predictions are dependent on attentional processes (see also \protect\hyperlink{ref-Kok2012}{Kok et al., 2012}), directed by task instructions;
thus, they are not \emph{always} automatic, and predictability does not \emph{always} facilitate comprehension of degraded speech.
To this point, our findings shed light on the growing body of literature indicating limitations of predictive language processing accounts (\protect\hyperlink{ref-Huettig2019}{Huettig \& Guerra, 2019}; \protect\hyperlink{ref-Huettig2016}{Huettig \& Mani, 2016}; \protect\hyperlink{ref-Mishra2012}{Mishra et al., 2012}; \protect\hyperlink{ref-Nieuwland2018}{Nieuwland et al., 2018}).

Results from both experiments show that the effect of trial number is not significant.
In contrast to previous studies (e.g., \protect\hyperlink{ref-Davis2005}{Davis et al., 2005}; \protect\hyperlink{ref-Erb2013}{Erb et al., 2013}), we did not observe adaptation to noise-vocoded speech.
In those studies, there was certainty about the speech quality of the next trial, as the participants were presented with only one level of spectral degradation (only 4-channel or only 6-channel noise-vocoding)
and crucially with no specific regard to semantic predictability.
On the contrary, in our study, listeners were always uncertain about the speech quality of the next trial as well as its semantic predictability.
Because of this changing context, the perceptual system of the participants may not retune itself (\protect\hyperlink{ref-Goldstone1998}{Goldstone, 1998}; \protect\hyperlink{ref-Mattys2012}{Mattys et al., 2012}).
However, there was no experimental condition in the current study in which participants were certain about the next-trial speech degradation.
It cannot be discarded entirely that certainty about speech degradation would retune the perceptual system,
and listeners would adapt to the degraded speech.
This is one of the limitations of the current study.

One could object to the metric of calculating accuracy in Experiment 2,
but it should be noted that for a valid comparison of the results between the two experiments,
we can only consider the accuracy of the sentence-final target word in Experiment 2.
Participants' response of the words preceding the sentence-final target word in Experiment 1 was not available;
in fact, it was the whole point of the instruction given to the participants:
Direct their attention only to the sentence-final target word but not to the words preceding it.
Hence, we find a discrepancy between the result of prior studies (\protect\hyperlink{ref-Obleser2007}{Obleser et al., 2007}; \protect\hyperlink{ref-Obleser2010}{Obleser \& Kotz, 2010}) and our study (Experiment 2)
regarding the degradation level at which contextual facilitation is observed.
Nonetheless, the conclusion from these studies and our study is consistent:
as long as listeners attend to the sentence context, semantic context facilitates language comprehension,
but, such a facilitatory effect is not observed when the degradation is at an extreme level, like 1-channel noise-vocoding.

In conclusion, this study provides a novel insight into the modulatory role of attention in the interaction between top-down predictive and bottom-up auditory processes.
We show that task instructions affect the distribution of attention to the degraded speech signal.
This, in turn, means that when insufficient attention is given to the context, top-down predictions cannot be generated, and the facilitatory effect of predictability is substantially reduced.
The findings of this study indicate limitations to predictive processing accounts of language comprehension.

\hypertarget{summary-2}{%
\section{Summary}\label{summary-2}}

This chapter reported studies which replicated the previous finding that semantic predictability facilitates language comprehension
when speech degradation is not at an extreme level.
That is, when the channel of transmission \(N\) is noisy,
listeners put less weight on the degraded auditory input \(P(u_p|u_i,N)\) and
more weight on the prior \(P(u_i|m_i)\) derived from the context information that facilitates language comprehension.
Importantly,
we showed in this chapter that contextual facilitation (i.e., facilitatory effect of predictability) is observed only when the listeners attend to the entire sentence, including the context.
In the next chapter, we further investigate this effect;
specifically, we examine the granularity of the predictability effect at moderate levels of speech degradation.
We also examine whether (un)certainty about next-trial speech degradation and predictability influences perceptual adaptation to degraded speech.

\hypertarget{chapter-graded-prediction}{%
\chapter{Semantic predictability facilitates comprehension of degraded speech in a graded manner}\label{chapter-graded-prediction}}

\chaptermark{Graded effect of predictability}

In the previous chapter, we concluded that in a noisy channel, predictability facilitates comprehension of degraded speech only when listeners attend to the context.
We also pointed out a few limitations of the study.
In Experiment \protect\hyperlink{experiment1b}{2} of Chapter \ref{chapter-attention-prediction}, there was an implicit assumption that all the noun-correct responses were borne out of correctly identifying the context-evoking words (i.e., verbs).
For a comparable analysis and results between Experiments 1 and 2, we only considered the accuracy of noun identification.
In this chapter, we take into account listeners' identification of context (i.e., a verb that precedes the noun) while calculating the response accuracy.
Importantly, we replicated the predictability effects in degraded speech comprehension reported in the previous chapter, showing a difference between comprehension of high and low predictability sentences.
In this chapter, we extend it further and examine if the predictability is graded or all-or-nothing.
We only showed that listeners do not adapt to degraded speech when there is a trial-by-trial variability in speech degradation.
Here we report two experiments investigating if listeners' adaptation to degraded speech is affected by such variability by comparing it against another condition in which speech degradation is kept constant.
The results showed that in contrast to the ``narrowed expectations'' view postulated for the predictive processing of degraded speech,
listeners probabilistically preactivate upcoming words from a wide range of semantic space, not limiting only to the highly probable sentence endings.
We also did not find any learning effect on repeated exposure to degraded speech.
We speculate that when there is a trial-by-trial variation in semantic feature (e.g., sentence predictability), listeners do not adapt to low-level perceptual property (e.g., speech quality) regardless of the certainty about the degradation level.

\hypertarget{introduction-1}{%
\section{Introduction}\label{introduction-1}}

In the literature on speech perception and sentence processing, studies have argued that prediction is either probabilistic and graded or all-or-nothing (e.g., \protect\hyperlink{ref-Coltheart2004}{Coltheart, 2004}; \protect\hyperlink{ref-Kuperberg2016}{Kuperberg \& Jaeger, 2016}; \protect\hyperlink{ref-Luke2016}{Luke \& Christianson, 2016}).
Few studies have investigated such theoretical questions within the domain of adverse listening conditions, specifically in degraded speech comprehension (e.g., \protect\hyperlink{ref-Corps2020}{Corps \& Rabagliati, 2020}; \protect\hyperlink{ref-Strauss2013}{Strauß et al., 2013}; cf. \protect\hyperlink{ref-vanOs2021}{van Os et al., 2021}).
Strauß et al. (\protect\hyperlink{ref-Strauss2013}{2013}) posit that listeners cannot preactivate less predictable sentence endings in an adverse listening condition.
They propose that the facilitatory effect of predictability is limited to only highly predictable sentence endings at a moderate level of spectral degradation of speech.
Although many studies support the general idea of Strau\ss~and colleagues that predictability facilitates comprehension of degraded speech (e.g., \protect\hyperlink{ref-Hunter2018}{Hunter \& Pisoni, 2018}; \protect\hyperlink{ref-Obleser2010}{Obleser \& Kotz, 2010}; \protect\hyperlink{ref-Sheldon2008a}{Sheldon et al., 2008a}),
there have been no studies so far after Strau\ss~and colleagues, to our knowledge, which examined the nature of predictability specifically in degraded speech comprehension.

In this chapter, our main aim is to attempt a replication of the previous findings of these predictability effects
and extend them further by testing if listeners form narrowed expectations while listening to moderately degraded speech.
In line with Strauß et al. (\protect\hyperlink{ref-Strauss2013}{2013})'s argument, listeners can form predictions that are restricted to only highly probable sentence endings.
On the opposite, listeners can generate expectations about an upcoming word based on how likely the word is to appear in the given context
and hence form a probabilistic prediction.
We also test the presence of perceptual adaptation and its interplay with contextual facilitation.
We set a metric of measurement of language comprehension that considers whether listeners correctly identified the context information.

\hypertarget{background-1}{%
\section{Background}\label{background-1}}

\hypertarget{predictability-effects-in-degraded-speech-perception}{%
\subsection{Predictability effects in degraded speech perception}\label{predictability-effects-in-degraded-speech-perception}}

We discussed in Chapter \ref{chapter-background} (Section \ref{background-facilitatory-effect})
that some studies (\protect\hyperlink{ref-Obleser2007}{Obleser et al., 2007}; \protect\hyperlink{ref-Obleser2010}{Obleser \& Kotz, 2010}; \protect\hyperlink{ref-Sheldon2008a}{Sheldon et al., 2008a}; see also \protect\hyperlink{ref-Hunter2018}{Hunter \& Pisoni, 2018}) have already shown the facilitatory effect of predictability in comprehension of degraded speech.
For example, Obleser and colleagues compared high and low predictability sentences and observed contextual facilitation, in terms of the difference in response accuracy between high and low predictability sentences, at 8- and 4-channel noise-vocoded speech in their (\protect\hyperlink{ref-Obleser2007}{2007}) and (\protect\hyperlink{ref-Obleser2010}{2010}) studies, respectively.
However, these neuroimaging studies were not designed to test the nature of predictability effects.

In a modified experimental design, Strauß et al. (\protect\hyperlink{ref-Strauss2013}{2013}) varied the target word predictability by manipulating its expectancy (i.e., how expected the target word is given the verb) and typicality (i.e., co-occurrence of the target word and the preceding verb).
They reported that at a moderate level of spectral degradation, N400 responses at highly predictable (strong-context and high-typical) words were the smallest.
In contrast, they found that the N400 effect (in terms of the amplitude of the N400 component) was largest at the strong-context, low typical words and the weak-context, low-typical words;
the responses at the latter two were not statistically different from each other.
The authors interpreted these findings as a facilitatory effect of sentence predictability which might be limited to only highly predictable sentence endings at a moderate level of spectral degradation.
They proposed it as an \emph{expectancy searchlight model} and suggested that listeners form \emph{narrowed expectations} from a restricted semantic space when the sentence endings are highly predictable.
Their model posits that when the sentence endings are less predictable, listeners cannot preactivate those less predictable sentence endings in an adverse listening condition, namely, a severe spectral degradation.
It is similar to the earlier observations made by Rayner et al. (\protect\hyperlink{ref-Rayner2006}{2006}; see \protect\hyperlink{ref-Brothers2021}{Brothers \& Kuperberg, 2021} for discussion), who found that reading times at low and medium predictability words were shorter than high predictability words,
but it is contrary to the view that readers and listeners form a probabilistic prediction of an upcoming word in a sentence.
For example, Nieuwland et al. (\protect\hyperlink{ref-Nieuwland2018}{2018})\footnote{However, Nieuwland et al.~(2018) could not replicate DeLong et al.~(2005)'s finding that comprehenders predict word-form. The N400 effect at the English articles \emph{a/an} were not replicable.} showed in a large-scale replication study of DeLong et al. (\protect\hyperlink{ref-Delong2005}{2005}) that the N400 amplitude at the sentence-final noun is directly proportional to its cloze probability across a range of high- and low-cloze words (see also \protect\hyperlink{ref-Kochari2019}{Kochari \& Flecken, 2019}; \protect\hyperlink{ref-Nicenboim2020}{Nicenboim et al., 2020}).
Heilbron et al. (\protect\hyperlink{ref-Heilbron2022}{2022}) also showed that a probabilistic prediction model outperforms a constrained guessing model in predicting listeners' neural activities (MEG and EEG recordings).
They suggested that linguistic prediction is probabilistic, and it is not limited only to the highly predictable sentence endings, but operates broadly in a wide range of probable sentence endings.
However, when put in perspective with our research question, these studies were conducted in conditions without noise or degraded speech.
Furthermore, the ones that examined degraded speech comprehension used only two levels of semantic predictability (high and low).
The granularity and the nature of prediction remain to be tested in degraded speech comprehension.

\hypertarget{adaptation-to-degraded-speech}{%
\subsection{Adaptation to degraded speech}\label{adaptation-to-degraded-speech}}

We discussed in Chapter \ref{chapter-background} that studies have shown evidence for perceptual adaptation to artificially distorted speech.
When exposed to noise-vocoded speech, listeners' word recognition accuracy is shown to increase over the course of the experiment.
Davis et al. (\protect\hyperlink{ref-Davis2005}{2005}) and Erb et al. (\protect\hyperlink{ref-Erb2013}{2013}) presented participants with 4- and 6-channel noise-vocoded speech in a single block.
They found that the proportion of correctly reported words increased over the course of the experiment.
It is important to note that in these experiments, listeners were not uncertain about the speech quality of any upcoming trial,
i.e., the \emph{global channel context} was certain or predictable.
Additionally, there was no systematic variation in the semantic features of the words presented to the participants.

Listeners gradually map the representation of degraded lexicons around their ``true'' (or clear) schema/exemplars on repeated exposure (\protect\hyperlink{ref-Goldstone1998}{Goldstone, 1998}; \protect\hyperlink{ref-Nosofsky1986}{Nosofsky, 1986}).
With repeated exposure, the representation of degraded input comes closer to the exemplar, thereby improving the performance.
This feature-mapping mechanism proposes that the listeners map the whole feature of the sensory input.
However, the higher level features of a speech (e.g., semantic property, like predictability) can also influence the acoustic realization of a degraded word,
i.e., bottom-up processing of the degraded speech and perceptual adaptation (\protect\hyperlink{ref-Gold2010}{Gold \& Watanabe, 2010}; \protect\hyperlink{ref-Goldstone1998}{Goldstone, 1998}; cf. \protect\hyperlink{ref-Nahum2008}{Nahum et al., 2008}).
Listeners can assign weight to different dimensions of speech stimuli (acoustic-phonetic and lexical-semantic).
Performance improves over time when listeners give more attentional weight to the acoustic-phonetic dimension (cf. \protect\hyperlink{ref-Haider1996}{Haider \& Frensch, 1996}).

Thus, when multiple levels of degraded speech signals are presented in a (pseudo-)randomized order, then the listener is uncertain about the speech quality of any upcoming trial, i.e., the \emph{global channel context} is certain or predictable.
Such changes in the auditory features of the speech signal throughout the experiment are likely to render the perceptual adaptation totally absent (\protect\hyperlink{ref-Mattys2012}{Mattys et al., 2012}).
Additionally, the trial-by-trial variability in the characteristics of speech signals can also impair word recognition (\protect\hyperlink{ref-Sommers1994}{Sommers et al., 1994}; see also \protect\hyperlink{ref-Dahan2006}{Dahan \& Magnuson, 2006}).
Very few studies have tried to study the influence of (un)certainty about next-trial speech quality and semantic feature in perceptual adaptation.
For example, in a study by Vaden et al. (\protect\hyperlink{ref-Vaden2013}{2013}), participants were presented with words in background noise at +3dB SNR and +10dB SNR in a pseudo-random order.
They argued that an adaptive control system is involved to optimize task performance when there is uncertainty about the next trial.
Similarly, Obleser and colleagues (\protect\hyperlink{ref-Hartwigsen2015}{Hartwigsen et al., 2015}; \protect\hyperlink{ref-Obleser2007}{Obleser et al., 2007}; \protect\hyperlink{ref-Obleser2010}{Obleser \& Kotz, 2010}) also presented listeners with multiple noise-vocoded speech (ranging from 2 to 32 channels noise-vocoding) in a pseudo-random order.
However, none of these studies reported a change in listeners' performance over the course of the experiment.
So, we cannot derive a conclusion from these studies about the effect of (un)certainty of the \emph{global channel context} in perceptual adaptation and contextual facilitation.

As previously mentioned in Chapter \ref{chapter-background} (Section \ref{background-adaptation}), there are two conflicting findings in the literature on perceptual adaptation:
On the one hand, repeated exposure to degraded speech leads to perceptual adaptation, consequently improving word recognition throughout the experiment.
On the other hand, uncertainty about the next-trial speech quality is detrimental to word recognition.

\hypertarget{chapter-6-measurement}{%
\subsection{Measurement of language comprehension}\label{chapter-6-measurement}}

How we measure language comprehension has rarely been guided by any specific theoretical motive in the existing literature (cf. \protect\hyperlink{ref-Amichetti2018}{Amichetti et al., 2018}).
There is a discrepancy across studies in how language comprehension in degraded speech is quantified.
Some studies that reported contextual facilitation in degraded speech comprehension used the proportion of correctly reported \emph{final} words only (e.g., \protect\hyperlink{ref-Hunter2018}{Hunter \& Pisoni, 2018}; \protect\hyperlink{ref-Obleser2010}{Obleser \& Kotz, 2010}; \protect\hyperlink{ref-Sheldon2008a}{Sheldon et al., 2008a}).
Obleser et al. (\protect\hyperlink{ref-Obleser2007}{2007}) quantified language comprehension as the proportion of correctly identified \emph{key words} in SPIN sentences.
Erb et al. (\protect\hyperlink{ref-Erb2013}{2013}) and Hakonen et al. (\protect\hyperlink{ref-Hakonen2017}{2017}) used \emph{report scores} (\protect\hyperlink{ref-Peelle2013}{Peelle, 2013}) that measure the proportion of correctly recognized \emph{words per sentence} as an index of language comprehension.
Such inconsistencies make cross-study comparison difficult.
None of the metrics outlined here take into account if listeners have correctly identified the context, which should be the most important factor to be considered in the first place.
It is clear that if the context is misidentified, then the listeners are highly likely to misidentify the succeeding words (\protect\hyperlink{ref-Marrufo2019}{Marrufo-Pérez et al., 2019}).

\hypertarget{the-present-study}{%
\subsection{The present study}\label{the-present-study}}

Stemming from the results of Chapter \ref{chapter-attention-prediction} and the motivations outlined at the beginning of this chapter, the goals of the present study were threefold:
The first goal was to attempt to replicate the facilitatory effect of predictability examining the nature of predictability, i.e., to test if listeners form narrowed expectations.
Obleser and colleagues (e.g., \protect\hyperlink{ref-Obleser2007}{Obleser et al., 2007}; \protect\hyperlink{ref-Obleser2010}{Obleser \& Kotz, 2010}) have shown predictability effects (or contextual facilitation) to appear only at a moderate level of speech degradation by using only two levels of predictability (low and high).
Using of three levels of target word predictability (low, medium and high) will let us test the narrowed expectations view (\protect\hyperlink{ref-Strauss2013}{Strauß et al., 2013}) by also taking into account the accuracy of context.
If the listeners form narrowed predictions only for the target words with high cloze probability, then the facilitatory effect of semantic prediction will be observed only at these highly predictable sentence endings.
Listeners' response to the target words with medium and low cloze probability would be quite similar since these two fall out of the range of narrow prediction.
However, if the listeners' predictions are not restricted to highly predictable target words, then they form predictions across a wide context proportional to the probability of occurrence of the target word.
In addition to highly predictable sentence endings, listeners will also form predictions for less predictable sentence endings.
Such predictions will depend on the probability of occurrence of the target words.
In other words, listeners also form predictions for less expected sentence endings;
the semantic space of prediction depends on the probability of occurrence of those sentence endings.
In contrast to prior studies (e.g., \protect\hyperlink{ref-Obleser2010}{Obleser \& Kotz, 2010}), the inclusion of sentences with medium cloze target words thus allows us to differentiate whether listeners form all-or-nothing prediction restricted to high cloze target words or a probabilistic prediction for words across a wide range of cloze probability.

There is a variation in the sentences we use, i.e., they are low, medium and high predictability sentences, and they are degraded at different levels of spectral degradation.
So our second goal was to investigate the role of uncertainty about the next-trial speech features on perceptual adaptation by varying the global channel context on the comprehension of degraded speech.
To study this, we presented sentences randomized across all levels of predictability but
i) blocked by each noise-vocoding channel, i.e.~spectral degradation (\emph{predictable channel context}) and
ii) pseudo-randomized across all noise-vocoding channels (\emph{unpredictable channel context}).
Based on the previous findings, we expected that in the unpredictable channel context (i.e., when sentences are presented in a random order of spectral degradation), participants' word recognition performance would be worse than in the predictable channel context (i.e., when the sentences are blocked by noise-vocoding, \protect\hyperlink{ref-Garrido2011}{Garrido et al., 2011}; \protect\hyperlink{ref-Sommers1994}{Sommers et al., 1994}; \protect\hyperlink{ref-Vaden2013}{Vaden et al., 2013}).
To further examine perceptual adaptation, we also considered the effect of trial number in the analyses.

And third, we aimed to measure language comprehension with a metric that reflects the participants' correct or incorrect identification of the context.
If participants do not understand the context and we only measure the recognition of the final word, this might not truly reflect the effect of contextual facilitation.

\hypertarget{methods-2}{%
\section{Methods}\label{methods-2}}

\hypertarget{participants-1}{%
\subsection{Participants}\label{participants-1}}

We recruited a group of participants via Prolific Academic (\protect\hyperlink{ref-Prolific}{Prolific, 2014}) and assigned them to the \emph{predictable channel context} (n = 50; \(M\) age \(\pm SD=23.6\pm\) 3.2 years; age range = 18-30 years; 14 females).
Another group of 48 participants (n = 48; \(M\) age \(\pm SD=24.44\pm\) 3.5 years; age range = 18-31 years; 16 females) from \protect\hyperlink{experiment1b}{Experiment 2} of Chapter \ref{chapter-attention-prediction} were recruited and assigned to the \emph{unpredictable channel context}.
All participants were native speakers of German and reportedly did not have any speech-language disorder, hearing loss, or neurological disorder.
They received monetary compensation of 6.20 Euro for participating in the approximately 40 minutes long experiment.

\hypertarget{materials-1}{%
\subsection{Materials}\label{materials-1}}

We used the same stimuli described in Chapter \ref{chapter-methods} (Section \ref{experimental-materials}).
One hundred twenty sentences each for low predictability, medium predictability, and high predictability sentences that differed in the cloze probability of sentence-final target words were used.
Their mean cloze probabilities in the low, medium and high predictability sentences were \(0.022\pm0.027\) (\(M\pm SD\); range = 0.00-0.09), \(0.274\pm0.134\) (\(M\pm SD\); range = 0.1-0.55), and \(0.752\pm0.123\) (\(M\pm SD\); range = 0.56-1.00), respectively.
All 360 sentences were then noise-vocoded through 1, 4, 6, and 8 channels to create degraded speech.

\hypertarget{procedure-2}{%
\subsection{Procedure}\label{procedure-2}}

Participants were asked to use earphones or headphones.
A sample of vocoded speech not used in the practice trial or the main experiment was presented to adjust the volume to their preferred comfort level at the beginning of the experiment.
The participants were instructed to listen and report the entire sentences by typing in everything they heard using the keyboard.
The time for typing in the response was not limited.
They were informed at the beginning of the experiment that some of the sentences would be `noisy' and not easy to understand.
In these cases, guessing was encouraged.
Eight practice trials with different levels of speech degradation were provided to the participants to familiarize them with the task before presenting all 120 experimental trials with an intertrial interval of 1,000 ms.

Each participant was presented in the \emph{unpredictable channel context} with 120 unique sentences: 40 low predictability, 40 medium predictability, and 40 high predictability sentences.
Degradation level was also balanced across each sentence type, i.e., in each of the low, medium, and high predictability sentences, 10 sentences passed through each noise-vocoding channels --- 1, 4, 6, and 8 --- were presented.
This resulted in 12 experimental lists.
The sentences in each list were pseudo-randomized.
No more than three sentences of the same degradation and predictability condition appeared consecutively.
This randomization confirmed the uncertainty of next-trial speech quality (or degradation) in the global context of the experiment.

The same set of stimuli and experimental lists were used in the \emph{predictable channel context}.
Each participant was presented with 120 unique sentences blocked by degradation level, i.e., by noise-vocoding channels.
There were four blocks of stimuli, one for each degradation level.
Thirty sentences were presented in each of the 4 blocks.
In the first block, all sentences were 8-channel noise-vocoded, followed by the blocks of 6-, 4-, and 1-channel noise-vocoded speech consecutively (\protect\hyperlink{ref-Sheldon2008a}{Sheldon et al., 2008a}).
Within each block, 10 low predictability, 10 medium predictability and 10 high predictability sentences were presented.
All the sentences were pseudo-randomized so that not more than three sentences of the same predictability condition appeared consecutively in each block.
This confirmed the certainty of next-trial speech quality (within each block) and uncertainty of next-trial sentence predictability across all four blocks.
The lists of both unpredictable and predictable channel contexts are presented in Appendix B and C.

\hypertarget{analyses-2}{%
\section{Analyses}\label{analyses-2}}

In the sentences used in our experiment, verbs evoke predictability of the sentence-final noun.
Therefore, the effect of predictability (evoked by the verb) on language comprehension can be rightfully measured if we consider only those trials in which participants identify the verbs correctly.
Verb-correct trials were considered as the sentence in which participants identified the context independent of the succeeding words.
Morphological inflections and typos were considered as correct.
We first filtered out those trials in which verbs were not identified correctly, i.e., trials with incorrect verbs.
Therefore, we excluded 2469 out of 5760 trials in unpredictable channel context and 2374 out of 6000 trials in predictable channel context from the analyses.
The 1-channel noise-vocoding condition was dropped from the analyses as there were no correct responses in any of the remaining trials in this condition.

Accuracy was analyzed using Generalized Linear Mixed Models (GLMMs) with lmerTest (\protect\hyperlink{ref-Kuznetsova2017}{Kuznetsova et al., 2017}) and lme4 (\protect\hyperlink{ref-Bates2015}{Bates, Mächler, et al., 2015}) packages.
Binary responses (categorical: correct and incorrect) for all participants in both groups (predictable and unpredictable channel contexts) were fit with a \protect\hyperlink{binomial-logistic-mixed-effects-model}{binomial linear mixed-effects model}.
Correct responses were coded as 1, and incorrect responses were coded as 0.
Number of channels (categorical: 4-channel, 6-channel, and 8-channel noise-vocoding), target word predictability (categorical: high predictability, medium predictability, and low predictability), global channel context (categorical: predictable channel context and unpredictable channel context) and the interaction of number of channels and target word predictability were included in the fixed effects.

Separately for each group (i.e., for predictable and unpredictable channel context), we first fitted a model with a maximal random effects structure that included random intercepts for each participant and item (\protect\hyperlink{ref-Barr2013}{Barr et al., 2013}).
Both by-participant and by-item random slopes were included for number of channels, target word predictability, and their interaction,
which was supported by the experiment design.
Following the procedure described in Chapter \ref{chapter-stats} (Section \ref{analysis-main}),
we selected the optimal model that best fit our data, not necessarily the maximal one.
We applied treatment contrast for number of channels (8-channel as a baseline; factor levels: 8-channel, 4-channel, 6-channel) and sliding difference contrast for target word predictability (low vs medium predictability and low vs high predictability) and channel context (factor levels: unpredictable vs predictable).

\hypertarget{results-and-discussion-2}{%
\section{Results and discussion}\label{results-and-discussion-2}}

Mean response accuracy for different conditions in both channel contexts is shown in Tables \ref{summarypredictable}, \ref{summaryunpredictable}, and Figure \ref{fig:figure2}.
We found that accuracy increased when the number of noise-vocoding channels increased and when the target word predictability increased.
The results of the statistical analysis confirmed these observations (Table \ref{results2}).

\begin{longtable}[]{@{}lllc@{}}
\caption{Response accuracy (mean and standard error of the mean) across all levels of speech degradation and target word predictability in the predictable channel context}
\label{summarypredictable}
\tabularnewline
\toprule
Number of channels & Target word predictability & Mean & Standard
error \\
\midrule
\endfirsthead
\toprule
Number of channels & Target word predictability & Mean & Standard
error \\
\midrule
\endhead
4 & Low & 71.59 & 2.74 \\
& Medium & 86.53 & 1.99 \\
& High & 93.53 & 1.42 \\
6 & Low & 93.73 & 1.33 \\
& Medium & 96.21 & 1.08 \\
& High & 98.75 & 1.02 \\
8 & Low & 97.84 & 0.80 \\
& Medium & 97.52 & 1.04 \\
& High & 99.38 & 0.59 \\
\bottomrule
\end{longtable}

\begin{longtable}[]{@{}lllc@{}}
\caption{Response accuracy (mean and standard error of the mean) across all levels of speech degradation and target word predictability in the unpredictable channel context}
\label{summaryunpredictable}
\tabularnewline
\toprule
Number of channels & Target word predictability & Mean & Standard
error \\
\midrule
\endfirsthead
\toprule
Number of channels & Target word predictability & Mean & Standard
error \\
\midrule
\endhead
4 & Low & 72.16 & 2.93 \\
& Medium & 85.61 & 2.47 \\
& High & 92.94 & 1.96 \\
6 & Low & 93.88 & 1.04 \\
& Medium & 94.86 & 1.24 \\
& High & 99.81 & 0.62 \\
8 & Low & 96.14 & 1.02 \\
& Medium & 96.59 & 0.97 \\
& High & 99.55 & 0.64 \\
\bottomrule
\end{longtable}

\begin{figure}

{\centering \includegraphics[width=0.95\linewidth]{figures/results-fig/expt-2} 

}

\caption{Mean response accuracy across all conditions in Experiment 2. Accuracy increased only with an increase in the number of noise-vocoding channels in both channel contexts. Only in the unpredictable global channel context, at the 4-channel noise-vocoding condition, a graded effect of prediction is observed. Error bars represent the standard error of the means.}\label{fig:figure2}
\end{figure}

We found a significant main effect of number of channels.
The response accuracy at 8-channel was higher than for both 4-channel
(\(\beta\) = -2.87, SE = .22, \emph{z}(6917) = -13.1, \emph{p} \textless.001),
and 6-channel noise-vocoding (\(\beta\) = -.66, SE = .19, \emph{z}(6917) = -3.42, \emph{p} \textless{} .001).
There was a significant main effect of target word predictability suggesting that
the response accuracy in low predictability sentences was lower than in high predictability sentences
(\(\beta\) = 2.18, SE = .3, \emph{z}(6917) = 7.2, \emph{p} \textless{} .001) and medium predictability sentences
(\(\beta\) = -.52, SE = .27, \emph{z}(6917) = -1.97, \emph{p} = .049).

\begin{table}[ht]
\begin{center}
\caption{Estimated effects of the model accounting for the correct word recognition}
\label{results2} 
\vskip 0.12in
\begin{tabular}[]{@{}lrrrr@{}}
\toprule
Fixed effects & Estimate & Std. Error & \emph{z} value & \emph{p}
value \\
\midrule
Intercept & 5.09 & .24 & 21.38 & \textless.001 \\
\\
Noise condition (4-channel) & -2.87 & .22 & -13.10 & \textless.001 \\
\\
Noise condition (6-channel) & -.66 & .19 & -3.42 & .001 \\
\\
Target word predictability (Low-Medium) & -.52 & .27 & -1.97 & .049 \\
\\
Target word predictability (High-Low) & 2.18 & .30 & 7.21 & \textless.001 \\
\\
Noise condition (4-channel) $\times$ & -.71 & .29 & -2.44 & .015 \\
Target word predictability (Low-Medium) \\
\\
Global channel context $\times$ & -..27 & .14 & -2.02 & .043 \\
(Unpredictable - Predictable) \\
\bottomrule
\end{tabular} 
\end{center} 
\end{table}

We also found a significant interaction between number of channels and target word predictability
(\(\beta\) = -.71, SE = .29, \emph{z}(6917) = -2.44, \emph{p} = .015).
The interaction was driven by the effect of predictability at 4-channel condition:
The accuracy in high predictability sentences was higher than in medium predictability sentences
(\(\beta\) = 1.14, SE = .37, \emph{z}(1608) = 3.1, \emph{p} \textless{} .001) which in turn was higher than low predictability sentences
(\(\beta\) = 1, SE = .24, \emph{z}(1608) = 4.2, \emph{p} \textless{} .001).
There was no significant difference in response accuracy between low predictability and high predictability sentences
at both 6-channel (\(\beta\) = .33, SE = .32, \emph{z}(2590) = 1.04, \emph{p} = .3)
and 8-channel (\(\beta\) = -.014, SE = .32, \emph{z}(2719) = -.04, \emph{p} = .97) conditions.

A subgroup analysis was also performed on each channel context.
There was a significant main effect of global channel context which showed that the response accuracy was higher in predictable channel context than in unpredictable channel context (\(\beta\) = -.27, SE = .14, \emph{z}(6917) = -2.02, \emph{p} = .04).

To further address the question of perceptual adaptation, following the findings of Chapter \ref{chapter-attention-prediction}, we also added trial number in the fixed effect.
Note that there were 30 trials in each block in the predictable channel context (i.e., blocked design).
For comparability, we divided unpredictable channel context (i.e., randomized design) into four blocks in the analysis.
We did not find a significant main effect of trial number indicating that the response accuracy did not change throughout the experiment (\(\beta\) = -.0004, SE = .01, \emph{z}(6917) = -.05, \emph{p} = .97).
It remained constant within each block in the predictable channel context (\(\beta\) = -.02, SE = .01, \emph{z}(3291) = -1.43, \emph{p} = .15) as well as in the unpredictable channel context (\(\beta\) = .01 SE = .01, \emph{z}(3291) = 1.05, \emph{p} = .29).

\hypertarget{conclusion-1}{%
\section{Conclusion}\label{conclusion-1}}

The present study had three goals: i) to examine if the previously reported facilitatory effect of semantic predictability is restricted to only highly predictable sentence endings,
ii) to assess the role of perceptual adaptation on the facilitation of language comprehension by sentence predictability, and
iii) to use and establish a sensitive metric to measure language comprehension that takes into account whether listeners benefited from the semantic context of the sentence.

Results of our study showed the expected interaction between predictability and degraded speech.
Language comprehension was better for high-cloze than for low-cloze target words when the speech signal was moderately degraded by noise-vocoding through 4 channels, while the effect of predictability was absent when speech was not intelligible by noise-vocoding through 1 channel.
Listeners could not even identify the context at this severe degradation level.
These results align with Obleser \& Kotz (\protect\hyperlink{ref-Obleser2010}{2010});
we partly included identical sentences from their study in the present study (see Appendix A).
Importantly, in contrast to their study, we also created sentences with medium-cloze target words (which were intermediate between high-cloze and low-cloze target words).
We found that the effect of predictability was also significant when comparing sentences with medium-cloze target words against the sentences with low-cloze and high-cloze target words in 4-channel noise-vocoding condition.
Recognition of a target word was dependent on its level of predictability (measured by cloze probability), and correct recognition was not just limited to high-cloze target words.
These significant differences in response accuracy between medium-cloze and low-cloze target words and between medium-cloze and high-cloze target words at 4-channel noise-vocoding condition show that the sentence-final word recognition is facilitated by semantic predictability in a graded manner,
especially at a moderate level of speech degradation.
This is in line with the findings from other experimental paradigms, including but not limited to the ERP literature, where it has been observed that the semantic predictability, in terms of cloze probability of the target word of a sentence, modulates semantic processing, indexed by N400, in a graded manner (\protect\hyperlink{ref-Delong2005}{DeLong et al., 2005}; \protect\hyperlink{ref-Nieuwland2018}{Nieuwland et al., 2018}; \protect\hyperlink{ref-Wlotko2012}{Wlotko \& Federmeier, 2012}).

The interpretation of the observed graded effect of semantic predictability at the moderate level of spectral degradation provides a novel insight into how listeners form predictions when the bottom-up input is compromised.
That is, in an adverse listening condition, listeners rely more on top-down semantic prediction than bottom-up acoustic-phonetic cues.
However, such a reliance on top-down prediction is not an all-or-nothing phenomenon.
Instead, listeners form a probabilistic prediction about the target word.
The effect of target word predictability on comprehension is not sharply focused solely on high-cloze target words like a `searchlight' as proposed by Strau\ss~and colleagues.
Rather, it is spread across a wide range, including low- and medium-cloze target words.
As the cloze probability of the target words decreases from high to low, the focus of the searchlight becomes less precise.

One could argue that the participants in our experiment ``guessed'' the verb after first correctly identifying the noun in a sentence.
To rule out this possible explanation of our findings, we conducted an additional analysis comparing the \emph{forward predictability effect} (from verb to noun) to the size of the \emph{backward predictability effect} (correct identification of the noun based on the final verb).
If the observed effect is a guessing phenomenon, then we would expect that both forward and backward predictability effects are similar in size.
If, on the other hand, understanding the verb helps to shape the predictions of the upcoming noun, and this helps intelligibility, then the forward prediction effect should be larger.
The results of this complementary analysis support the findings of the main analysis reported in the Results section.
In the backward predictability analysis, there was no graded effect of predictability, and the backward effect of ``guessing'' the verb \emph{jongliert} after recognizing the noun \emph{Bälle}, if present at all, was smaller than the forward effect of predicting the noun after recognizing the verb in the sentence \emph{Sie jongliert die Bälle}.
This further corroborates our argument that the listeners, in fact, made use of the verb-evoked context to form predictions about the upcoming noun, not the other way around, in a graded manner when the speech was moderately degraded.

There was no learning effect or perceptual adaptation to degraded speech at the trial-by-trial level.
We reason that the adaptation was hampered by a constant variation in the higher-level semantic feature (i.e., target word predictability).

The results of the analyses of trial number on the effect of channel context to capture trial-by-trial perceptual adaptation showed that the response accuracy did not increase over the course of the experiment.
This suggests that listeners' performance remained constant throughout the experiment regardless of certainty about the next-trial spectral degradation.
One way by which perceptual adaptation occurs is when the perceptual system of a listener retunes itself to the sensory properties of the auditory signal,
which can be facilitated by feedback from higher-level lexical information (\protect\hyperlink{ref-Goldstone1998}{Goldstone, 1998}; \protect\hyperlink{ref-Mattys2012}{Mattys et al., 2012}; cf. \protect\hyperlink{ref-Davis2005}{Davis et al., 2005}).
We reason that the trial-by-trial variability in the spectral resolution of the speech signal in the unpredictable channel context prevented perceptual adaptation.
Although there was certainty about the quality of speech signal within a block in the predictable channel context, we did not observe trial-by-trial perceptual adaptation in this condition either.
This is contrary to previous studies showing that listeners adapt to degraded speech when the global context of speech quality is predictable (\protect\hyperlink{ref-Davis2005}{Davis et al., 2005}; \protect\hyperlink{ref-Erb2013}{Erb et al., 2013}).
However, the crucial difference between those studies and the study reported here is the manipulation of target word predictability.
For example, Erb et al. (\protect\hyperlink{ref-Erb2013}{2013}) presented sentences with only low predictability target words from the G-SPIN test.
We, on the contrary, parametrically varied target word predictability from low to medium and high.
Note that we presented target words in a randomized order in both channel contexts.
This alone introduces trial-by-trial uncertainty in the predictable channel context and possibly hinders trial-by-trial perceptual adaptation.
As Goldstone notes, ``one way in which perception becomes adapted to tasks and environments is by increasing the attention paid to perceptual dimensions and features that are important, and/or by decreasing attention to irrelevant {[}perceptual{]} dimensions and features'' (\protect\hyperlink{ref-Goldstone1998}{Goldstone, 1998, p. 588}; see also \protect\hyperlink{ref-Gold2010}{Gold \& Watanabe, 2010}).
A similar prediction is made by the Reverse Hierarchy Theory on auditory perception (\protect\hyperlink{ref-Ahissar2009}{Ahissar et al., 2009}; \protect\hyperlink{ref-Nahum2008}{Nahum et al., 2008}).
It posits that listeners first have access to the higher-level features of a speech signal.
If their task is to comprehend language, then they may not be able to access the lower-level perceptual features.
Consequently, they cannot adapt to the speech in an adverse listening condition.
In our study, listeners paid more attention to the semantic properties of the sentences (i.e., contextual cues and target word predictability) than to the perceptual properties (i.e., spectral resolution or speech quality) as the instruction focused on ``language comprehension'' rather than ``perception''.
We speculate this might have resulted in the absence of trial- by-trial perceptual adaptation to degraded speech, even when next-trial speech quality was predictable.
Therefore, in both predictable and unpredictable channel contexts, perceptual learning of the degraded speech was hindered by trial-by-trial variation of either one (target word predictability) or both properties (target word predictability and spectral degradation level) of the speech stimuli.

We also argue that for the examination of semantic predictability effects during language comprehension, the analyses of response accuracy should be based on the trials in which context evoking words are correctly identified in the first place to make sure that listeners make use of the contextual cues instead of analyzing general word recognition scores.
Use of crude word recognition score, or key-word recognition score do not reflect whether the a comprehender formed a representation of the available context information.
The experimental paradigm in which sentence context is presented visually on a screen could likely circumvent the problem of misidentifying the context.
In such a paradigm, one could use the word recognition score without considering the context recognition (e.g., \protect\hyperlink{ref-vanOs2021}{van Os et al., 2021}).
However, such a paradigm introduces a confound:
linguistic materials are processed differently in the brain when presented auditorily vs visually (e.g., \protect\hyperlink{ref-Robinson2018}{Robinson et al., 2018}),
and listeners do not necessarily identify the visually presented context (e.g., visual half-field recognition superiority, \protect\hyperlink{ref-McKeever1977}{McKeever \& VanDeventer, 1977})

\hypertarget{summary-3}{%
\section{Summary}\label{summary-3}}

This chapter primarily investigated the nature of the predictability effect.
The experiment reported here provides a novel insight into predictive language processing when bottom-up signal quality is compromised and uncertain:
We showed that while processing a moderately degraded speech, listeners form top-down predictions across a wide range of semantic space that is not restricted within highly predictable sentence endings.
In contrast to the \emph{narrowed expectations} view, comprehension of words ranging from low- to high-cloze probability, including the medium-cloze probability, is facilitated in a graded manner.
This contextual facilitation is observed while listening to a moderately degraded speech.
Regardless of (un)certainty about the next-trial speech quality, we found that listeners do not adapt to the degraded speech when semantic predictability constantly varies,
i.e., higher-level semantic features interfere with the lower-level perceptual properties.
All in all, these findings revealed that the bottom-up perceptual property of speech (i.e., speech quality) interacts with the top-down predictive processes.
Together with the preceding chapter, this chapter showed that when listeners attend to the sentence context, predictability facilitates comprehension of moderately degraded speech in a graded manner.
In the next chapter,
we investigate the effect of further changes in the lower-level bottom-up processing on the top-down semantic predictions.
Specifically, we examine how the change in speech rate affects semantic predictions at the moderate level of speech degradation.
We ask the question:
Does an increase or decrease in the speech rate further increase or decrease the contextual facilitation?

The experiment reported here provides a novel insight into predictive language processing when bottom-up signal quality is compromised and uncertain: We showed that while processing a moderately degraded speech, listeners form top-down predictions across a wide range of semantic space that is not restricted within highly predictable sentence endings.
These findings also showed that predictability facilitates comprehension of moderately degraded speech, similar to the results of the preceding chapter, when listeners attend to the sentence context
Here we observed that in contrast to the narrowed expectations view, comprehension of words ranging from low- to high-cloze probability, including the medium-cloze probability, is facilitated in a graded manner.
This contextual facilitation is observed while listening to a moderately degraded speech.
Regardless of (un)certainty about the next-trial speech quality, we found that listeners do not adapt to degraded speech when semantic predictability constantly varies, i.e., higher-level semantic features interfere with the lower-level perceptual properties.

\hypertarget{chapter-speech-rate}{%
\chapter{Comprehension of degraded speech is modulated by the rate of speech}\label{chapter-speech-rate}}

\chaptermark{Speech rate and predictability effects}

On the one hand, clean speech perception and reading studies have shown that contextual facilitation decreases with an increase in presentation rate (e.g., fast speech), with mixed evidence on the enhancement of contextual facilitation with a decrease in presentation rate (e.g., slow speech).
On the other hand, it has been shown that semantic predictability facilitates language comprehension at a moderate level of spectral degradation (e.g., at 4-channel noise-vocoded speech) while degraded speech perception is inherently effortful.
Considering these two lines of research and their inconsistencies,
the study reported in this chapter aimed to examine how a change in speech rate modulates contextual facilitation in language comprehension when the speech is moderately degraded by noise-vocoding through 4 channels.
To this end, we conducted two experiments:
In Experiment 1, we compared participants' word recognition in a sentence while they listened to the moderately degraded speech presented at a normal and fast speech rates (compressed by a factor of 0.65).
In Experiment 2, we compared a separate group of participants' word recognition in a moderately degraded speech presented at a normal and slow speech rates (expanded by a factor of 1.35).
The sentences varied in the degree of predictability of the sentence-final target word (high and low predictability).
Results of this study demonstrate that fast speech limits the time for lexical processing.
This time constraint interferes with the lexical processing of words disproportionately affecting the low predictability sentences on top of effortful listening of the moderately degraded speech
In contrast, slow speech does not amplify the contextual facilitation --- we found the lexical processing, context representation, and semantic predictions to be optimal at the normal speech rate when the speech is moderately degraded.

\hypertarget{introduction-2}{%
\section{Introduction}\label{introduction-2}}

When speech is degraded, its intelligibility and comprehension are reduced.
For example, degradation by noise-vocoding reduces the spectral properties of speech rendering it difficult to understand (\protect\hyperlink{ref-Davis2005}{Davis et al., 2005}; \protect\hyperlink{ref-Shannon1995}{Shannon et al., 1995}).
Studies have shown that semantic predictability facilitates comprehension of moderately degraded speech (e.g., 4-channels noise-vocoded speech, \protect\hyperlink{ref-Obleser2010}{Obleser \& Kotz, 2010}),
which we have also replicated in the study presented in the previous chapter (Chapter \ref{chapter-attention-prediction}).
That is, listeners utilize context information and form predictions about upcoming linguistic units,
which in turn facilitates the comprehension of the degraded speech.
However, prediction is a time- and resource-consuming mechanism (\protect\hyperlink{ref-Pickering2018}{Pickering \& Gambi, 2018}) such that an increase or decrease in speech rate can modulate a listener's ability to use available context information and generate linguistic predictions (cf. \protect\hyperlink{ref-Cole2020}{Cole, 2020}; \protect\hyperlink{ref-Ito2016}{Ito et al., 2016}).
More processing time is available at slow presentation rates (slow speech) and less at fast presentation rates (fast speech).
So, the contextual facilitation is reduced in fast speech.
However, the evidence of enhanced contextual facilitation in slow speech is mixed (\protect\hyperlink{ref-Aydelott2004}{Aydelott \& Bates, 2004}; \protect\hyperlink{ref-Goy2013}{Goy et al., 2013}; \protect\hyperlink{ref-Koch2016}{Koch \& Janse, 2016}).
Specifically for degraded speech, there is no clear evidence on how different speech rates affect the facilitatory effect (contextual facilitation) at a moderate level of degradation (\protect\hyperlink{ref-Iwasaki2002}{Iwasaki et al., 2002}; \protect\hyperlink{ref-Meng2019}{Meng et al., 2019}; \protect\hyperlink{ref-Winn2021}{M. B. Winn \& Teece, 2021}).

Degraded speech is intrinsically effortful to listen to (\protect\hyperlink{ref-Eckert2016}{Eckert et al., 2016}; \protect\hyperlink{ref-Wild2012}{Wild et al., 2012}).
An increase (or decrease) in listening effort by a change in speech rate limits the cognitive resources available to encode the context information and form predictions (cf. \protect\hyperlink{ref-Huettig2016a}{Huettig \& Janse, 2016}).
Therefore, the present study aimed to investigate the effect of a change in speech rate on listeners' ability to generate predictions while listening to a moderately degraded speech.
One line of studies shows that at a moderate level of degradation (e.g., 4-channel noise-vocoding), semantic predictions facilitate language comprehension (e.g., \protect\hyperlink{ref-Obleser2007}{Obleser et al., 2007}).
Another line of studies shows that an increase or decrease in speech rate modulates the predictability effect, i.e., contextual facilitation (e.g., \protect\hyperlink{ref-Aydelott2004}{Aydelott \& Bates, 2004}; \protect\hyperlink{ref-Goy2013}{Goy et al., 2013}).
The current study is driven by an interest to bring these two lines of research together to understand the effect of speech rate on the facilitatory effect of predictability in degraded speech comprehension.
We wanted to investigate how contextual facilitation at a moderate level of spectral degradation is affected by the change in speech rate.
We expected that the contextual facilitation in degraded speech comprehension would be reduced by an increase in speech rate, while a decrease in speech rate would increase the contextual facilitation.

\hypertarget{background-2}{%
\section{Background}\label{background-2}}

\hypertarget{comprehension-of-fast-and-slow-speech}{%
\subsection{Comprehension of fast and slow speech}\label{comprehension-of-fast-and-slow-speech}}

A change in speech rate (by uniform time-compression or expansion) manipulates the speech signal but does not by itself produce a spectral degradation (\protect\hyperlink{ref-Charpentier1986}{Charpentier \& Stella, 1986}; \protect\hyperlink{ref-Moulines1990}{Moulines \& Charpentier, 1990}; \protect\hyperlink{ref-Schlueter2014}{Schlueter et al., 2014}; but see \protect\hyperlink{ref-Longster2003}{Longster, 2003}).
Understanding fast speech is more effortful compared to normal and slow speech (e.g., \protect\hyperlink{ref-Mueller2019}{Müller et al., 2019}; \protect\hyperlink{ref-Winn2021}{M. B. Winn \& Teece, 2021}; see also \protect\hyperlink{ref-Simantiraki2020}{Simantiraki \& Cooke, 2020}),
and its intelligibility and comprehension are reduced (\protect\hyperlink{ref-Fairbanks1957}{Fairbanks \& Kodman Jr., 1957}; \protect\hyperlink{ref-Peelle2005}{Peelle \& Wingfield, 2005}; \protect\hyperlink{ref-Schlueter2014}{Schlueter et al., 2014}).
With an increased speech rate, processing demand increases as less time is available to process the incoming information (\protect\hyperlink{ref-Gordonsalant1995}{Gordon-Salant \& Fitzgibbons, 1995}; \protect\hyperlink{ref-Rodero2016}{Rodero, 2016}; see also \protect\hyperlink{ref-Roennberg2013}{Rönnberg et al., 2013}).
Furthermore, some authors argue that the cognitive resources required for language processing are exhausted (\protect\hyperlink{ref-Gordonsalant2004}{Gordon-Salant \& Fitzgibbons, 2004}; \protect\hyperlink{ref-Janse2009}{Janse, 2009}).
Since cognitive resources are also required to encode and process the context information for generating predictions (\protect\hyperlink{ref-Pickering2018}{Pickering \& Gambi, 2018}), it can be expected that the effect of predictability is reduced in fast speech.
Studies comparing older and younger adults show that reduced intelligibility and comprehension in fast speech is associated with the limit of the central auditory processing system to process fast speech, identify the word, and activate its meaning (\protect\hyperlink{ref-Wingfield1999}{Wingfield et al., 1999}; \protect\hyperlink{ref-Wingfield2006}{Wingfield et al., 2006}; see also \protect\hyperlink{ref-Connolly1990}{Connolly et al., 1990}; \protect\hyperlink{ref-Poldrack1998}{Poldrack et al., 1998}).
Lerner et al. (\protect\hyperlink{ref-Lerner2014}{2014}) also show that the central auditory-language processing system is flexible and can rescale itself according to the speed of incoming information.
That is, the information processing speed in the auditory-language processing system can change per the change in speech rate,
however, there is an upper limit to the system's flexibility.
Beyond a certain maximum speed of speech rate, the processing of fast speech becomes difficult.

In contrast, the central auditory-language comprehension system is shown to be flexible in processing slow speech without reducing its intelligibility to a certain lower limit of its rescaling capacity (\protect\hyperlink{ref-Lerner2014}{Lerner et al., 2014}).
So, it can be expected that slow speech does not limit cognitive resources, and therefore processing context information to generate predictions in slow speech is not different from normal speech.
Alternatively, slow speech provides more time to buffer the auditory information at the lower level of the information processing hierarchy (\protect\hyperlink{ref-Ghitza2009}{Ghitza \& Greenberg, 2009}; \protect\hyperlink{ref-Vagharchakian2012}{Vagharchakian et al., 2012}) and consequently provides more time for the central auditory-language comprehension system to use the context information and form predictions.
Studies from Visual World Paradigm also support this claim that slow speech provides more time for speech processing and semantic predictions (\protect\hyperlink{ref-Fernandez2020}{Fernandez et al., 2020}; \protect\hyperlink{ref-Huettig2016a}{Huettig \& Janse, 2016}).
However, some studies have cast doubt on the processing advantage of slow speech, arguing that slow speech is perceived as overly artificial and demands high working memory (e.g., \protect\hyperlink{ref-Kemper1999}{Kemper \& Harden, 1999}; \protect\hyperlink{ref-Nejime1998}{Nejime \& Moore, 1998}; see also \protect\hyperlink{ref-Liu2006}{Liu \& Zeng, 2006}; \protect\hyperlink{ref-Love2009}{Love et al., 2009}).
In both younger and older adults, Sommers et al. (\protect\hyperlink{ref-Sommers2020}{2020}) found that slow speech does not render additional benefit in a sentence comprehension task in noise, even when supported by a visual context.
Therefore, given these competing accounts, it is unclear whether the effect of predictability increases in slow speech compared to normal speech.
Nonetheless, it is clear that a change in speech rate has different effects on speech intelligibility and language comprehension: Fast speech reduces intelligibility and comprehension,
but the evidence for the beneficial/neutral effect of slow speech on language comprehension is mixed.

A few studies have directly examined the role of fast and slow speech in listeners' use of and benefit from semantic context by using clean speech.
For instance, Aydelott \& Bates (\protect\hyperlink{ref-Aydelott2004}{2004}) used a priming paradigm to examine the effects of contextual cues, which were target words embedded in sentences, and compared fast speech to normal speech.
Target words were either congruent to the sentence context (100\% cloze probability, i.e., in a constraining sentence context), incongruent (0\% cloze probability, i.e., in an implausible sentence), or neutral (cloze probability not mentioned).
Results indicated no reduction in the facilitatory effect of contextual cues (congruent versus neutral target words) at fast speech compared to normal speech. In contrast, they found a reduced inhibitory effect (incongruent versus neutral target words).
They argued that the constraining sentence context was easy to process --- fast speech did not interfere with the earlier stage of activation of words that matched the context (i.e., in the congruent trials).
In contrast, the inhibition effect was reduced because there was less time to build up the representation of words in implausible sentence contexts, so less inhibition of the incongruent target word was needed.
However, in a replication study of Aydelott \& Bates (\protect\hyperlink{ref-Aydelott2004}{2004}), Goy et al. (\protect\hyperlink{ref-Goy2013}{2013}) found that the facilitatory effect was reduced in fast speech compared to normal speech.
They argued that the fast speech slowed down the activation of potential target words that matched the context, effectively reducing the contextual facilitation.
In a recent study, M. B. Winn \& Teece (\protect\hyperlink{ref-Winn2021}{2021}) did not observe an increase in contextual facilitation for slow speech compared to normal speech, although the intelligibility was slightly higher for slow speech among cochlear implantees.
In another experiment, Koch \& Janse (\protect\hyperlink{ref-Koch2016}{2016}) presented participants with a question-answer sequence of varying lengths across a wide range of normal and fast speech from the clean speech of Spoken Dutch Corpus (\protect\hyperlink{ref-Oostdijk2000}{Oostdijk, 2000}).
They did not find any effect of predictability on word recognition. However, their study did not systematically control target word predictability and target word position in the sentences.

The effects of varying presentation rates on semantic predictability have also been investigated with self-paced reading studies.
For example, Wlotko \& Federmeier (\protect\hyperlink{ref-Wlotko2015}{2015}) presented participants with context-evoking sentences followed by sentences containing a target word that was either expected (mean cloze probability of 74\%) or unexpected (either same or different semantic category, both with cloze probability of approximately 0\%).
They found that the facilitation effect (as reflected in the N400 amplitude) was reduced in the sentences that were presented fast compared to the ones that were presented slow.
They suggested that at a fast presentation rate, predictive preactivation of words was not common:
There was not enough time to activate proper representation to process upcoming words.
In the same study, however, the semantic facilitation effect was not reduced when the slow presentation followed the fast presentation in separate blocks.
That is, an increase in the flow of information did not always impair the ability to predict.
They argued that once the brain is engaged in predictive comprehension mode, for example, first in the slow presentation rate, it then continues to allocate resources in the same mode under a faster presentation rate.
Dambacher et al. (\protect\hyperlink{ref-Dambacher2012}{2012}) also showed that the N400 effect was delayed and smaller at a fast presentation rate compared to slow presentation rates.

To summarize, there is already some evidence from studies applying various paradigms that the predictability of the sentence context interacts with the speech rate (\protect\hyperlink{ref-Aydelott2004}{Aydelott \& Bates, 2004}; \protect\hyperlink{ref-Dambacher2012}{Dambacher et al., 2012}; \protect\hyperlink{ref-Ito2016}{Ito et al., 2016}; \protect\hyperlink{ref-Sharit2003}{Sharit et al., 2003}; \protect\hyperlink{ref-Winn2021}{M. B. Winn \& Teece, 2021}; \protect\hyperlink{ref-Wlotko2015}{Wlotko \& Federmeier, 2015}).
The predictability effect is generally reduced for fast speech, while the findings are inconsistent in the case of slow speech. Fast speech interferes with the lexical processing and activation of words that match the context, as limited time would be available to form expectations about an upcoming word (\protect\hyperlink{ref-Dambacher2012}{Dambacher et al., 2012}; \protect\hyperlink{ref-Goy2013}{Goy et al., 2013}).
In contrast, slow speech can provide more time than a normal speech rate for listeners to form a rich context representation and generate a prediction about an upcoming word (cf. \protect\hyperlink{ref-Huettig2019}{Huettig \& Guerra, 2019}).

\hypertarget{speech-rate-and-contextual-facilitation-of-moderately-degraded-speech}{%
\subsection{Speech rate and contextual facilitation of moderately degraded speech}\label{speech-rate-and-contextual-facilitation-of-moderately-degraded-speech}}

Predictions about upcoming linguistic units are generated as a listener forms a meaning representation of context information from a speech signal. Such linguistic predictions facilitate comprehension of degraded speech when the degradation is at a moderate level.
However, the effect of predictability observed at the moderate degradation level no longer exists if the listener does not understand the context.
Therefore, it is essential that the speech rate remains within the listener's limit to buffer and process the auditory information (\protect\hyperlink{ref-Vagharchakian2012}{Vagharchakian et al., 2012}) so that the listener can form the representation of the context and have sufficient time to generate predictions.

Several studies have examined the role of speech rate on the intelligibility and comprehension of degraded speech but without considering predictability effects.
For example, Meng et al. (\protect\hyperlink{ref-Meng2019}{2019}) found that an increase in speech rate had a much more severe effect on spectrally degraded speech (4-channel sine-wave vocoded) than on clean speech.
To achieve the same level of accuracy, listeners required degraded speech to be much slower than normal speech rate.
Among cochlear implantees whose speech input is spectrally degraded (\protect\hyperlink{ref-Shannon2004}{Shannon et al., 2004}), Iwasaki et al. (\protect\hyperlink{ref-Iwasaki2002}{2002}) found that a change in speech rate from slow to fast reduced word recognition accuracy.
Their speech perception was impaired with an increased speech rate, and it was improved when the speech rate was decreased (e.g., \protect\hyperlink{ref-Dincer2018}{Dincer D'Alessandro et al., 2018}).
M. B. Winn \& Teece (\protect\hyperlink{ref-Winn2021}{2021})`s study showed no significant difference in the facilitatory effect of semantic predictability between slow and normal speech rates.
This was attributed to listeners' ``repair'' strategy at normal speech rate such that they made sensible guesses about the words that fit the given context.
Similar to the studies conducted with clean speech, these studies also indicate that an increase in the speed of degraded speech is detrimental to its intelligibility, while its intelligibility increases with a decrease in speech rate.

Taken together, the utility of semantic predictability in comprehension of degraded speech is fairly established.
However, the findings about the effect of speech rate on predictability effect in degraded speech comprehension are inconsistent.
Similarly, prediction itself is a time- and resource-consuming mechanism (\protect\hyperlink{ref-Pickering2018}{Pickering \& Gambi, 2018}) which is affected by a comprehender's processing speed (e.g., \protect\hyperlink{ref-Huettig2016a}{Huettig \& Janse, 2016}).
However, the role of the speed of incoming information (i.e., speech rate of a degraded speech) on a listener's ability to form predictions, and hence its interplay with the facilitatory effect of semantic predictability at a moderately degraded speech, remains unclear.
It can be speculated from the findings of the abovementioned studies that fast speech reduces the availability of time and resources to process the speech signal and generate predictions, in addition to the effortful listening of degraded speech.
It can similarly be speculated that slow speech provides listeners more time than normal speech to process the words and form a representation of context information, in addition to reducing the effortful listening of degraded speech.

\hypertarget{the-present-study-1}{%
\subsection{The present study}\label{the-present-study-1}}

Semantic predictability has been shown to facilitate degraded speech comprehension when the degradation level is moderate at normal speech rate.
The aim of this study was to investigate whether an increase (and decrease) in speech rate reduces (and amplifies) the facilitatory effect of semantic predictability.
We systematically examined whether contextual facilitation at a moderate level of degradation varies with a change in speech rate for which
semantic predictability was manipulated by varying the cloze probability of target words in a sentence, and moderate degradation was achieved by noise-vocoding of speech through 4 channels.
4-channel noise-vocoding has been shown to be the moderate degradation level in the previous chapter, similar to the findings of Obleser \& Kotz (\protect\hyperlink{ref-Obleser2010}{2010}).
Speech rate was manipulated by time-compression (and expansion) of the moderately degraded speech to make it fast (and slow).

To achieve our aim, we conducted two experiments in which listeners were instructed to listen to the sentences and type in the entire sentence they heard.
Sentence comprehension (word recognition accuracy) for high and low predictability sentences was assessed in fast speech (Experiment 1) and slow speech (Experiment 2).
The processing demand increases, and a limited time is available to process the context and generate predictions with an increase in speech rate (e.g., \protect\hyperlink{ref-Aydelott2004}{Aydelott \& Bates, 2004}; \protect\hyperlink{ref-Wlotko2015}{Wlotko \& Federmeier, 2015}; see also \protect\hyperlink{ref-Pickering2018}{Pickering \& Gambi, 2018}).
Therefore, we expected that the contextual facilitation (i.e., the increase in word recognition accuracy in high predictability sentences compared to low predictability sentences) would be reduced for fast speech compared to normal speech (Experiment 1).
However, for slow speech, due to an abundance of time to process the degraded speech and the context and reduced listening effort (e.g., \protect\hyperlink{ref-Winn2021}{M. B. Winn \& Teece, 2021}), we expected contextual facilitation to be increased compared to normal speech (Experiment 2).
We expected that both increase and decrease in contextual facilitation would be primarily driven by the ease of processing high predictability sentences compared to low predictability sentences (\protect\hyperlink{ref-Aydelott2004}{Aydelott \& Bates, 2004}; \protect\hyperlink{ref-Goy2013}{Goy et al., 2013}).

\hypertarget{experiment-1}{%
\section{Experiment 1}\label{experiment-1}}

This experiment was conducted to investigate the effect of an increase in speech rate on predictability effect in the comprehension of the 4-channel noise-vocoded speech.
We examined if the facilitatory effect of predictability decreased as the speech sped up by a compression factor of 0.65.

\hypertarget{methods-3}{%
\subsection{Methods}\label{methods-3}}

\hypertarget{participants-2}{%
\subsubsection{Participants}\label{participants-2}}

We recruited one group of participant (n=101; (\(M\) age \(\pm SD=23.14\pm 3.31\) years; age range = 18-31 years; 66 females, 1 preferred not to say) online via Prolific Academic.
All participants were native speakers of German and did not have any speech-language disorder, hearing loss, or neurological disorder (all self-reported).
All participants received 6.20 Euro as monetary compensation for their participation in the approximately 40 minutes long experiment.

\hypertarget{materials-2}{%
\subsubsection{Materials}\label{materials-2}}

In this experiment, we used a subset of materials created by the method described in Chapter \ref{chapter-methods} (Section \ref{experimental-materials}).
One hundred twenty sentences each for low predictability and high predictability sentences that differed in the cloze probability of sentence-final target words were used.
Mean cloze probabilities of the target words of low and high predictability sentences were \(0.022\pm0.027\) (\(M\pm SD\); range = 0.00-0.09) and \(0.752\pm0.123\) (\(M\pm SD\); range = 0.56-1.00) respectively.
The audio recodings of all 240 sentences were compressed by a factor of 0.65 in Praat software to create fast speech (see Chapter \ref{chapter-methods} Section \ref{compression-expansion} for details).
Then the recordings of speech signal at fast rate and normal rate were passed through 4 channels of noise-vocoding to create moderately degraded speech stimuli of two types: fast speech and normal speech (see Chapter \ref{chapter-methods} Section \ref{noise-vocoding} for details).

Each participant was presented with 120 unique sentences: 60 HP and 60 LP sentences.
Speech rate was also balanced across each predictability level.
The participants received 30 sentences with normal speed and 30 with fast speed in each of the predictability conditions resulting into 4 experimental lists.
The sentences in each list were pseudo-randomized, that is, not more than 3 sentences of same speed, or same predictability condition appeared consecutively.

\hypertarget{procedure-3}{%
\subsubsection{Procedure}\label{procedure-3}}

Participants were asked to use earphones or headphones.
A sample of vocoded speech not used in the main experiment and the practice trial was provided so that the participants could adjust the volume to a preferred level of comfort at the beginning of the experiment.
The participants were instructed to listen and report the entire sentences by typing in the everything they heard using the keyboard.
The time for typing in the response was not limited.
They were informed at the beginning of the experiment that some of the sentences would be `noisy' and not easy to understand.
In these cases, guessing was encouraged.
To familiarize the participants with the task, eight practice trials with different levels of speech degradation were provided before presenting all 120 experimental trials with an intertrial interval of 1,000 ms.

Each participant had to listen to 60 high and 60 low predictability sentences.
Speech rate was also balanced across each predictability condition.
For each predictability condition, 30 sentences with fast speech and 30 with normal speech were presented.
Sentences were pseudo-randomized so that no more than three sentences of the same predictability level or speech rate appeared consecutively.
A total of four lists were constructed (see Appendix D).

\hypertarget{analyses-3}{%
\subsection{Analyses}\label{analyses-3}}

We have already shown in the previous chapters that predictability effects, i.e., contextual facilitation in language comprehension can be rightfully measured only if we consider the trials in which participants accurately identify the context.
Verbs are predictive of the nouns in our stimuli (e.g., \emph{Sie jongliert die Bälle}).
Therefore, we discarded the trials in which verbs were identified incorrectly, which were XXXX out of XXXX trials.

Accuracy was analyzed using Generalized Linear Mixed Models (GLMMs) following the procedure described in Chapter \ref{chapter-stats} (Section \ref{analysis-main}) similar to the preceding chapters.
Binary responses (categorical: correct and incorrect) for all participants were fit with a \protect\hyperlink{binomial-logistic-mixed-effects-model}{binomial linear mixed-effects model}.
Correct responses were coded as 1, and incorrect responses were coded as 0.
Speech rate (categorical: fast speech and slow speech), target word predictability (categorical: high predictability sentences and low predictability sentences), and the interaction of speech rate (i.e., speed) and target word predictability were included in the fixed effects.
We fitted a model with a maximal random effects structure that included random intercepts for each participant and item (\protect\hyperlink{ref-Barr2013}{Barr et al., 2013}).
Both by-participant and by-item random slopes were included for speech rate, target word predictability, and their interaction,
which was supported by the experiment design.
We applied treatment contrast for both predictability and speech rate, mapping low predictability and normal speech to the intercept.

\hypertarget{results-and-discussion-3}{%
\subsection{Results and discussion}\label{results-and-discussion-3}}

\begin{longtable}[]{@{}lllc@{}}
\caption{Response accuracy (mean and standard error of the mean) across all levels of speech rate and target word predictability in Experiment 1}
\label{summary3a}
\tabularnewline
\toprule
Speed & Target word predictability & Mean & Standard
error \\
\midrule
\endfirsthead
\toprule
Speed & Target word predictability & Mean & Standard
error \\
\midrule
\endhead
Fast & Low & 58.93 & 1.54 \\
& High & 91.78 & 1.23 \\
Normal & Low & 71.82 & 1.37 \\
& High & 94.13 & 1.01 \\
\bottomrule
\end{longtable}

Mean response accuracies (in percentage) for all experimental conditions aggregated across all participants and items are shown in Table \ref{summary3a} and Figure \ref{fig:figure3a}.
It shows that accuracy increases with an increase in target word predictability, but it decreases with an increase in speech rate.
The results of the statistical analysis confirmed these observations (Table \ref{results3a}).

\begin{figure}

{\centering \includegraphics[width=0.95\linewidth]{figures/results-fig/expt-3a} 

}

\caption{Mean response accuracy across all conditions in Experiment 1. Accuracy increased only with an increase in the target-word predictability and a decrease in speech rate. Error bars represent the standard error of the means.}\label{fig:figure3a}
\end{figure}

\begin{table}[ht]
\begin{center}
\caption{Estimated effects of the model accounting for the correct word recognition in Experiment 1}
\label{results3a} 
\vskip 0.12in
\begin{tabular}[]{@{}lrrrr@{}}
\toprule
Fixed effects & Estimate & Std. Error & \emph{z} value & \emph{p}
value \\
\midrule
Intercept & 1.34 & .24 & 5.58 & \textless.001 \\
\\
Speech rate (Fast) & -.98 & .24 & -4.16 & \textless.001 \\
\\
Target word predictability (High) & 2.42 & .28 & 8.55 & \textless.001 \\
\\
Speech rate $times$ Target word predictability & 1.06 & .42 & 2.50 & .012 \\
\bottomrule
\end{tabular} 
\end{center} 
\end{table}

We found a significant main effect of target word predictability (\(\beta\) = 2.42, SE = .28, \emph{z} = 8.55, \emph{p} \textless{} .001) and a significant main effect of speech rate (\(\beta\) = -.98, SE = .24, \emph{z} = 4.16, \emph{p} \textless{} .001)
suggesting that participants' response accuracy was higher for the high predictability sentences than for the low predictability sentences and for normal speech than for fast speech.
We also found a significant interaction between target word predictability and speech rate (\(\beta\) = 1.06, SE = .42, \emph{z} = 2.50, \emph{p} = .01).
These findings show that the effect of target word predictability, i.e., contextual facilitation was reduced at fast speech (see Figure \ref{fig:figure3a}).

Separate planned analyses of each predictability level were performed.
There was no significant main effect of speech rate at high predictability condition (\(\beta\) = .02, SE = .34, \emph{z} = .05, \emph{p} = .96).
At low predictability condition, in contrast, we found a significant main effect of speech rate (\(\beta\) = -.99, SE = .27, \emph{z} = -3.72, \emph{p} \textless{} .001).
Hence, response accuracy decreased at fast speech, but only for the low predictability sentences.

Separate planned analyses of each speech rate revealed that there was significant main effect of predictability in both normal speech (\(\beta\) = 1.98, SE = .28, \emph{z} = 7.05, \emph{p} \textless{} .001) and fast speech (\(\beta\) = 2.67, SE = .37, \emph{z} = 7.14, \emph{p} \textless{} .001),
but the effect appeared to be higher for fast speech (\(\beta\) = 2.67) than for normal speech (\(\beta\) = 1.98).
This resulted from a significant drop in accuracy at the low predictability condition rather than a rise in accuracy at high predictability condition in the fast speech.

These results indicated an increase in response accuracy with an increase in target word predictability only at a normal speech rate.
Fast speech rate significantly reduced the accuracy in the low predictability condition.
It suggests that fast speech incurs a cost in processing the low predictability sentences and reduces the contextual facilitation in degraded speech comprehension.
These findings also align with previous studies conducted with clean speech, which reported that fast speech reduces contextual facilitation (e.g., \protect\hyperlink{ref-Aydelott2004}{Aydelott \& Bates, 2004}).

We conducted another experiment to examine if slowing down the speech rate eases the processing of both low and high predictability sentences and increases the contextual facilitation in comprehension of moderately degraded speech.

\hypertarget{experiment-2}{%
\section{Experiment 2}\label{experiment-2}}

Following up on Experiment 1, we conducted Experiment 2 on a separate group of participants to investigate the effect of a decrease in speech rate on predictability effect in the comprehension of the 4-channel noise-vocoded speech.
We examined if the facilitatory effect of predictability increased as the speech slowed down by an expansion factor of 1.65.

\hypertarget{methods-4}{%
\subsection{Methods}\label{methods-4}}

\hypertarget{participants-and-materials-1}{%
\subsubsection{Participants and Materials}\label{participants-and-materials-1}}

We recruited another group of participant (n=101; (\(M\) age \(\pm SD=23.49\pm 3.26\) years; age range = 18-30 years; 60 females, 1 preferred not to say) online via Prolific Academic.
Same sentences were used as stimuli as in Experiment 1.
Instead of compression, the auditory recordings were expanded by a factor of 1.35 to create slow speech.
All other procedure, including the noise-vocoding through 4 channels, to create stimuli were the same as in Experiment 1.
This resulted in two types of 4-channel noise-vocoded speech: slow speech and normal speech.

\hypertarget{procedure-4}{%
\subsubsection{Procedure}\label{procedure-4}}

Same procedure was followed as Experiment 1.
Participants were asked to use earphones or headphones.
They were instructed to report the entire sentence by typing in what they heard.

Four experimental lists were constructed to present each participant with 60 high and 60 low predictability sentences (see Appendix D).
Speech rate was also balanced across each predictability condition in each list. For each predictability condition, 30 sentences with slow speech and 30 with normal speech were presented.
Sentences were pseudo-randomized so that no more than three sentences of the same predictability level or speech rate appeared consecutively.

\hypertarget{analyses-4}{%
\subsection{Analyses}\label{analyses-4}}

The data analysis procedure was the same as Experiment 1.
Accuracy was analyzed using Generalized Linear Mixed Models (GLMMs).
We fit a model with maximal random effects structure.
Treatment contrast was applied for both predictability and speech rate, mapping low predictability and normal speech to the intercept.

\hypertarget{results-and-discussion-4}{%
\subsection{Results and discussion}\label{results-and-discussion-4}}

\begin{longtable}[]{@{}lllc@{}}
\caption{Response accuracy (mean and standard error of the mean) across all levels of speech rate and target word predictability in Experiment 2}
\label{summary3b}
\tabularnewline
\toprule
Speed & Target word predictability & Mean & Standard
error \\
\midrule
\endfirsthead
\toprule
Speed & Target word predictability & Mean & Standard
error \\
\midrule
\endhead
Slow & Low & 70.92 & 1.09 \\
& High & 94.25 & .89 \\
Normal & Low & 73.09 & 1.02 \\
& High & 94.82 & .70 \\
\bottomrule
\end{longtable}

Mean response accuracies (in percentage) for all experimental conditions aggregated across all participants and items are shown in Table \ref{summary3b} and Figure \ref{fig:figure3b}.
It shows that accuracy increases with an increase in target word predictability
but did not increase with a decrease in speech rate.
The results of the statistical analysis confirmed these observations (Table \ref{results3b}).

\begin{figure}

{\centering \includegraphics[width=0.95\linewidth]{figures/results-fig/expt-3b} 

}

\caption{Mean response accuracy across all conditions in Experiment 2. Accuracy increased only with an increase in the target-word predictability, but a change in speech rate had no significant effect on accuracy. Error bars represent the standard error of the means.}\label{fig:figure3b}
\end{figure}

\begin{table}[ht]
\begin{center}
\caption{Estimated effects of the model accounting for the correct word recognition in Experiment 2}
\label{results3b} 
\vskip 0.12in
\begin{tabular}[]{@{}lrrrr@{}}
\toprule
Fixed effects & Estimate & Std. Error & \emph{z} value & \emph{p}
value \\
\midrule
Intercept & 1.41 & .23 & 6.20 & \textless.001 \\
\\
Speech rate (Slow) & -.08 & .14 & -57 & .568 \\
\\
Target word predictability (High) & 2.58 & .30 & 8.65 & \textless.001 \\
\\
Speech rate $times$ Target word predictability & .44 & .27 & 1.65 & .099 \\
\bottomrule
\end{tabular} 
\end{center} 
\end{table}

We again found a significant main effect of target word predictability, indicating that participants' response accuracy was higher for the high predictability condition than for the low predictability condition (\(\beta\) = 2.58, SE = .30, \emph{z} = 8.65, \emph{p} \textless{} .001).
In contrast to Experiment 1, we did not find a significant main effect of speech rate (\(\beta\) = -.08, SE = .15, \emph{z} = .57, \emph{p} = .568),
nor there was a significant interaction between speech rate and target word predictability (\(\beta\) = .44, SE = .27, \emph{z} = 1.65, \emph{p} = .099).
These suggested that there was no change in participants' response accuracy with a reduction in speech rate,
nor did the contextual facilitation significantly increase or decrease with slowing down of the speech rate.

In contrast to Experiment 1, Experiment 2 did not indicate a differential effect of speech rates in the comprehension of high and low predictability sentences.
While Experiment 1 showed that speeding up the speech rate significantly reduced the accuracy of low predictability sentences, such a reduction was not observed in Experiment 2 when the speech rate was slowed down.
Although listeners' response accuracy was reduced in both fast and slow speech than in normal speech, their ability to utilize context information was only impaired by the fast speech in the low predictability sentences.

\hypertarget{conclusion-2}{%
\section{Conclusion}\label{conclusion-2}}

The main goal of the present study was to examine whether the contextual facilitation (i.e., the facilitatory effect of semantic predictability) in comprehension of a moderately degraded speech is modulated by changes in speech rate.
The results of two experiments revealed that fast speech selectively impedes the comprehension of low predictability sentences, while slow speech has no detrimental or beneficial effect on contextual facilitation.

In both experiments, our results showed a significant main effect of predictability at normal speech rate,
i.e., we observed a facilitatory effect of semantic predictability at normal speech rate under moderate degradation level by noise-vocoding through 4 channels.
This replicates the findings of earlier studies (e.g., \protect\hyperlink{ref-Obleser2010}{Obleser \& Kotz, 2010}) and the study presented in Chapter \ref{chapter-graded-prediction} in which participants were presented only with normal speech rate, and contextual facilitation was observed at the spectral degradation through 4-channel noise-vocoding.
At this moderate degradation level, listeners could decode the context and form its meaning representation.
Consequently, they generated predictions about the upcoming target word in a sentence even in low predictability conditions depending on the contextual constraint of the sentences (cf. \protect\hyperlink{ref-Strauss2013}{Strauß et al., 2013}).

The expected interaction between speech rate and target word predictability in Experiment 1 showed that comprehension of degraded speech was significantly impaired for low predictability sentences but not for high predictability sentences in fast speech.
Listening to degraded speech is effortful and requires more attentional resources than clean speech (\protect\hyperlink{ref-Wild2012}{Wild et al., 2012}).
When presented as a fast speech, spectral degradation imposes additional cognitive demands; and less time is available to process the speech signal.
The central auditory-language processing system does not rescale itself according to the speed of the fast speech presented in Experiment 1 (\protect\hyperlink{ref-Lerner2014}{Lerner et al., 2014}).
It is then difficult to process the fast speech, decode the context information and form its meaning representation from the degraded speech to generate predictions about upcoming target words.
This disproportionately affects low predictability sentences as fast speech interferes with the lexical processing of words, likely reducing the activation of target words in less constraining sentence contexts (\protect\hyperlink{ref-Aydelott2004}{Aydelott \& Bates, 2004}; \protect\hyperlink{ref-Dambacher2012}{Dambacher et al., 2012}; cf. \protect\hyperlink{ref-Goy2013}{Goy et al., 2013}).
As a result, language comprehension in the low predictability condition is impaired more than in the high predictability condition in Experiment 1.

In contrast to Experiment 1, we did not find the expected interaction between speech rate and target word predictability in Experiment 2,
i.e., a decrease in speech rate did not differentially affect the comprehension of high or low predictability sentences.
Unlike Experiment 1, we did not observe a significant change in contextual facilitation in the slow speech at 4-channel noise-vocoding level in Experiment 2.
Slowing down the speech gives listeners more time to process the information, including the context that is important to generate predictions.
However, our findings show that the added time in slow speech does not benefit intelligibility and comprehension of sentences more than the normally available time at a normal speech rate.
Comprehenders' lexical processing is optimal at the normal presentation rate (\protect\hyperlink{ref-Dambacher2012}{Dambacher et al., 2012}).
Although slow speech reduces effortful listening of degraded speech, the resources thus freed up by the slow speech are not allocated to enhance contextual facilitation.
This argument is in line with M. B. Winn \& Teece (\protect\hyperlink{ref-Winn2021}{2021}), who reported that contextual facilitation does not increase when the speech is slowed down.
Alternatively, it is plausible that the artificial expansion of speech introduced distortion in the speech signal.
Although speech intelligibility and comprehension are increased by slow speech (\protect\hyperlink{ref-Dincer2018}{Dincer D'Alessandro et al., 2018}; \protect\hyperlink{ref-Iwasaki2002}{Iwasaki et al., 2002}), acoustic distortion due to artificial expansion reduces intelligibility and comprehension (\protect\hyperlink{ref-Longster2003}{Longster, 2003}).
As a result, we did not observe an overall amplification of contextual facilitation in the slow speech at the moderate degradation level in Experiment 2.

Accounts from speech perception and predictive language processing point to a common expectation: contextual facilitation is enhanced when comprehenders have more time to process the presented information (\protect\hyperlink{ref-Huettig2019}{Huettig \& Guerra, 2019}; \protect\hyperlink{ref-Ito2016}{Ito et al., 2016}; \protect\hyperlink{ref-Kuperberg2016}{Kuperberg \& Jaeger, 2016}).
However, there is conflicting empirical evidence on whether an increase or a decrease in speech rate benefits intelligibility, comprehension, and contextual facilitation.
Our findings show this interplay among spectral degradation, speech rate, and semantic prediction.
Although reducing the speech rate provides time to process the information (including the context) in the degraded speech, this does not necessarily ease the processing of high or low predictability sentences differentially.
Thus, no increased facilitatory effect is observed at the slow speech rate.
In contrast, increasing the speech rate adds more cognitive load on top of the effort required to listen to the degraded speech.
This results in difficulty processing and understanding the rapidly unfolding sentences; this difficulty further increases when the target words are not easily predictable.

Similarly, in the ``narrowed expectations'' framework of degraded speech comprehension, Strauß et al. (\protect\hyperlink{ref-Strauss2013}{2013}) argue that lexico-semantic cues are more robust to degradation and the target words can be processed faster and relatively more easily in a highly constraining context than in a less constraining context.
They posit that listeners can activate a narrow range of most likely target words from the context in a high predictability sentence.
Our results show that when the moderately degraded speech is sped up, the context is still robust:
There is enough processing time available in the fast speech to process the context and generate a small range of lexical predictions about an upcoming target word in a high predictability sentence.
Therefore, the comprehension of high predictability sentences is not reduced due to an increase in speech rate.
However, in a low predictability sentence, the range of probable sentence endings is too wide to generate enough lexical predictions that facilitate comprehension.
When the processing time is short, it further reduces the activation of likely sentence endings, especially when the context is less constraining (\protect\hyperlink{ref-Aydelott2004}{Aydelott \& Bates, 2004}).

An alternative explanation of our findings of contextual facilitation could be that the listeners first identified the noun (e.g., Bälle), then integrated it with the verb (e.g., jongliert) instead of first identifying the verb and predicting the noun.
To rule this out, we conducted an additional analysis, the results of which supported the prediction-based explanation.
We compared the effect (estimates) of forward-predictability (from the verb to noun) with that of backward integration (identifying the verb from the correct identification of the noun).
In both experiments, the forward predictability effect was larger than the backward integration.
This finding favours the explanation that the contextual facilitation we observed is due mainly to predictability rather than guessing or backward integration.

Of note, the generalization of our results is limited. First, we tested only with one expansion factor of 1.35 and one compression factor of 0.65.
It can be speculated that an increase in facilitatory effect could be observed when the speech is expanded to different levels by including other expansion factors.
There could be an optimal trade-off between slowing down the speech with more time to process (\protect\hyperlink{ref-Fernandez2020}{Fernandez et al., 2020}) and the speech still remaining intelligible.
Second, we only tested younger adults.
We did not examine the effect of cognitive ageing on contextual facilitation of comprehension of fast and slow speech.
Older adults have delayed processing speed such that slow speech generally improves their speech intelligibility and language comprehension.
Furthermore, semantic context benefits older adults more than younger adults in adverse listening conditions.
Therefore, the effect of slow speech could be different in older than what we found in younger adults under adverse listening conditions.

To conclude, we show that access (or restriction) to lexical processing is associated with the speed of information flow, and the constraints in attentional and cognitive resources are key factors that influence contextual facilitation of moderately degraded speech.
Lexical processing is restricted in an effortful listening of the rapidly unfolding degraded speech;
consequently, understanding the words that are not easily predictable from the context is difficult.
On the contrary, auditory-language comprehension is optimal in the normal speech rate, and thus, slowing down the degraded speech does not necessarily amplify contextual facilitation.

\hypertarget{summary-4}{%
\section{Summary}\label{summary-4}}

This chapter reported studies investigating the effect of changes in speech rate on contextual facilitation of a moderately degraded speech.
While it was already shown in the preceding chapter that at a normal speech rate, predictability facilitates comprehension of degraded speech at 4-channel noise-vocoding level,
in this chapter, the effect of increase and decrease of speech rate on this predictability effect was investigated.
When the speech rate is increased, we found that activating target words using the context information is more difficult in the low predictability sentences than in the high predictability sentences.
This is on top of the fact that fast speech adds further load in processing the inherently effortful degraded speech.
In contrast, slowing down the moderately degraded speech did not provide any benefit in the comprehension of high or low predictability sentences.
Although slow speech reduces the effort on listening to degraded speech,
this chapter concluded that thus freed up resources are not necessarily used to amplify the predictability effects.
All in all, this chapter revealed that the bottom-up perceptual property, like speech rate, interacts with the top-down predictive processes, in addition to other perceptual properties, like speech degradation;
however, the nature of this interaction depends on the nature of the speech (i.e., fast vs slow).

In the next chapter, we provide a concluding remark on the studies presented in Chapters \ref{chapter-attention-prediction}, \ref{chapter-graded-prediction}, and \ref{chapter-speech-rate}.
We discuss the limitations of the studies, their generalization, and future outlook.

\hypertarget{chapter-conclusion}{%
\chapter{Discussion and conclusion}\label{chapter-conclusion}}

In this chapter, we present an overview of the experimental findings reported in the preceding chapters, and
their conclusions are discussed in the broader context of probabilistic accounts of language processing.
The noisy channel model of communication (see Chapter \ref{chapter-introduction} for elaborate discussion) is revisited and discussed concerning the findings of our studies.
We also discuss the implications, limitations, outlook and considerations for future research.
Finally, we conclude with the closing remarks on the interaction of top-down predictive and bottom-up auditory processes in the comprehension of degraded speech
and the status of the thesis in the research domain of predictive language processing.

\hypertarget{overview-of-the-main-findings}{%
\section{Overview of the main findings}\label{overview-of-the-main-findings}}

A prominent view in the field of language science is that readers and listeners use context information to form linguistic predictions (for reviews, \protect\hyperlink{ref-Kuperberg2016}{Kuperberg \& Jaeger, 2016}),
which is akin to the view that humans are \emph{prediction machines} constantly generating predictions about upcoming events (\protect\hyperlink{ref-Clark2013}{A. Clark, 2013}).
Studies have shown that it is not always the case in language processing,
to the extent that some even question the necessity of prediction (e.g., \protect\hyperlink{ref-Huettig2016}{Huettig \& Mani, 2016}).
For example, differences in age and literacy have been shown to limit listeners' ability to form linguistic predictions (e.g., \protect\hyperlink{ref-Federmeier2010}{K. D. Federmeier et al., 2010}; \protect\hyperlink{ref-Mishra2012}{Mishra et al., 2012}; \protect\hyperlink{ref-Sheldon2008b}{Sheldon et al., 2008b}).
Chapter \ref{chapter-attention-prediction} showed that prediction does not always occur in language comprehension.
While listening to degraded speech, when listeners attended only to the sentence-final target word but not the preceding context, the facilitatory effect of predictability was absent.
However, when the sentence context was attended to, it facilitated the comprehension of the degraded speech.
These results showed that attention (or lack thereof) can limit the predictability effect in degraded speech comprehension: \emph{no attention, no prediction}.
We also replicated prior findings that when the bottom-up input is less reliable due to degradation,
listeners rely more on the lexical-semantic cues (e.g., \protect\hyperlink{ref-Obleser2010}{Obleser \& Kotz, 2010}).

In Chapter \ref{chapter-graded-prediction}, we further examined the effect of predictability and its nature (all-or-nothing vs graded).
Since we already showed in Chapter \ref{chapter-attention-prediction} that attention to the context is necessary for the contextual facilitation,
our instruction did not restrict participants' attention to only the target word (and away from the context) in the studies reported in Chapter 6.
Participants, thus, attended to the context and formed its meaning representation.
This chapter revealed that predictability facilitates language comprehension in a graded manner when the speech is moderately degraded at 4-channel noise-vocoding.
At the extremes, listeners either did not utilize the context (unintelligible at 1-channel noise-vocoding),
or the context and target word were clearly intelligible (least degradation at 8-channel noise-vocoding) ---
in the latter case, listeners identified the target word based on the bottom-up information rather than the context.
That is, listeners processed the language \emph{rationally} at different levels of speech degradation (see \protect\hyperlink{ref-Ryskin2018}{Ryskin et al., 2018} for a similar argument).
These findings also refute the claim of the \emph{narrowed expectations} framework proposed by Strauß et al. (\protect\hyperlink{ref-Strauss2013}{2013}).
Contrary to their claim that predictions are made only for highly predictable sentence endings,
we found that listeners predict target words across a wide range of semantic space, including the sentence endings in the low and medium predictability sentences.

After we showed in Chapter \ref{chapter-graded-prediction} that predictability effects are observed at the moderate degradation level,
our goal in Chapter \ref{chapter-speech-rate} was to examine if a change in speech rate at 4-channel noise-vocoding
further increases or decreases the predictability effect.
In two experiments, we manipulated the bottom-up processes by changing the speech rates:
We compared the contextual facilitation at the moderate degradation level in normal and fast speech rates,
then in normal and slow speech rates.
The experiments presented in this chapter showed that slow speech does not amplify the contextual facilitation that is observed in normal the speech rate.
Listeners already performed at their optimal level in normal speech rate;
slowing down the speech rate did not necessarily benefit the contextual facilitation.
On the contrary, fast speech impaired the processing of low predictability sentences.
These findings showed that with a restricted time in the processing of fast speech,
lexical access and activation of target words in less constraining sentence contexts are difficult.

Chapters \ref{chapter-attention-prediction} and \ref{chapter-graded-prediction} also showed that regardless of (un)certainty about the quality of subsequent trials,
listeners do not adapt to degraded speech across all levels of speech degradation;
their performance did not improve over the course of the experiment.
We reasoned that a constant trial-by-trial variability in the higher-level feature of the speech stimuli (e.g., predictability)
interferes with the perceptual retuning of the auditory system to the sensory properties of the speech stimuli.
Hence, the identification of words did not improve throughout the experiment.
In Chapters 6 and 7, we argued for a new approach to calculate response accuracy that takes into account a listener's context identification instead of other word recognition scores (e.g., the proportion of correctly identified words per sentence)
that do not consider whether listeners correctly identified the context.
In our analyses, we included only those trials in which the context-evoking words were identified correctly.

Taken together, the contribution of this thesis can be stated as follows:

\begin{quote}
When a listener attends to a sentence context, semantic predictability facilitates language comprehension at a moderate level of spectral degradation in a \emph{graded manner} as opposed to being an all-or-nothing phenomenon.
Such contextual facilitation is optimal at a normal speech rate, which is not necessarily amplified by slowing down the speech.
However, increasing the speech rate reduces contextual facilitation by restricting lexical access in the less predictable sentence endings.
\end{quote}

\hypertarget{implications-of-the-findings}{%
\section{Implications of the findings}\label{implications-of-the-findings}}

\hypertarget{probabilistic-prediction-in-a-noisy-channel}{%
\subsection{Probabilistic prediction in a noisy channel}\label{probabilistic-prediction-in-a-noisy-channel}}

The studies in this thesis were based on the theoretical accounts of predictive language processing and the noisy channel model of communication.
Speech degradation by noise-vocoding created a noisy communication channel that interfered with a listener's perception and understanding of a speaker's utterance
(schematically represented in Figure \ref{fig:noisy-channel}),
which was formalized in Equation \eqref{eq:noisy-channel3} in Chapter \ref{chapter-introduction} as:

\begin{align*} 
\hat{m_p} &= \mathop{\mathrm{argmax}}\limits_{m_p} P(m_p | u_p) * P(u_p|u_i, N) * P(u_i | m_i) * P(m_i)
\end{align*}

Thus, the experiments presented in this thesis suggest that listeners are \emph{rational} comprehenders:
They weigh the top-down (\(P(u_i | m_i) * P(m_i)\)) and bottom-up processes (\(P(u_p|u_i, N)\)) to comprehend a degraded speech.
When the distribution of \(P(u_p|u_i, N)\) is relatively flat, i.e.,
when the speech signal is degraded, and listeners have difficulty understanding an utterance,
they rely more on the context (e.g., at 4-channel noise-vocoded speech in Chapter \ref{chapter-graded-prediction}).
On the contrary, when this bottom-up information is reliable, i.e.,
when the speech signal is least degraded, and listeners understand an utterance,
they do not necessarily rely on the top-down information.
Regardless of their predictions from the context
the listeners' comprehension results from what they actually perceive (e.g., at 8-channel noise-vocoded speech in Chapter \ref{chapter-graded-prediction}).

Under the rational account, this thesis showed that listeners predict an upcoming word based on its probability of occurrence in a given context.
To our knowledge, the empirical evidence presented in this thesis is the only one since Strauß et al. (\protect\hyperlink{ref-Strauss2013}{2013}) to examine the nature of the predictability effect in degraded speech comprehension.
We did not find prediction to be restrictive or deterministic, as reported in Strauß et al. (\protect\hyperlink{ref-Strauss2013}{2013}) in degraded speech comprehension.
Instead, our findings are in line with the probabilistic accounts of predictive language processing (\protect\hyperlink{ref-Delong2005}{DeLong et al., 2005}; \protect\hyperlink{ref-Kuperberg2016}{Kuperberg \& Jaeger, 2016}; cf. \protect\hyperlink{ref-Nieuwland2018}{Nieuwland et al., 2018}) proposed in the literature on speech perception and reading studies.

\hypertarget{attention-and-prediction}{%
\subsection{Attention and prediction}\label{attention-and-prediction}}

Chapter \ref{chapter-attention-prediction} showed that attention and prediction can operate independently (i.e., they are two separate processes) in the predictive processing of degraded speech (see also \protect\hyperlink{ref-Astheimer2011}{Astheimer \& Sanders, 2011}; \protect\hyperlink{ref-Li2017}{X. Li et al., 2017}).
When we restricted listeners' attention to the contextually predicted target word, the facilitatory effect of predictability was absent.
Only attention to the context provided contextual facilitation.
This role of attention is not fully addressed in the current frameworks of predictive language processing.

In their \emph{good enough processing} framework, Ferreira \& Lowder (\protect\hyperlink{ref-Ferreira2016}{2016}) speculated that a comprehender can focus and process one part of a sentence ``deeper'',
and other parts can be ignored or processed at a ``shallow'' level.
However, their proposal is unclear on how attention to different parts of a speech stream can be strategically allocated
and how it moderates contextual facilitation.
Another influential account of predictive language processing proposed by Pickering \& Gambi (\protect\hyperlink{ref-Pickering2018}{2018}) states that prediction involves speech production mechanism,
i.e., listeners simulate the production of the perceived speech to predict upcoming linguistic units.
It is supposed that listeners ideally have access to all the stages of lexical processing.
However, their account does not include the role of attention at any stage of lexical processing in speech production, comprehension, and prediction.

In an fMRI study of visual perception, Kok et al. (\protect\hyperlink{ref-Kok2012}{2012}) found a significant difference in the amplitude of the BOLD signal between predicted and unpredicted stimuli location in the visual field even when the participants did not attend to the stimuli.
This relationship between prediction and attention in visual perception is accounted for in predictive coding models (e.g., \protect\hyperlink{ref-Friston2009}{K. Friston, 2009}).
Therefore, an elaborate and explanatory theory of predictive language processing should also account for attention regulation that modulates the predictability effects in language comprehension.

\hypertarget{speech-rate}{%
\subsection{Speech rate}\label{speech-rate}}

We showed that sentence context facilitates comprehension of degraded speech presented at the normal speed.
Contrary to common wisdom and previous findings (e.g., \protect\hyperlink{ref-Dambacher2012}{Dambacher et al., 2012}; \protect\hyperlink{ref-Wlotko2015}{Wlotko \& Federmeier, 2015}), slowing the speech rate did not improve contextual facilitation (cf. \protect\hyperlink{ref-Winn2021}{M. B. Winn \& Teece, 2021}).
Our results from younger adults showed no benefit of slow speech either.
Participants in our study were neither able to better understand the degraded speech at a slow speed
nor did the slow speech help to better process the context and facilitate comprehension compared to the speech presented at a normal rate.
In contrast, fast speech selectively impaired the processing of low predictability sentences.
The activation of target words in low constraining sentences was difficult.
These findings have some practical implications.
The speech that people with sensory neural hearing loss and cochlear implants perceive is spectrally degraded (\protect\hyperlink{ref-Parida2022}{Parida \& Heinz, 2022}; \protect\hyperlink{ref-Shannon1998}{Shannon et al., 1998}; \protect\hyperlink{ref-Shannon2004}{Shannon et al., 2004}).
The findings from our study can inform the clinical and rehabilitative setup:
We do not find evidence that speaking slow benefits degraded speech comprehension.
At the same time, we provide evidence that speaking fast is detrimental to processing sentences that are not easily predictable from the context.
Therefore, in a rehabilitative setup, auditory-verbal training for the cochlear implantees can likely benefit from a normal speech rate than the exaggerated slowing down of the speech.
Other studies have also shown that listeners do not prefer slow speech (e.g., \protect\hyperlink{ref-Sutton1995}{Sutton et al., 1995}; cf. \protect\hyperlink{ref-Winn2021}{M. B. Winn \& Teece, 2021}).
On the scientific aspect,
our findings inform the theories of predictive language processing, which take into account the speed of lexical processing.
For example, Pickering \& Gambi (\protect\hyperlink{ref-Pickering2018}{2018})'s account of predictive language processing posits that comprehenders have access to word-form at the late stage of lexical processing.
Our findings indicate that at a fast speech rate when the speech is degraded, processing of the less predictable words does not reach the late stage in contrast to the highly predictable words.
Replication and extension of these findings measuring the time-course of lexical processing at different speech rates can further test the predictions of these accounts of language processing.

\hypertarget{limitations-and-scope-for-future-studies}{%
\section{Limitations and scope for future studies}\label{limitations-and-scope-for-future-studies}}

\hypertarget{measurement-of-predictability}{%
\subsection{Measurement of predictability}\label{measurement-of-predictability}}

Our interpretation of the experimental results to support the probabilistic and graded nature of predictability is that listeners form expectations about an upcoming word based on the likelihood of its occurrence given the context.
The ``likelihood of occurrence'' was measured with the cloze probability of the target word in a sentence,
which is widely used in sentence comprehension studies (see \protect\hyperlink{ref-Staub2015a}{Staub et al., 2015} for discussion).
However, some argue that it is not the best metric to measure the predictability of a word (e.g., \protect\hyperlink{ref-Smith2011}{N. Smith \& Levy, 2011}; \protect\hyperlink{ref-Verhagen2018}{Verhagen et al., 2018}):
The cloze probability is an aggregated estimate of whether a group of participants will consider a particular word as a continuation of a sentence given a context.
For example, if 40 out of 50 participants in a cloze norming study may respond that \emph{balloon} is the most likely ending of the truncated sentence \emph{The child went out to fly a red} \_\_\_,
then ``balloon'' is considered to be the highly predictable word in this context with the cloze probability value of 0.80.
However, it is also likely that another group of 50 participants would respond with ``kite'' as the most likely ending of the same sentence.
This example illustrates that a cloze-based measure is an inconsistent estimate of predictability.

In recent years, alternatives to cloze-based measures have been proposed.
For example, Lopukhina et al. (\protect\hyperlink{ref-Lopukhina2021}{2021}) demonstrated that corpus-based measures of word probability are better predictors of linguistic predictability than the cloze-based measures calculated from a small group of participants in norming studies (see also \protect\hyperlink{ref-Michaelov2022}{Michaelov et al., 2022}).
Similarly, Hofmann et al. (\protect\hyperlink{ref-Hofmann2021}{2021}) demonstrated that surprisal-based measures estimated from Large Language Models (e.g., GPT-2, GPT-3) explain N400 effects and reading times better than cloze-based measures (see \protect\hyperlink{ref-Heilbron2022}{Heilbron et al., 2022} for an implementation of surprisal calculated from GPT-2).
As growing number of studies show that values other than cloze probability are better estimates of predictability,
it is not an overstatement to say that these measures can replace cloze probability which tends to be inconsistent.
Studies in the domain of probabilistic language processing that we reported in this thesis can benefit from multiple predictability estimates from language models and corpus.

\hypertarget{individual-differences}{%
\subsection{Individual differences}\label{individual-differences}}

It is evident that language processing is not the same across all participants.
For example, working memory capacity, processing speed, literacy, and language experience vary in a group of participants,
which results in a difference in language processing and the use of lexical-semantic cues among participants (\protect\hyperlink{ref-Federmeier2010}{K. D. Federmeier et al., 2010}; \protect\hyperlink{ref-Mishra2012}{Mishra et al., 2012}; \protect\hyperlink{ref-Rommers2015}{Rommers et al., 2015}; \protect\hyperlink{ref-Scholman2020}{Scholman et al., 2020}).
However, the general conclusions about the top-down--bottom-up interactions presented in this thesis are based on the mean estimates of predictability (in terms of response accuracy) across all participants.
Although we controlled for variability among participants in the mixed model analysis,
the individual differences measures could inform how the top-down--bottom-up interactions vary among the participants.
For example, it can be speculated that participants with faster processing speed benefit more from the semantic context when the speech rate is fast in Chapter \ref{chapter-speech-rate} (e.g., \protect\hyperlink{ref-Huettig2016a}{Huettig \& Janse, 2016}).
Therefore, it is recommended that the extension of the studies presented in this thesis include individual differences measures that can moderate linguistic predictions in adverse listening conditions.

\hypertarget{sentence-structure-and-context-information}{%
\subsection{Sentence structure and context information}\label{sentence-structure-and-context-information}}

One of the goals of the thesis was to replicate the predictability effects in degraded speech comprehension, as shown in Obleser et al. (\protect\hyperlink{ref-Obleser2007}{2007}) and Obleser \& Kotz (\protect\hyperlink{ref-Obleser2010}{2010}).
Therefore, we created short Subject--Verb--Object sentences similar to Obleser \& Kotz (\protect\hyperlink{ref-Obleser2010}{2010})'s stimuli.
In these sentences, the verb was predictive of the noun.
However, in daily conversations, a speaker's utterances are not structured in this short format in which only one preceding word provides a context to predict the next word.
Instead, different sources of information, like the knowledge about the speaker, topic, or discourse, build the context information and are jointly predictive of the upcoming linguistic units.
Similarly, the speaker indicates important words or concepts via pitch contours, stress, or intonation patterns,
which then direct the listener's attention.
Hence, one could argue that the generalization of the findings beyond the stimuli used here is restricted or limited.
Therefore, the next step is to extend these findings using longer utterances in which a discourse provides the context information about an upcoming word in a sentence in the discourse (e.g., \protect\hyperlink{ref-Brothers2015}{Brothers et al., 2015})
and the information about the speaker (e.g., \protect\hyperlink{ref-Bhandari2020}{Bhandari et al., 2020}).

\hypertarget{the-nature-of-the-predictability-effect}{%
\subsection{The nature of the predictability effect}\label{the-nature-of-the-predictability-effect}}

Strauß et al. (\protect\hyperlink{ref-Strauss2013}{2013}) formulated their ``narrowed expectations'' framework based on an EEG study measuring the latency and amplitude of the N400 component.
We did not find support for their claims;
instead, we demonstrated that the effect of predictability in degraded speech comprehension is \emph{graded} in nature.
A replication and extension of our findings in an EEG experiment would corroborate our claims.
It can be expected that the N400 amplitude of the target word in the low predictability sentences will be larger than in the medium predictability sentences, which in turn, will be larger than in the high predictability sentences.
Furthermore, these differences will be significantly larger in the moderately degraded speech (4-channel noise-vocoding) compared to the least degraded speech (8-channel noise-vocoding).
We note that the EEG experiment proposed here was initially planned as a part of this thesis.
However, due to the closure of the electrophysiology lab during the covid-19 lockdown, the experiment was not conducted.

\hypertarget{concluding-remark}{%
\section{Concluding remark}\label{concluding-remark}}

At the outset of this thesis, we outlined some goals:
to replicate the predictability effects in degraded speech comprehension,
to investigate whether the nature of the predictability effect is graded,
to examine if attention and speech rate limit or moderate contextual facilitation,
and if lexical-semantic properties of the speech influence listeners' adaptation to degraded speech.
We have largely achieved these goals.
In the experiments presented in Chapters \ref{chapter-attention-prediction}, \ref{chapter-graded-prediction}, and \ref{chapter-speech-rate}, we have shown that the interaction between top-down and bottom-up processes in the comprehension of degraded speech is dynamic:
Probabilistic language prediction is graded in nature at the moderate level of speech degradation while the listeners attend to the context information.
It was also revealed that an increase in speech rate is detrimental to processing low predictability sentences.
We argued for using a metric of language comprehension that considers listeners' identification of context information.

Despite these findings, this thesis does not answer all the questions about predictive language processing, especially about prediction in adverse listening conditions.
The research domain of predictive language processing is grapples with the problems like disentangling prediction from integration (e.g., \protect\hyperlink{ref-Mantegna2019}{Mantegna et al., 2019}) and
parallel vs sequential prediction (see \protect\hyperlink{ref-Gibson2000}{Gibson \& Pearlmutter, 2000} for discussion).
These questions are beyond the scope of this thesis to be addressed.
It would be an overstatement to claim that our findings are definitive answers to the question of graded vs deterministic prediction in degraded speech comprehension.
Nevertheless, the evidence from our experiments lines up with the existing findings supporting the account of graded prediction.
We hold a similar position regarding our evidence on the limitations of contextual facilitation (in Chapter \ref{chapter-attention-prediction}):
Our findings align with the growing body of literature that question the automaticity of predictions (see \protect\hyperlink{ref-Huettig2016}{Huettig \& Mani, 2016} for discussion).
Based on these, we speculate that although prediction undoubtedly facilitates language comprehension,
it is not a ubiquitous process in language comprehension.
Listeners can strategically deploy other top-down processes that limit or moderate linguistic predictions.

We discussed the limitations of our experiments, widely used methods and metrics (e.g., cloze probability, key word recognition accuracy),
and provided avenues for future research (individual differences, replication with EEG experiments, context information in a discourse).
Building on the findings of this thesis and addressing these recommendations in future research,
we will get a better understanding of the nuanced nature language comprehension in adverse listening conditions,
and an elaborate and comprehensive theory of predictive language processing can be built.

\hypertarget{chapter-ethics}{%
\chapter{Ethics and funding}\label{chapter-ethics}}

\noindent 

\textbf{Ethics}: The studies presented in this thesis involved human subjects.
All subjects were recruited following the recommendations of the American Psychological Association.
All subjects provided an informed consent in accordance with the Declaration of Helsinki.
The ethics committee of the Deutsche Gesellschaft für Sprache (DGfS; EN: German Society for Language Science) provided ethical approval for the experiments conducted.

\textbf{Funding}: The research presented in this thesis was funded by the Deutsche Forschungsgemeinschaft (DFG; EN: German Research Foundation) under the research grant SFB1102 (Sonderforschungsbereiche; EN: Collaborative Research Center), Project ID 232722074.

\startappendices

\hypertarget{experimental-items-1}{%
\chapter{Experimental items 1}\label{experimental-items-1}}

Experimental items used in the experiments presented in Chapters \ref{chapter-attention-prediction} and \ref{chapter-graded-prediction}.

\hypertarget{experimental-items-2}{%
\chapter{Experimental items 2}\label{experimental-items-2}}

Experimental items used in the experiments presented in Chapter \ref{chapter-speech-rate}

\hypertarget{forward-prediction-vs-backward-guessin-in-chapter-6}{%
\chapter{Forward prediction vs Backward guessin in Chapter 6}\label{forward-prediction-vs-backward-guessin-in-chapter-6}}

Results of the complementary analysis performed in Chapter \ref{chapter-graded-prediction}:

\hypertarget{forward-prediction-vs-backward-guessin-in-chapter-7}{%
\chapter{Forward prediction vs Backward guessin in Chapter 7}\label{forward-prediction-vs-backward-guessin-in-chapter-7}}

Results of the complementary analysis performed in Chapter \ref{chapter-speech-rate}:

\hypertarget{data-analysis}{%
\chapter{Data analysis}\label{data-analysis}}

Example of GLMM in \texttt{R}:

\hypertarget{bibliography}{%
\chapter*{Bibliography}\label{bibliography}}
\addcontentsline{toc}{chapter}{Bibliography}

\hypertarget{refs}{}
\begin{CSLReferences}{1}{0}
\leavevmode\vadjust pre{\hypertarget{ref-OSC2015}{}}%
Aarts, A. A., Anderson, J. E., Anderson, C. J., Attridge, P. R., Attwood, A., Axt, J., Babel, M., Bahník, Š., Baranski, E., Barnett-Cowan, M., Bartmess, E., Beer, J., Bell, R., Bentley, H., Beyan, L., Binion, G., Borsboom, D., Bosch, A., Bosco, F. A., \ldots{} Zuni, K. (2015). {Estimating the reproducibility of psychological science}. \emph{Science}, \emph{349}(6251). \url{https://doi.org/10.1126/science.aac4716}

\leavevmode\vadjust pre{\hypertarget{ref-Ahissar2009}{}}%
Ahissar, M., Nahum, M., Nelken, I., \& Hochstein, S. (2009). {Reverse hierarchies and sensory learning}. \emph{Philosophical Transactions of the Royal Society B: Biological Sciences}, \emph{364}(1515), 285--299. \url{https://doi.org/10.1098/rstb.2008.0253}

\leavevmode\vadjust pre{\hypertarget{ref-Akaike1973}{}}%
Akaike, H. (1973). Information theory and an extension of the maximum likelihood principle. In B. N. Petrov \& F. Csaksi (Eds.), \emph{Proceedings of the 2nd international symposium on information theory} (pp. 267--281). Akademiai Kaido.

\leavevmode\vadjust pre{\hypertarget{ref-Altmann1999}{}}%
Altmann, G. T. M., \& Kamide, Y. (1999). Incremental interpretation at verbs: restricting the domain of subsequent reference. \emph{Cognition}, \emph{73}(3), 247--264. \url{https://doi.org/10.1016/s0010-0277(99)00059-1}

\leavevmode\vadjust pre{\hypertarget{ref-Altmann2007}{}}%
Altmann, G. T. M., \& Kamide, Y. (2007). {The real-time mediation of visual attention by language and world knowledge: Linking anticipatory (and other) eye movements to linguistic processing}. \emph{Journal of Memory and Language}, \emph{57}(4), 502--518. \url{https://doi.org/10.1016/j.jml.2006.12.004}

\leavevmode\vadjust pre{\hypertarget{ref-Amichetti2018}{}}%
Amichetti, N. M., Atagi, E., Kong, Y.-Y., \& Wingfield, A. (2018). Linguistic Context Versus Semantic Competition in Word Recognition by Younger and Older Adults With Cochlear Implants. \emph{Ear \& Hearing}, \emph{39}(1), 101--109. \url{https://doi.org/10.1097/aud.0000000000000469}

\leavevmode\vadjust pre{\hypertarget{ref-Ankener2019}{}}%
Ankener, C. S. (2019). \emph{{The influence of visual information on word predictability and processing effort}} {[}Doctoral dissertation{]}. Saarland University; Saarl{ä}ndische Universit{ä}ts-und Landesbibliothek.

\leavevmode\vadjust pre{\hypertarget{ref-Ankener2018}{}}%
Ankener, C. S., Sekicki, M., \& Staudte, M. (2018). {The influence of visual uncertainty on word surprisal and processing effort}. \emph{Frontiers in Psychology}, \emph{9}, 2387. \url{https://doi.org/10.3389/fpsyg.2018.02387}

\leavevmode\vadjust pre{\hypertarget{ref-Anwylirvine2020}{}}%
Anwyl-Irvine, A. L., Massonnié, J., Flitton, A., Kirkham, N., \& Evershed, J. K. (2020). {Gorilla in our midst: An online behavioral experiment builder}. \emph{Behavior Research Methods}, \emph{52}(1), 388--407. \url{https://doi.org/10.3758/s13428-019-01237-x}

\leavevmode\vadjust pre{\hypertarget{ref-Anwylirvine2021}{}}%
Anwyl-Irvine, A., Dalmaijer, E. S., Hodges, N., \& Evershed, J. K. (2021). {Realistic precision and accuracy of online experiment platforms, web browsers, and devices}. \emph{Behavior Research Methods}, \emph{53}(4), 1407--1425. \url{https://doi.org/10.3758/s13428-020-01501-5}

\leavevmode\vadjust pre{\hypertarget{ref-Astheimer2011}{}}%
Astheimer, L. B., \& Sanders, L. D. (2011). {Predictability affects early perceptual processing of word onsets in continuous speech}. \emph{Neuropsychologia}, \emph{49}(12), 3512--3516. \url{https://doi.org/10.1016/j.neuropsychologia.2011.08.014}

\leavevmode\vadjust pre{\hypertarget{ref-Aydelott2004}{}}%
Aydelott, J., \& Bates, E. (2004). {Effects of acoustic distortion and semantic context on lexical access}. \emph{Language and Cognitive Processes}, \emph{19}(1), 29--56. \url{https://doi.org/10.1080/01690960344000099}

\leavevmode\vadjust pre{\hypertarget{ref-Baayen2008}{}}%
Baayen, R. H., Davidson, D. J., \& Bates, D. M. (2008). {Mixed-effects modeling with crossed random effects for subjects and items}. \emph{Journal of Memory and Language}, \emph{59}(4), 390--412. \url{https://doi.org/10.1016/j.jml.2007.12.005}

\leavevmode\vadjust pre{\hypertarget{ref-Barr2013}{}}%
Barr, D. J., Levy, R., Scheepers, C., \& Tily, H. J. (2013). Random effects structure for confirmatory hypothesis testing: Keep it maximal. \emph{Journal of Memory and Language}, \emph{68}(3), 255--278. \url{https://doi.org/10.1016/j.jml.2012.11.001}

\leavevmode\vadjust pre{\hypertarget{ref-Bates2015a}{}}%
Bates, D., Kliegl, R., Vasishth, S., \& Baayen, H. (2015). {Parsimonious Mixed Models}. \emph{arXiv}. \url{https://arxiv.org/abs/1506.04967}

\leavevmode\vadjust pre{\hypertarget{ref-Bates2015}{}}%
Bates, D., Mächler, M., Bolker, B., \& Walker, S. (2015). Fitting Linear Mixed-Effects Models Using lme4. \emph{Journal of Statistical Software}, \emph{67}(1). \url{https://doi.org/10.18637/jss.v067.i01}

\leavevmode\vadjust pre{\hypertarget{ref-Bernerslee1992}{}}%
Berners-Lee, T., Cailliau, R., Groff, J. F., \& Pollermann, B. (1992). {World-wide web: The information universe}. \emph{Internet Research}, \emph{2}(1), 52--58. \url{https://doi.org/10.1108/eb047254}

\leavevmode\vadjust pre{\hypertarget{ref-Bhandari2020}{}}%
Bhandari, P., Prasad, S., \& Mishra, R. K. (2020). High proficient bilinguals bring in higher executive control when encountering diverse interlocutors. \emph{Journal of Cultural Cognitive Science}, \emph{4}(2), 201--215.

\leavevmode\vadjust pre{\hypertarget{ref-Praat2001}{}}%
Boersma, P. (2001). Praat, a system for doing phonetics by computer. \emph{Glot. Int.}, \emph{5}(9), 341--345.

\leavevmode\vadjust pre{\hypertarget{ref-Bolker2009}{}}%
Bolker, B. M., Brooks, M. E., Clark, C. J., Geange, S. W., Poulsen, J. R., Stevens, M. H. H., \& White, J. S. S. (2009). {Generalized linear mixed models: a practical guide for ecology and evolution}. \emph{Trends in Ecology and Evolution}, \emph{24}(3), 127--135. \url{https://doi.org/10.1016/j.tree.2008.10.008}

\leavevmode\vadjust pre{\hypertarget{ref-Bondell2010}{}}%
Bondell, H. D., Krishna, A., \& Ghosh, S. K. (2010). Joint variable selection for fixed and random effects in linear mixed-effects models. \emph{Biometrics}, \emph{66}(4), 1069--1077.

\leavevmode\vadjust pre{\hypertarget{ref-Bowers2012}{}}%
Bowers, J. S., \& Davis, C. J. (2012). {Bayesian just-so stories in psychology and neuroscience}. \emph{Psychological Bulletin}, \emph{138}(3), 389--414. \url{https://doi.org/10.1037/a0026450}

\leavevmode\vadjust pre{\hypertarget{ref-Brothers2021}{}}%
Brothers, T., \& Kuperberg, G. R. (2021). {Word predictability effects are linear, not logarithmic: Implications for probabilistic models of sentence comprehension}. \emph{Journal of Memory and Language}, \emph{116}(September 2020), 104174. \url{https://doi.org/10.1016/j.jml.2020.104174}

\leavevmode\vadjust pre{\hypertarget{ref-Brothers2015}{}}%
Brothers, T., Swaab, T. Y., \& Traxler, M. J. (2015). {Effects of prediction and contextual support on lexical processing: Prediction takes precedence}. \emph{Cognition}, \emph{136}, 135--149. \url{https://doi.org/10.1016/j.cognition.2014.10.017}

\leavevmode\vadjust pre{\hypertarget{ref-Bruineberg2021}{}}%
Bruineberg, J., Dolega, K., Dewhurst, J., \& Baltieri, M. (2021). The emperor's new markov blankets. \emph{Behavioral and Brain Sciences}, 1--63. \url{https://doi.org/10.1017/S0140525X21002351}

\leavevmode\vadjust pre{\hypertarget{ref-Brunelliere2019}{}}%
Brunellière, A., Auran, C., \& Delrue, L. (2019). {Does the prosodic emphasis of sentential context cause deeper lexical-semantic processing?} \emph{Language, Cognition and Neuroscience}, \emph{34}(1), 29--42. \url{https://doi.org/10.1080/23273798.2018.1499945}

\leavevmode\vadjust pre{\hypertarget{ref-Charpentier1986}{}}%
Charpentier, F. J., \& Stella, M. G. (1986). {Diphone synthesis using an overlap-add technique for speech waveforms concatenation.} \emph{ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings}, 2015--2018. \url{https://doi.org/10.1109/icassp.1986.1168657}

\leavevmode\vadjust pre{\hypertarget{ref-Chatterjee2012}{}}%
Chatterjee, S., \& Hadi, A. S. (2012). Multiple linear regression. In \emph{Regression analysis by example} (pp. 57--91). John Wiley~\& Sons.

\leavevmode\vadjust pre{\hypertarget{ref-Chen2011}{}}%
Chen, F., \& Loizou, P. C. (2011). Predicting the intelligibility of vocoded speech. \emph{Ear and Hearing}, \emph{32}(3), 331.

\leavevmode\vadjust pre{\hypertarget{ref-Cherry1953}{}}%
Cherry, E. C. (1953). {Some experiments on the recognition of speech, with one and with two ears}. \emph{Journal of the Acoustical Society of America}, \emph{25}(5), 975--979. \url{https://doi.org/10.1121/1.1907229}

\leavevmode\vadjust pre{\hypertarget{ref-Christiansen2015}{}}%
Christiansen, M. H., \& Chater, N. (2015). {The Now-or-Never bottleneck: A fundamental constraint on language}. \emph{Behavioral and Brain Sciences}, \emph{39}, 1--72. \url{https://doi.org/10.1017/S0140525X1500031X}

\leavevmode\vadjust pre{\hypertarget{ref-Clark2013}{}}%
Clark, A. (2013). Whatever next? Predictive brains, situated agents, and the future of cognitive science. \emph{Behavioral and Brain Sciences}, \emph{36}(3), 181--204. \url{https://doi.org/10.1017/s0140525x12000477}

\leavevmode\vadjust pre{\hypertarget{ref-Clark1973}{}}%
Clark, H. H. (1973). {The language-as-a-fixed-effect fallacy: A critique of language statistics in psychological research}. \emph{Journal of Verbal Learning and Verbal Behavior}, \emph{12}(4), 335--359. \url{https://doi.org/10.1016/S0022-5371(73)80014-3}

\leavevmode\vadjust pre{\hypertarget{ref-Vocoder1940}{}}%
Clendeninn, P. (1940). {The vocoder}. \emph{Nature}, \emph{145}(3665), 157. \url{https://doi.org/10.1038/145157a0}

\leavevmode\vadjust pre{\hypertarget{ref-Cockburn2020}{}}%
Cockburn, A., Dragicevic, P., Besançon, L., \& Gutwin, C. (2020). {Threats of a replication crisis in empirical computer science}. \emph{Communications of the ACM}, \emph{63}(8), 70--79. \url{https://doi.org/10.1145/3360311}

\leavevmode\vadjust pre{\hypertarget{ref-Cole2020}{}}%
Cole, A. (2020). \emph{{The effects of prediction and speech rate on lexical processing}} (p. 35) {[}Masters thesis, University of Maryland{]}. \url{https://doi.org/10.13016/37my-jxp7}

\leavevmode\vadjust pre{\hypertarget{ref-Coleman1964}{}}%
Coleman, E. B. (1964). {Generalizing to a language population}. \emph{Psychological Reports}, \emph{14}(1), 219--226. \url{https://doi.org/10.2466/pr0.1964.14.1.219}

\leavevmode\vadjust pre{\hypertarget{ref-Coltheart2004}{}}%
Coltheart, M. (2004). Are there lexicons? \emph{Quarterly Journal of Experimental Psychology Section A: Human Experimental Psychology}, \emph{57}(7), 11531171. \url{https://doi.org/10.1080/02724980443000007}

\leavevmode\vadjust pre{\hypertarget{ref-Connolly1990}{}}%
Connolly, J. F., Stewart, S., \& Phillips, N. (1990). The effects of processing requirements on neurophysiological responses to spoken sentences. \emph{Brain and Language}, \emph{39}(2), 302--318.

\leavevmode\vadjust pre{\hypertarget{ref-Cooke2021}{}}%
Cooke, M., \& Garcia Lecumberri, M. (2021). Estimating the performance gap between lab and remote speech perception experiment. \emph{Acoustical Society of America Journal}, \emph{149}(4), A111--A111.

\leavevmode\vadjust pre{\hypertarget{ref-Cooke2022}{}}%
Cooke, M., Scharenborg, O., \& Meyer, B. T. (2022). The time course of adaptation to distorted speech. \emph{The Journal of the Acoustical Society of America}, \emph{151}(4), 2636--2646.

\leavevmode\vadjust pre{\hypertarget{ref-Corps2020}{}}%
Corps, R. E., \& Rabagliati, H. (2020). How top-down processing enhances comprehension of noise-vocoded speech: Predictions about meaning are more important than predictions about form. \emph{Journal of Memory and Language}, \emph{113}, 104114. \url{https://doi.org/10.1016/j.jml.2020.104114}

\leavevmode\vadjust pre{\hypertarget{ref-Dahan2006}{}}%
Dahan, D., \& Magnuson, J. S. (2006). \emph{Spoken word recognition} (pp. 249--283). Elsevier. \url{https://doi.org/10.1016/b978-012369374-7/50009-2}

\leavevmode\vadjust pre{\hypertarget{ref-Dambacher2012}{}}%
Dambacher, M., Dimigen, O., Braun, M., Wille, K., Jacobs, A. M., \& Kliegl, R. (2012). {Stimulus onset asynchrony and the timeline of word recognition: Event-related potentials during sentence reading}. \emph{Neuropsychologia}, \emph{50}(8), 1852--1870. \url{https://doi.org/10.1016/j.neuropsychologia.2012.04.011}

\leavevmode\vadjust pre{\hypertarget{ref-Darwiche2010}{}}%
Darwiche, A. (2010). Bayesian networks. \emph{Communications of the ACM}, \emph{53}(12), 80--90. \url{https://doi.org/10.1145/1859204.1859227}

\leavevmode\vadjust pre{\hypertarget{ref-Darwin2005}{}}%
Darwin, C. (2005). \emph{Praat scripts for producing shannon AM speech}. \url{http://www.lifesci.sussex.ac.uk/home/Chris_Darwin/Praatscripts/}.

\leavevmode\vadjust pre{\hypertarget{ref-Davis2005}{}}%
Davis, M. H., Johnsrude, I. S., Hervais-Adelman, A., Taylor, K., \& McGettigan, C. (2005). Lexical Information Drives Perceptual Learning of Distorted Speech: Evidence From the Comprehension of Noise-Vocoded Sentences. \emph{Journal of Experimental Psychology: General}, \emph{134}(2), 222--241. \url{https://doi.org/10.1037/0096-3445.134.2.222}

\leavevmode\vadjust pre{\hypertarget{ref-Delong2005}{}}%
DeLong, K. A., Urbach, T. P., \& Kutas, M. (2005). Probabilistic word pre-activation during language comprehension inferred from electrical brain activity. \emph{Nature Neuroscience}, \emph{8}(8), 1117--1121. \url{https://doi.org/10.1038/nn1504}

\leavevmode\vadjust pre{\hypertarget{ref-Demberg2013}{}}%
Demberg, V., Keller, F., \& Koller, A. (2013). Incremental, predictive parsing with psycholinguistically motivated tree-adjoining grammar. \emph{Computational Linguistics}, \emph{39}(4), 1025--1066.

\leavevmode\vadjust pre{\hypertarget{ref-Dincer2018}{}}%
Dincer D'Alessandro, H., Boyle, P. J., Ballantyne, D., De Vincentiis, M., \& Mancini, P. (2018). {The role of speech rate for Italian-speaking cochlear implant users: insights for everyday speech perception}. \emph{International Journal of Audiology}, \emph{57}(11), 851--857. \url{https://doi.org/10.1080/14992027.2018.1498139}

\leavevmode\vadjust pre{\hypertarget{ref-Dudley1939}{}}%
Dudley, H. (1939). {The vocoder}. \emph{Bell Laboratories Record}, \emph{18}(4), 122--126.

\leavevmode\vadjust pre{\hypertarget{ref-Dupoux1997}{}}%
Dupoux, E., \& Green, K. (1997). Perceptual adjustment to highly compressed speech: Effects of talker and rate changes. \emph{Journal of Experimental Psychology: Human Perception and Performance}, \emph{23}(3), 914--927. \url{https://doi.org/10.1037/0096-1523.23.3.914}

\leavevmode\vadjust pre{\hypertarget{ref-Ebersole2016}{}}%
Ebersole, C. R., Atherton, O. E., Belanger, A. L., Skulborstad, H. M., Allen, J. M., Banks, J. B., Baranski, E., Bernstein, M. J., Bonfiglio, D. B. V., Boucher, L., Brown, E. R., Budiman, N. I., Cairo, A. H., Capaldi, C. A., Chartier, C. R., Chung, J. M., Cicero, D. C., Coleman, J. A., Conway, J. G., \ldots{} Nosek, B. A. (2016). {Many Labs 3: Evaluating participant pool quality across the academic semester via replication}. \emph{Journal of Experimental Social Psychology}, \emph{67}, 68--82. \url{https://doi.org/10.1016/j.jesp.2015.10.012}

\leavevmode\vadjust pre{\hypertarget{ref-Eckert2016}{}}%
Eckert, M. A., Teubner-Rhodes, S., \& Vaden, K. I. (2016). Is Listening in Noise Worth It? The Neurobiology of Speech Recognition in Challenging Listening Conditions. \emph{Ear \& Hearing}, \emph{37}(1), 101S--110S. \url{https://doi.org/10.1097/aud.0000000000000300}

\leavevmode\vadjust pre{\hypertarget{ref-Ehrlich1981}{}}%
Ehrlich, S. F., \& Rayner, K. (1981). {Contextual effects on word perception and eye movements during reading}. \emph{Journal of Verbal Learning and Verbal Behavior}, \emph{20}(6), 641--655. \url{https://doi.org/10.1016/S0022-5371(81)90220-6}

\leavevmode\vadjust pre{\hypertarget{ref-Ellermeier2015}{}}%
Ellermeier, W., Kattner, F., Ueda, K., Doumoto, K., \& Nakajima, Y. (2015). Memory disruption by irrelevant noise-vocoded speech: Effects of native language and the number of frequency bands. \emph{The Journal of the Acoustical Society of America}, \emph{138}(3), 1561--1569.

\leavevmode\vadjust pre{\hypertarget{ref-Erb2014}{}}%
Erb, J. (2014). \emph{{The neural dynamics of perceptual adaptation to degraded speech}} (p. 211) {[}Doctoral dissertation{]}. Universit{ä}t Leipzig.

\leavevmode\vadjust pre{\hypertarget{ref-Erb2013}{}}%
Erb, J., Henry, M. J., Eisner, F., \& Obleser, J. (2013). The Brain Dynamics of Rapid Perceptual Adaptation to Adverse Listening Conditions. \emph{Journal of Neuroscience}, \emph{33}(26), 10688--10697. \url{https://doi.org/10.1523/jneurosci.4596-12.2013}

\leavevmode\vadjust pre{\hypertarget{ref-Eyal2021}{}}%
Eyal, P., David, R., Andrew, G., Zak, E., \& Ekaterina, D. (2021). {Data quality of platforms and panels for online behavioral research}. \emph{Behavior Research Methods}, 1--20. \url{https://doi.org/10.3758/s13428-021-01694-3}

\leavevmode\vadjust pre{\hypertarget{ref-Fairbanks1957}{}}%
Fairbanks, G., \& Kodman Jr., F. (1957). {Word intelligibility as a function of time compression}. \emph{The Journal of the Acoustical Society of America}, \emph{29}(5), 636--641.

\leavevmode\vadjust pre{\hypertarget{ref-Federmeier2007a}{}}%
Federmeier, K. D. (2007). {Thinking ahead: The role and roots of prediction in language comprehension}. \emph{Psychophysiology}, \emph{44}(4), 491--505. \url{https://doi.org/10.1111/j.1469-8986.2007.00531.x}

\leavevmode\vadjust pre{\hypertarget{ref-Federmeier2010}{}}%
Federmeier, K. D., Kutas, M., \& Schul, R. (2010). {Age-related and individual differences in the use of prediction during language comprehension}. \emph{Brain and Language}, \emph{115}(3), 149--161. \url{https://doi.org/10.1016/j.bandl.2010.07.006}

\leavevmode\vadjust pre{\hypertarget{ref-Federmeier2007b}{}}%
Federmeier, K. D., Wlotko, E. W., De Ochoa-Dewald, E., \& Kutas, M. (2007). {Multiple effects of sentential constraint on word processing}. \emph{Brain Research}, \emph{1146}(1), 75--84. \url{https://doi.org/10.1016/j.brainres.2006.06.101}

\leavevmode\vadjust pre{\hypertarget{ref-Federmeier2002}{}}%
Federmeier, K., Mclennan, D., Ochoa, E. de, \& Kutas, M. (2002). {The impact of semantic memory organization and sentence context information on spoken language processing by younger and older adults: An ERP study}. \emph{Psychophysiology}, \emph{39}(02), 133--146.

\leavevmode\vadjust pre{\hypertarget{ref-Federmeier2007}{}}%
Federmeier, K., Wlotko, E. W., De Ochoa-Dewald, E., \& Kutas, M. (2007). Multiple effects of sentential constraint on word processing. \emph{Brain Research}, \emph{1146}, 75--84. \url{https://doi.org/10.1016/j.brainres.2006.06.101}

\leavevmode\vadjust pre{\hypertarget{ref-Fernandez2020}{}}%
Fernandez, L. B., Engelhardt, P. E., Patarroyo, A. G., \& Allen, S. E. M. (2020). {Effects of speech rate on anticipatory eye movements in the visual world paradigm: Evidence from aging, native, and non-native language processing}. \emph{Quarterly Journal of Experimental Psychology}, \emph{73}(12), 2348--2361. \url{https://doi.org/10.1177/1747021820948019}

\leavevmode\vadjust pre{\hypertarget{ref-Ferreira2018}{}}%
Ferreira, F., \& Chantavarin, S. (2018). {Integration and Prediction in Language Processing: A Synthesis of Old and New}. \emph{Current Directions in Psychological Science}, \emph{27}(6), 443--448. \url{https://doi.org/10.1177/0963721418794491}

\leavevmode\vadjust pre{\hypertarget{ref-Ferreira1986}{}}%
Ferreira, F., \& Clifton Jr, C. (1986). The independence of syntactic processing. \emph{Journal of Memory and Language}, \emph{25}(3), 348--368.

\leavevmode\vadjust pre{\hypertarget{ref-Ferreira2016}{}}%
Ferreira, F., \& Lowder, M. W. (2016). \emph{{Prediction, Information Structure, and Good-Enough Language Processing}} (Vol. 65, pp. 217--247). Elsevier Ltd. \url{https://doi.org/10.1016/bs.plm.2016.04.002}

\leavevmode\vadjust pre{\hypertarget{ref-Fontan2015}{}}%
Fontan, L., Tardieu, J., Gaillard, P., Woisard, V., \& Ruiz, R. (2015). Relationship Between Speech Intelligibility and Speech Comprehension in Babble Noise. \emph{Journal of Speech, Language, and Hearing Research}, \emph{58}(3), 977--986. \url{https://doi.org/10.1044/2015_jslhr-h-13-0335}

\leavevmode\vadjust pre{\hypertarget{ref-Forster1981}{}}%
Forster, K. I. (1981). Priming and the effects of sentence and lexical contexts on naming time: Evidence for autonomous lexical processing. \emph{The Quarterly Journal of Experimental Psychology}, \emph{33}(4), 465--495.

\leavevmode\vadjust pre{\hypertarget{ref-Frank2015}{}}%
Frank, S. L., Otten, L. J., Galli, G., \& Vigliocco, G. (2015). {The ERP response to the amount of information conveyed by words in sentences}. \emph{Brain and Language}, \emph{140}, 1--11. \url{https://doi.org/10.1016/j.bandl.2014.10.006}

\leavevmode\vadjust pre{\hypertarget{ref-Frisson2005}{}}%
Frisson, S., Rayner, K., \& Pickering, M. J. (2005). {Effects of contextual predictability and transitional probability on eye movements during reading}. \emph{Journal of Experimental Psychology: Learning Memory and Cognition}, \emph{31}(5), 862--877. \url{https://doi.org/10.1037/0278-7393.31.5.862}

\leavevmode\vadjust pre{\hypertarget{ref-Friston2009}{}}%
Friston, K. (2009). The free-energy principle: A rough guide to the brain? \emph{Trends in Cognitive Sciences}, \emph{13}(7), 293--301.

\leavevmode\vadjust pre{\hypertarget{ref-Friston2020}{}}%
Friston, K. J., Parr, T., Yufik, Y., Sajid, N., Price, C. J., Holmes, E., \& Square, Q. (2020). {Generative models, linguistic communication and active inference}. \emph{Neuroscience {\&} Biobehavioral Reviews}, \emph{118}, 42--64. \url{https://doi.org/10.1016/j.neubiorev.2020.07.005}

\leavevmode\vadjust pre{\hypertarget{ref-Friston2020b}{}}%
Friston, K. J., Sajid, N., Quiroga-Martinez, D. R., Parr, T., Price, C. J., \& Holmes, E. (2020). {Active listening}. \emph{Hearing Research}, \emph{xxxx}, 107998. \url{https://doi.org/10.1016/j.heares.2020.107998}

\leavevmode\vadjust pre{\hypertarget{ref-Fritz2007}{}}%
Fritz, J. B., Elhilali, M., David, S. V., \& Shamma, S. A. (2007). {Auditory attention - focusing the searchlight on sound}. \emph{Current Opinion in Neurobiology}, \emph{17}(4), 437--455. \url{https://doi.org/10.1016/j.conb.2007.07.011}

\leavevmode\vadjust pre{\hypertarget{ref-Gadiraju2017}{}}%
Gadiraju, U., Möller, S., Nöllenburg, M., Saupe, D., Egger-Lampl, S., Archambault, D., \& Fisher, B. (2017). {Crowdsourcing versus the laboratory: Towards human-centered experiments using the crowd}. In D. Archambault, H. Purchase, \& T. Hoßfeld (Eds.), \emph{Evaluation in the crowd. Crowdsourcing and human-centered experiments} (pp. 6--26). Springer, Cham. \url{https://doi.org/10.1007/978-3-319-66435-4_2}

\leavevmode\vadjust pre{\hypertarget{ref-Gagne2021}{}}%
Gagné, N., \& Franzen, L. (2021). \emph{How to run behavioural experiments online: Best practice suggestions for cognitive psychology and neuroscience}.

\leavevmode\vadjust pre{\hypertarget{ref-Ganong1980}{}}%
Ganong, W. F. (1980). Phonetic categorization in auditory word perception. \emph{Journal of Experimental Psychology: Human Perception and Performance}, \emph{6}(1), 110.

\leavevmode\vadjust pre{\hypertarget{ref-Garrido2011}{}}%
Garrido, M. I., Dolan, R. J., \& Sahani, M. (2011). Surprise Leads to Noisier Perceptual Decisions. \emph{I-Perception}, \emph{2}(2), 112--120. \url{https://doi.org/10.1068/i0411}

\leavevmode\vadjust pre{\hypertarget{ref-Garvey1953}{}}%
Garvey, W. D. (1953). {The intelligibility of speeded speech}. \emph{Journal of Experimental Psychology}, \emph{45}(2), 102--108. \url{https://doi.org/10.1037/h0054381}

\leavevmode\vadjust pre{\hypertarget{ref-Ghitza2009}{}}%
Ghitza, O., \& Greenberg, S. (2009). {On the possible role of brain rhythms in speech perception: Intelligibility of time-compressed speech with periodic and aperiodic insertions of silence}. \emph{Phonetica}, \emph{66}(1-2), 113--126. \url{https://doi.org/10.1159/000208934}

\leavevmode\vadjust pre{\hypertarget{ref-Gibson2013}{}}%
Gibson, E., Bergen, L., \& Piantadosi, S. T. (2013). Rational integration of noisy evidence and prior semantic expectations in sentence interpretation. \emph{Proceedings of the National Academy of Sciences}, \emph{110}(20), 8051--8056. \url{https://doi.org/10.1073/pnas.1216438110}

\leavevmode\vadjust pre{\hypertarget{ref-Gibson2019}{}}%
Gibson, E., Futrell, R., Piantadosi, S. P., Dautriche, I., Mahowald, K., Bergen, L., \& Levy, R. (2019). How efficiency shapes human language. \emph{Trends in Cognitive Sciences}, \emph{23}(5), 389--407. \url{https://doi.org/10.1016/j.tics.2019.02.003}

\leavevmode\vadjust pre{\hypertarget{ref-Gibson2000}{}}%
Gibson, E., \& Pearlmutter, N. J. (2000). Distinguishing serial and parallel parsing. \emph{Journal of Psycholinguistic Research}, \emph{29}(2), 231--240.

\leavevmode\vadjust pre{\hypertarget{ref-Gold2010}{}}%
Gold, J. I., \& Watanabe, T. (2010). Perceptual learning. \emph{Current Biology}, \emph{20}(2), R46--R48. \url{https://doi.org/10.1016/j.cub.2009.10.066}

\leavevmode\vadjust pre{\hypertarget{ref-Goldstone1998}{}}%
Goldstone, R. L. (1998). Perceptual learning. \emph{Annual Review of Psychology}, \emph{49}(1), 585--612. \url{https://doi.org/10.1146/annurev.psych.49.1.585}

\leavevmode\vadjust pre{\hypertarget{ref-Gordonsalant1995}{}}%
Gordon-Salant, S., \& Fitzgibbons, P. J. (1995). {Recognition of multiply degraded speech by young and elderly listeners}. \emph{Journal of Speech and Hearing Research}, \emph{38}(5), 1150--1156.

\leavevmode\vadjust pre{\hypertarget{ref-Gordonsalant2004}{}}%
Gordon-Salant, S., \& Fitzgibbons, P. J. (2004). {Effects of stimulus and noise rate variability on speech perception by younger and older adults}. \emph{The Journal of the Acoustical Society of America}, \emph{115}(4), 1808--1817. \url{https://doi.org/10.1121/1.1645249}

\leavevmode\vadjust pre{\hypertarget{ref-Goy2013}{}}%
Goy, H., Pelletier, M., Coletta, M., \& Pichora-Fuller, M. K. (2013). {The Effects of Semantic Context and the Type and Amount of Acoustic Distortion on Lexical Decision by Younger and Older Adults}. \emph{Journal of Speech, Language, and Hearing Research}, \emph{56}(6), 1715--1732. \url{https://doi.org/10.1044/1092-4388(2013/12-0053)}

\leavevmode\vadjust pre{\hypertarget{ref-Greenberg1996}{}}%
Greenberg, S. (1996). Auditory processing of speech. In N. J. Lass (Ed.), \emph{Principles of experimental phonetics} (pp. 362--407). Mosby, St. Louis.

\leavevmode\vadjust pre{\hypertarget{ref-Greenwood1990}{}}%
Greenwood, D. D. (1990). {A cochlear frequency-position function for several species---29 years later}. \emph{Journal of the Acoustical Society of America}, \emph{87}(6), 2592--2605. \url{https://doi.org/10.1121/1.399052}

\leavevmode\vadjust pre{\hypertarget{ref-Grueber2011}{}}%
Grueber, C. E., Nakagawa, S., Laws, R. J., \& Jamieson, I. G. (2011). Multimodel inference in ecology and evolution: challenges and solutions. \emph{Journal of Evolutionary Biology}, \emph{24}(4), 699--711. \url{https://doi.org/10.1111/j.1420-9101.2010.02210.x}

\leavevmode\vadjust pre{\hypertarget{ref-Guediche2014}{}}%
Guediche, S., Blumstein, S. E., Fiez, J. A., \& Holt, L. L. (2014). {Speech perception under adverse conditions: Insights from behavioral, computational, and neuroscience research}. \emph{Frontiers in Systems Neuroscience}, \emph{7}(Jan), 1--16. \url{https://doi.org/10.3389/fnsys.2013.00126}

\leavevmode\vadjust pre{\hypertarget{ref-Hafter2007}{}}%
Hafter, E. R., Sarampalis, A., \& Loui, P. (2007). {Auditory Attention and Filters}. In \emph{Auditory perception of sound sources} (Vol. 29, pp. 115--142). \url{https://doi.org/10.1007/978-0-387-71305-2_5}

\leavevmode\vadjust pre{\hypertarget{ref-Haider1996}{}}%
Haider, H., \& Frensch, P. A. (1996). The role of information reduction in skill acquisition. \emph{Cognitive Psychology}, \emph{30}(3), 304--337.

\leavevmode\vadjust pre{\hypertarget{ref-Hakonen2017}{}}%
Hakonen, M., May, P. J. C., Jääskeläinen, I. P., Jokinen, E., Sams, M., \& Tiitinen, H. (2017). Predictive processing increases intelligibility of acoustically distorted speech: Behavioral and neural correlates. \emph{Brain and Behavior}, \emph{7}(9), e00789. \url{https://doi.org/10.1002/brb3.789}

\leavevmode\vadjust pre{\hypertarget{ref-Hale2001}{}}%
Hale, J. (2001). A probabilistic earley parser as a psycholinguistic model. \emph{Second Meeting of the North American Chapter of the Association for Computational Linguistics}.

\leavevmode\vadjust pre{\hypertarget{ref-Hartwigsen2015}{}}%
Hartwigsen, G., Golombek, T., \& Obleser, J. (2015). Repetitive transcranial magnetic stimulation over left angular gyrus modulates the predictability gain in degraded speech comprehension. \emph{Cortex}, \emph{68}, 100--110. \url{https://doi.org/10.1016/j.cortex.2014.08.027}

\leavevmode\vadjust pre{\hypertarget{ref-Hauser2002}{}}%
Hauser, M. D., Chomsky, N., \& Fitch, W. T. (2002). The Faculty of Language: What Is It, Who Has It, and How Did It Evolve? \emph{Science}, \emph{298}(5598), 1569--1579. \url{https://doi.org/10.1126/science.298.5598.1569}

\leavevmode\vadjust pre{\hypertarget{ref-Heilbron2022}{}}%
Heilbron, M., Armeni, K., Schoffelen, J.-M., Hagoort, P., \& De Lange, F. P. (2022). A hierarchy of linguistic predictions during natural language comprehension. \emph{Proceedings of the National Academy of Sciences}, \emph{119}(32), e2201968119. \url{https://doi.org/10.1073/pnas.2201968119}

\leavevmode\vadjust pre{\hypertarget{ref-Hervais2019}{}}%
Hervais-Adelman, A., Kumar, U., Mishra, R. K., Tripathi, V. N., Guleria, A., Singh, J. P., Eisner, F., \& Huettig, F. (2019). Learning to read recycles visual cortical networks without destruction. \emph{Science Advances}, \emph{5}(9), eaax0262.

\leavevmode\vadjust pre{\hypertarget{ref-Heyselaar2021}{}}%
Heyselaar, E., Peeters, D., \& Hagoort, P. (2021). {Do we predict upcoming speech content in naturalistic environments?} \emph{Language, Cognition and Neuroscience}, \emph{36}(4), 440--461. \url{https://doi.org/10.1080/23273798.2020.1859568}

\leavevmode\vadjust pre{\hypertarget{ref-Hofmann2021}{}}%
Hofmann, M. J., Remus, S., Biemann, C., Radach, R., \& Kuchinke, L. (2021). Language models explain word reading times better than empirical predictability. \emph{Frontiers in Artificial Intelligence}, \emph{4}.

\leavevmode\vadjust pre{\hypertarget{ref-Huettig2019}{}}%
Huettig, F., \& Guerra, E. (2019). {Effects of speech rate, preview time of visual context, and participant instructions reveal strong limits on prediction in language processing}. \emph{Brain Research}, \emph{1706}(June 2017), 196--208. \url{https://doi.org/10.1016/j.brainres.2018.11.013}

\leavevmode\vadjust pre{\hypertarget{ref-Huettig2016a}{}}%
Huettig, F., \& Janse, E. (2016). Individual differences in working memory and processing speed predict anticipatory spoken language processing in the visual world. \emph{Language, Cognition and Neuroscience}, \emph{31}(1), 80--93.

\leavevmode\vadjust pre{\hypertarget{ref-Huettig2016}{}}%
Huettig, F., \& Mani, N. (2016). Is prediction necessary to understand language? Probably not. \emph{Language, Cognition and Neuroscience}, \emph{31}(1), 19--31. \url{https://doi.org/10.1080/23273798.2015.1072223}

\leavevmode\vadjust pre{\hypertarget{ref-Hunter2018}{}}%
Hunter, C. R., \& Pisoni, D. B. (2018). {Extrinsic cognitive load impairs spoken word recognition in high-and low-predictability sentences}. \emph{Ear and Hearing}, \emph{39}(2), 378--389. \url{https://doi.org/10.1097/AUD.0000000000000493}

\leavevmode\vadjust pre{\hypertarget{ref-Husband2020}{}}%
Husband, E. M., \& Bovolenta, G. (2020). {Prediction failure blocks the use of local semantic context}. \emph{Language, Cognition and Neuroscience}, \emph{35}(3), 273--291. \url{https://doi.org/10.1080/23273798.2019.1651881}

\leavevmode\vadjust pre{\hypertarget{ref-Ito2016}{}}%
Ito, A., Corley, M., Pickering, M. J., Martin, A. E., \& Nieuwland, M. S. (2016). {Predicting form and meaning: Evidence from brain potentials}. \emph{Journal of Memory and Language}, \emph{86}, 157--171. \url{https://doi.org/10.1016/j.jml.2015.10.007}

\leavevmode\vadjust pre{\hypertarget{ref-Iwasaki2002}{}}%
Iwasaki, S., Ocho, S., Nagura, M., \& Hoshino, T. (2002). {Contribution of speech rate to speech perception in multichannel cochlear implant users}. \emph{Annals of Otology, Rhinology and Laryngology}, \emph{111}(8), 718--721. \url{https://doi.org/10.1177/000348940211100811}

\leavevmode\vadjust pre{\hypertarget{ref-Jackendoff2002}{}}%
Jackendoff, R. (2002). \emph{Foundations of language: How language connects to the brain, the world, evolution, and thinking}. Oxford University Press.

\leavevmode\vadjust pre{\hypertarget{ref-Jaeger2008}{}}%
Jaeger, T. F. (2008). {Categorical data analysis: Away from ANOVAs (transformation or not) and towards logit mixed models}. \emph{Journal of Memory and Language}, \emph{59}(4), 434--446. \url{https://doi.org/10.1016/j.jml.2007.11.007}

\leavevmode\vadjust pre{\hypertarget{ref-Janse2009}{}}%
Janse, E. (2009). {Processing of fast speech by elderly listeners}. \emph{The Journal of the Acoustical Society of America}, \emph{125}(4), 2361--2373. \url{https://doi.org/10.1121/1.3082117}

\leavevmode\vadjust pre{\hypertarget{ref-Johnson2021}{}}%
Johnson, B. P., Dayan, E., Censor, N., \& Cohen, L. G. (2021). {Crowdsourcing in cognitive and systems neuroscience}. \emph{The Neuroscientist}, 10738584211017018. \url{https://doi.org/10.1177/10738584211017018}

\leavevmode\vadjust pre{\hypertarget{ref-Jones2011}{}}%
Jones, M., \& Love, B. C. (2011). {Bayesian fundamentalism or enlightenment? on the explanatory status and theoretical contributions of bayesian models of cognition}. \emph{Behavioral and Brain Sciences}, \emph{34}(4), 169--188. \url{https://doi.org/10.1017/S0140525X10003134}

\leavevmode\vadjust pre{\hypertarget{ref-Kaiser2004}{}}%
Kaiser, E., \& Trueswell, J. (2004). The role of discourse context in the processing of a flexible word-order language. \emph{Cognition}, \emph{94}(2), 113--147. \url{https://doi.org/10.1016/j.cognition.2004.01.002}

\leavevmode\vadjust pre{\hypertarget{ref-Kamide2003}{}}%
Kamide, Y., Altmann, G. T. M., \& Haywood, S. L. (2003). The time-course of prediction in incremental sentence processing: Evidence from anticipatory eye movements. \emph{Journal of Memory and Language}, \emph{49}(1), 133--156. \url{https://doi.org/10.1016/s0749-596x(03)00023-8}

\leavevmode\vadjust pre{\hypertarget{ref-Kaufeld2021}{}}%
Kaufeld, G. (2021). \emph{Investigating spoken language comprehension as perceptual inference} (p. 183) {[}Doctoral dissertation{]}. Max Planck Research School (IMPRS) for Language Sciences.

\leavevmode\vadjust pre{\hypertarget{ref-Kemper1999}{}}%
Kemper, S., \& Harden, T. (1999). {Experimentally disentangling what's beneficial about elderspeak from what's not}. \emph{Psychology and Aging}, \emph{14}(4), 656--670. \url{https://doi.org/10.1037/0882-7974.14.4.656}

\leavevmode\vadjust pre{\hypertarget{ref-Knoeferle2005}{}}%
Knoeferle, P., Crocker, M. W., Scheepers, C., \& Pickering, M. J. (2005). The influence of the immediate visual context on incremental thematic role-assignment: evidence from eye-movements in depicted events. \emph{Cognition}, \emph{95}(1), 95--127. \url{https://doi.org/10.1016/j.cognition.2004.03.002}

\leavevmode\vadjust pre{\hypertarget{ref-Koch2016}{}}%
Koch, X., \& Janse, E. (2016). {Speech rate effects on the processing of conversational speech across the adult life span}. \emph{The Journal of the Acoustical Society of America}, \emph{139}(4), 1618--1636. \url{https://doi.org/10.1121/1.4944032}

\leavevmode\vadjust pre{\hypertarget{ref-Kochari2019}{}}%
Kochari, A. R., \& Flecken, M. (2019). {Lexical prediction in language comprehension: a replication study of grammatical gender effects in Dutch}. \emph{Language, Cognition and Neuroscience}, \emph{34}(2), 239--253. \url{https://doi.org/10.1080/23273798.2018.1524500}

\leavevmode\vadjust pre{\hypertarget{ref-Kok2012}{}}%
Kok, P., Rahnev, D., Jehee, J. F. M., Lau, H. C., \& De Lange, F. P. (2012). {Attention reverses the effect of prediction in silencing sensory signals}. \emph{Cerebral Cortex}, \emph{22}(9), 2197--2206. \url{https://doi.org/10.1093/cercor/bhr310}

\leavevmode\vadjust pre{\hypertarget{ref-Kuperberg2020}{}}%
Kuperberg, G. R. (2021). {Tea with milk? A hierarchical generative framework of sequential event comprehension}. \emph{Topics in Cognitive Science}, \emph{13}(1), 256--298. \url{https://doi.org/10.1111/tops.12518}

\leavevmode\vadjust pre{\hypertarget{ref-Kuperberg2016}{}}%
Kuperberg, G. R., \& Jaeger, T. F. (2016). What do we mean by prediction in language comprehension? \emph{Language, Cognition and Neuroscience}, \emph{31}(1), 32--59. \url{https://doi.org/10.1080/23273798.2015.1102299}

\leavevmode\vadjust pre{\hypertarget{ref-Kutas2011}{}}%
Kutas, M., \& Federmeier, K. D. (2011). Thirty Years and Counting: Finding Meaning in the N400 Component of the Event-Related Brain Potential (ERP). \emph{Annual Review of Psychology}, \emph{62}(1), 621--647. \url{https://doi.org/10.1146/annurev.psych.093008.131123}

\leavevmode\vadjust pre{\hypertarget{ref-Kutas1984}{}}%
Kutas, M., \& Hillyard, S. A. (1984). Brain potentials during reading reflect word expectancy and semantic association. \emph{Nature}, \emph{307}(5947), 161--163. \url{https://doi.org/10.1038/307161a0}

\leavevmode\vadjust pre{\hypertarget{ref-Kuznetsova2017}{}}%
Kuznetsova, A., Brockhoff, P. B., \& Christensen, R. H. B. (2017). lmerTest Package: Tests in Linear Mixed Effects Models. \emph{Journal of Statistical Software}, \emph{82}(13). \url{https://doi.org/10.18637/jss.v082.i13}

\leavevmode\vadjust pre{\hypertarget{ref-Lange2013}{}}%
Lange, K. (2013). {The ups and downs of temporal orienting: A review of auditory temporal orienting studies and a model associating the heterogeneous findings on the auditory N1 with opposite effects of attention and prediction}. \emph{Frontiers in Human Neuroscience}, \emph{7}, 1--14. \url{https://doi.org/10.3389/fnhum.2013.00263}

\leavevmode\vadjust pre{\hypertarget{ref-Lange2010}{}}%
Lange, K., \& Röder, B. (2010). Temporal orienting in audition, touch, and across modalities. \emph{Attention and Time}, 393--405.

\leavevmode\vadjust pre{\hypertarget{ref-LeCompte1995}{}}%
Lecompte, D. C. (1995). An irrelevant speech effect with repeated and continuous background speech. \emph{Psychonomic Bulletin \& Review}, \emph{2}(3), 391--397.

\leavevmode\vadjust pre{\hypertarget{ref-Leensen2013}{}}%
Leensen, M. C. J., \& Dreschler, W. A. (2013). {Speech-in-noise screening tests by internet, Part 3: Test sensitivity for uncontrolled parameters in domestic usage}. \emph{International Journal of Audiology}, \emph{52}(10), 658--669. \url{https://doi.org/10.3109/14992027.2013.803610}

\leavevmode\vadjust pre{\hypertarget{ref-Lerner2014}{}}%
Lerner, Y., Honey, C. J., Katkov, M., \& Hasson, U. (2014). {Temporal scaling of neural responses to compressed and dilated natural speech}. \emph{Journal of Neurophysiology}, \emph{111}(12), 2433--2444. \url{https://doi.org/10.1152/jn.00497.2013}

\leavevmode\vadjust pre{\hypertarget{ref-Levy2008}{}}%
Levy, R. (2008). Expectation-based syntactic comprehension. \emph{Cognition}, \emph{106}(3), 1126--1177. \url{https://doi.org/10.1016/j.cognition.2007.05.006}

\leavevmode\vadjust pre{\hypertarget{ref-Li2014}{}}%
Li, J., Xia, R., Ying, D., Yan, Y., \& Akagi, M. (2014). {Investigation of objective measures for intelligibility prediction of noise-reduced speech for Chinese, Japanese, and English}. \emph{The Journal of the Acoustical Society of America}, \emph{136}(6), 3301--3312. \url{https://doi.org/10.1121/1.4901079}

\leavevmode\vadjust pre{\hypertarget{ref-Li2017}{}}%
Li, X., Zhang, Y., Li, L., Zhao, H., \& Du, X. (2017). {Attention is shaped by semantic level of event-structure during speech comprehension: An electroencephalogram study}. \emph{Cognitive Neurodynamics}, \emph{11}(5), 467--481. \url{https://doi.org/10.1007/s11571-017-9442-4}

\leavevmode\vadjust pre{\hypertarget{ref-Lieberman2013}{}}%
Lieberman, P. (2013). The unpredictable species. In \emph{The unpredictable species}. Princeton University Press.

\leavevmode\vadjust pre{\hypertarget{ref-Liu2006}{}}%
Liu, S., \& Zeng, F.-G. (2006). {Temporal properties in clear speech perception}. \emph{The Journal of the Acoustical Society of America}, \emph{120}(1), 424--432. \url{https://doi.org/10.1121/1.2208427}

\leavevmode\vadjust pre{\hypertarget{ref-Loizou1999}{}}%
Loizou, P. C., Dorman, M., \& Tu, Z. (1999). On the number of channels needed to understand speech. \emph{The Journal of the Acoustical Society of America}, \emph{106}(4), 2097--2103. \url{https://doi.org/10.1121/1.427954}

\leavevmode\vadjust pre{\hypertarget{ref-Longster2003}{}}%
Longster, J. A. (2003). \emph{{Concatenative Speech Synthesis : A Framework for Reducing Perceived Distortion when using the TD-PSOLA Algorithm}} {[}Doctoral dissertation{]}. Bournemouth University.

\leavevmode\vadjust pre{\hypertarget{ref-Lopukhina2021}{}}%
Lopukhina, A., Lopukhin, K., \& Laurinavichyute, A. (2021). Morphosyntactic but not lexical corpus-based probabilities can substitute for cloze probabilities in reading experiments. \emph{PloS One}, \emph{16}(1), e0246133.

\leavevmode\vadjust pre{\hypertarget{ref-Lorch1990}{}}%
Lorch, R. F., \& Myers, J. L. (1990). Regression analyses of repeated measures data in cognitive research. \emph{Journal of Experimental Psychology: Learning, Memory, and Cognition}, \emph{16}(1), 149.

\leavevmode\vadjust pre{\hypertarget{ref-Love2009}{}}%
Love, T., Walenski, M., \& Swinney, D. (2009). {Slowed speech input has a differential impact on on-line and off-line processing in children's comprehension of pronouns}. \emph{Journal of Psycholinguistic Research}, \emph{38}(3), 285--304. \url{https://doi.org/10.1007/s10936-009-9103-9}

\leavevmode\vadjust pre{\hypertarget{ref-Lowder2016}{}}%
Lowder, M. W., \& Ferreira, F. (2016). {Prediction in the processing of repair disfluencies}. \emph{Language, Cognition and Neuroscience}, \emph{31}(1), 73--79. \url{https://doi.org/10.1080/23273798.2015.1036089}

\leavevmode\vadjust pre{\hypertarget{ref-Luce1998}{}}%
Luce, P. A., \& Pisoni, D. B. (1998). Recognizing spoken words: The neighborhood activation model. \emph{Ear and Hearing}, \emph{19}(1), 1.

\leavevmode\vadjust pre{\hypertarget{ref-Luke2016}{}}%
Luke, S. G., \& Christianson, K. (2016). Limits on lexical prediction during reading. \emph{Cognitive Psychology}, \emph{88}, 22--60. \url{https://doi.org/10.1016/j.cogpsych.2016.06.002}

\leavevmode\vadjust pre{\hypertarget{ref-Lupyan2015}{}}%
Lupyan, G., \& Clark, A. (2015). Words and the World. \emph{Current Directions in Psychological Science}, \emph{24}(4), 279--284. \url{https://doi.org/10.1177/0963721415570732}

\leavevmode\vadjust pre{\hypertarget{ref-Malik2020}{}}%
Malik, W. A., Marco-Llorca, C., Berendzen, K., \& Piepho, H. P. (2020). {Choice of link and variance function for generalized linear mixed models: a case study with binomial response in proteomics}. \emph{Communications in Statistics - Theory and Methods}, \emph{49}(17), 4313--4332. \url{https://doi.org/10.1080/03610926.2019.1599021}

\leavevmode\vadjust pre{\hypertarget{ref-Mantegna2019}{}}%
Mantegna, F., Hintz, F., Ostarek, M., Alday, P. M., \& Huettig, F. (2019). Distinguishing integration and prediction accounts of ERP N400 modulations in language processing through experimental design. \emph{Neuropsychologia}, \emph{134}, 107199.

\leavevmode\vadjust pre{\hypertarget{ref-Markman2011}{}}%
Markman, A. B., \& Otto, A. R. (2011). Cognitive systems optimize energy rather than information. \emph{Behav. Brain Sci}, \emph{34}(207), 10--1017.

\leavevmode\vadjust pre{\hypertarget{ref-Marques2018}{}}%
Marques, T., Nguyen, J., Fioreze, G., \& Petreanu, L. (2018). The functional organization of cortical feedback inputs to primary visual cortex. \emph{Nature Neuroscience}, \emph{21}(5), 757--764. \url{https://doi.org/10.1038/s41593-018-0135-z}

\leavevmode\vadjust pre{\hypertarget{ref-Marrufo2019}{}}%
Marrufo-Pérez, M. I., Eustaquio-Martı́n, A., \& Lopez-Poveda, E. A. (2019). Speech predictability can hinder communication in difficult listening conditions. \emph{Cognition}, \emph{192}, 103992. \url{https://doi.org/10.1016/j.cognition.2019.06.004}

\leavevmode\vadjust pre{\hypertarget{ref-Martin2016}{}}%
Martin, A. E. (2016). Language processing as cue integration: Grounding the psychology of language in perception and neurophysiology. \emph{Frontiers in Psychology}, \emph{7}, 120.

\leavevmode\vadjust pre{\hypertarget{ref-Mattys2012}{}}%
Mattys, S. L., Davis, M. H., Bradlow, A. R., \& Scott, S. K. (2012). {Speech recognition in adverse conditions: A review}. \emph{Language and Cognitive Processes}, \emph{27}(7-8), 953--978. \url{https://doi.org/10.1080/01690965.2012.705006}

\leavevmode\vadjust pre{\hypertarget{ref-Matuschek2017}{}}%
Matuschek, H., Kliegl, R., Vasishth, S., Baayen, H., \& Bates, D. (2017). Balancing type i error and power in linear mixed models. \emph{Journal of Memory and Language}, \emph{94}, 305--315.

\leavevmode\vadjust pre{\hypertarget{ref-Mcclelland1986}{}}%
McClelland, J. L., \& Elman, J. L. (1986). {The TRACE model of speech perception}. \emph{Cognitive Psychology}, \emph{18}(1), 1--86. \url{https://doi.org/10.1016/0010-0285(86)90015-0}

\leavevmode\vadjust pre{\hypertarget{ref-Mccullough1958}{}}%
McCullough, C. M. (1958). {Context aids reading}. \emph{The Reading Teacher}, \emph{11}(4), 225--229.

\leavevmode\vadjust pre{\hypertarget{ref-McGurk1976}{}}%
McGurk, H., \& MacDonald, J. (1976). Hearing lips and seeing voices. \emph{Nature}, \emph{264}(5588), 746--748.

\leavevmode\vadjust pre{\hypertarget{ref-McKeever1977}{}}%
McKeever, W. F., \& VanDeventer, A. D. (1977). Visual and auditory language processing asymmetries: Influences of handedness, familial sinistrality, and sex. \emph{Cortex}, \emph{13}(3), 225--241.

\leavevmode\vadjust pre{\hypertarget{ref-Meng2019}{}}%
Meng, Q., Wang, X., Cai, Y., Kong, F., Buck, A. N., Yu, G., Zheng, N., \& Schnupp, J. W. H. (2019). {Time-compression thresholds for Mandarin sentences in normal-hearing and cochlear implant listeners}. \emph{Hearing Research}, \emph{374}, 58--68. \url{https://doi.org/10.1016/j.heares.2019.01.011}

\leavevmode\vadjust pre{\hypertarget{ref-Metusalem2012}{}}%
Metusalem, R., Kutas, M., Urbach, T. P., Hare, M., McRae, K., \& Elman, J. L. (2012). Generalized event knowledge activation during online sentence comprehension. \emph{Journal of Memory and Language}, \emph{66}(4), 545--567. \url{https://doi.org/10.1016/j.jml.2012.01.001}

\leavevmode\vadjust pre{\hypertarget{ref-Michaelov2022}{}}%
Michaelov, J. A., Coulson, S., \& Bergen, B. K. (2022). So cloze yet so far: N400 amplitude is better predicted by distributional information than human predictability judgements. \emph{IEEE Transactions on Cognitive and Developmental Systems}.

\leavevmode\vadjust pre{\hypertarget{ref-Miller1951}{}}%
Miller, G. A., Heise, G. A., \& Lichten, W. (1951). {The intelligibility of speech as a function of the context of the test materials}. \emph{Journal of Experimental Psychology}, \emph{41}(5), 329--335.

\leavevmode\vadjust pre{\hypertarget{ref-Minocher2021}{}}%
Minocher, R., Atmaca, S., Bavero, C., McElreath, R., \& Beheim, B. (2021). Estimating the reproducibility of social learning research published between 1955 and 2018. \emph{Royal Society Open Science}, \emph{8}(9), 210450.

\leavevmode\vadjust pre{\hypertarget{ref-Mishra2012}{}}%
Mishra, R. K., Singh, N., Pandey, A., \& Huettig, F. (2012). {Spoken language-mediated anticipatory eye- movements are modulated by reading ability - Evidence from Indian low and high literates}. \emph{Journal of Eye Movement Research}, \emph{5}(1), 1--10. \url{https://doi.org/10.16910/jemr.5.1.3}

\leavevmode\vadjust pre{\hypertarget{ref-Moon2014a}{}}%
Moon, I. J., \& Hong, S. H. (2014). What is temporal fine structure and why is it important? \emph{Korean Journal of Audiology}, \emph{18}(1), 1--7. \url{https://doi.org/10.7874/kja.2014.18.1.1}

\leavevmode\vadjust pre{\hypertarget{ref-Moon2014}{}}%
Moon, I. J., Won, J. H., Park, M. H., Ives, D. T., Nie, K., Heinz, M. G., Lorenzi, C., \& Rubinstein, J. T. (2014). Optimal combination of neural temporal envelope and fine structure cues to explain speech identification in background noise. \emph{Journal of Neuroscience}, \emph{34}(36), 12145--12154. \url{https://doi.org/10.1523/JNEUROSCI.1025-14.2014}

\leavevmode\vadjust pre{\hypertarget{ref-Morton1964}{}}%
Morton, J. (1964). {The effects of context on the visual duration threshold for words}. \emph{British Journal of Psychology}, \emph{55}(2), 165--180. \url{https://doi.org/10.1111/j.2044-8295.1964.tb02716.x}

\leavevmode\vadjust pre{\hypertarget{ref-Moulines1990}{}}%
Moulines, E., \& Charpentier, F. (1990). {Pitch-synchronous waveform processing techniques for text-to-speech synthesis using diphones}. \emph{Speech Communication}, \emph{9}(1990), 453--467.

\leavevmode\vadjust pre{\hypertarget{ref-Mueller2019}{}}%
Müller, J. A., Wendt, D., Kollmeier, B., Debener, S., \& Brand, T. (2019). {Effect of speech rate on neural tracking of speech}. \emph{Frontiers in Psychology}, \emph{10}. \url{https://doi.org/10.3389/fpsyg.2019.00449}

\leavevmode\vadjust pre{\hypertarget{ref-Musch2000}{}}%
Musch, J., \& Reips, U.-D. (2000). {A brief history of web experimenting}. In \emph{Psychological experiments on the internet} (pp. 61--87). \url{https://doi.org/10.1016/b978-012099980-4/50004-6}

\leavevmode\vadjust pre{\hypertarget{ref-Naatanen1987}{}}%
Näätänen, R., \& Picton, T. (1987). {The N1 wave of the human electric and magnetic response to sound: A review and an analysis of the component structure}. \emph{Psychophysiology}, \emph{24}(4), 375--425. \url{https://doi.org/10.1111/j.1469-8986.1987.tb00311.x}

\leavevmode\vadjust pre{\hypertarget{ref-Nahum2008}{}}%
Nahum, M., Nelken, I., \& Ahissar, M. (2008). {Low-level information and high-level perception: The case of speech in noise}. \emph{PLoS Biology}, \emph{6}(5), 0978--0991. \url{https://doi.org/10.1371/journal.pbio.0060126}

\leavevmode\vadjust pre{\hypertarget{ref-Nejime1998}{}}%
Nejime, Y., \& Moore, B. C. J. (1998). {Evaluation of the effect of speech-rate slowing on speech intelligibility in noise using a simulation of cochlear hearing loss}. \emph{The Journal of the Acoustical Society of America}, \emph{103}(1), 572--576. \url{https://doi.org/10.1121/1.421123}

\leavevmode\vadjust pre{\hypertarget{ref-Nicenboim2020}{}}%
Nicenboim, B., Vasishth, S., \& Rösler, F. (2020). Are words pre-activated probabilistically during sentence comprehension? Evidence from new data and a Bayesian random-effects meta-analysis using publicly available data. \emph{Neuropsychologia}, \emph{142}, 107427. \url{https://doi.org/10.1016/j.neuropsychologia.2020.107427}

\leavevmode\vadjust pre{\hypertarget{ref-Nieuwland2019}{}}%
Nieuwland, M. S. (2019). {Do `early' brain responses reveal word form prediction during language comprehension? A critical review}. \emph{Neuroscience and Biobehavioral Reviews}, \emph{96}, 367--400. \url{https://doi.org/10.1016/j.neubiorev.2018.11.019}

\leavevmode\vadjust pre{\hypertarget{ref-Nieuwland2020a}{}}%
Nieuwland, M. S., Barr, D. J., Bartolozzi, F., Busch-Moreno, S., Darley, E., Donaldson, D. I., Ferguson, H. J., Fu, X., Heyselaar, E., Huettig, F., Husband, E. M., Ito, A., Kazanina, N., Kogan, V., Kohút, Z., Kulakova, E., Mézière, D., Politzer-Ahles, S., Rousselet, G., \ldots{} Von Grebmer Zu Wolfsthurn, S. (2020). {Dissociable effects of prediction and integration during language comprehension: Evidence from a largescale study using brain potentials}. \emph{Philosophical Transactions of the Royal Society B: Biological Sciences}. \url{https://doi.org/10.1098/rstb.2018.0522}

\leavevmode\vadjust pre{\hypertarget{ref-Nieuwland2018}{}}%
Nieuwland, M. S., Politzer-Ahles, S., Heyselaar, E., Segaert, K., Darley, E., Kazanina, N., Von Grebmer Zu Wolfsthurn, S., Bartolozzi, F., Kogan, V., Ito, A., Mézière, D., Barr, D. J., Rousselet, G. A., Ferguson, H. J., Busch-Moreno, S., Fu, X., Tuomainen, J., Kulakova, E., Husband, E. M., \ldots{} Huettig, F. (2018). {Large-scale replication study reveals a limit on probabilistic prediction in language comprehension}. \emph{eLife}, \emph{7}, 1--24. \url{https://doi.org/10.7554/elife.33468}

\leavevmode\vadjust pre{\hypertarget{ref-Norris2016}{}}%
Norris, D., McQueen, J. M., \& Cutler, A. (2016). {Prediction, Bayesian inference and feedback in speech recognition}. \emph{Language, Cognition and Neuroscience}, \emph{31}(1), 4--18. \url{https://doi.org/10.1080/23273798.2015.1081703}

\leavevmode\vadjust pre{\hypertarget{ref-Nosofsky1986}{}}%
Nosofsky, R. M. (1986). Attention, similarity, and the identification--categorization relationship. \emph{Journal of Experimental Psychology: General}, \emph{115}(1), 39.

\leavevmode\vadjust pre{\hypertarget{ref-Obleser2014}{}}%
Obleser, J. (2014). Putting the Listening Brain in Context. \emph{Language and Linguistics Compass}, \emph{8}(12), 646--658. \url{https://doi.org/10.1111/lnc3.12098}

\leavevmode\vadjust pre{\hypertarget{ref-Obleser2010}{}}%
Obleser, J., \& Kotz, S. A. (2010). Expectancy Constraints in Degraded Speech Modulate the Language Comprehension Network. \emph{Cerebral Cortex}, \emph{20}(3), 633--640. \url{https://doi.org/10.1093/cercor/bhp128}

\leavevmode\vadjust pre{\hypertarget{ref-Obleser2011}{}}%
Obleser, J., \& Kotz, S. A. (2011). Multiple brain signatures of integration in the comprehension of degraded speech. \emph{NeuroImage}, \emph{55}(2), 713--723. \url{https://doi.org/10.1016/j.neuroimage.2010.12.020}

\leavevmode\vadjust pre{\hypertarget{ref-Obleser2007}{}}%
Obleser, J., Wise, R. J. S., Alex Dresner, M., \& Scott, S. K. (2007). Functional Integration across Brain Regions Improves Speech Perception under Adverse Listening Conditions. \emph{Journal of Neuroscience}, \emph{27}(9), 2283--2289. \url{https://doi.org/10.1523/jneurosci.4663-06.2007}

\leavevmode\vadjust pre{\hypertarget{ref-Oostdijk2000}{}}%
Oostdijk, N. (2000). {The spoken Dutch corpus: Overview and first evaluation}. \emph{2nd International Conference on Language Resources and Evaluation, LREC 2000}, \emph{January 2000}.

\leavevmode\vadjust pre{\hypertarget{ref-Orena2021}{}}%
Orena, A. J., \& Colby, S. (2021). \emph{Recognizing voices through a cochlear implant: A systematic review}.

\leavevmode\vadjust pre{\hypertarget{ref-Parida2022}{}}%
Parida, S., \& Heinz, M. G. (2022). Underlying neural mechanisms of degraded speech intelligibility following noise-induced hearing loss: The importance of distorted tonotopy: Neural mechanisms of degraded speech intelligibility. \emph{Hearing Research}, 108586.

\leavevmode\vadjust pre{\hypertarget{ref-Patro2020}{}}%
Patro, C., \& Mendel, L. L. (2020). Semantic influences on the perception of degraded speech by individuals with cochlear implants. \emph{The Journal of the Acoustical Society of America}, \emph{147}(3), 1778--1789. \url{https://doi.org/10.1121/10.0000934}

\leavevmode\vadjust pre{\hypertarget{ref-Pearl1985}{}}%
Pearl, J. (1985). {Bayesian networks: A model of self-activated memory for evidential reasoning}. \emph{Proceedings of the 7th Conference of the Cognitive Science Society}, 329--334.

\leavevmode\vadjust pre{\hypertarget{ref-Peelle2013}{}}%
Peelle, J. E. (2013). Cortical responses to degraded speech are modulated by linguistic predictions. \emph{Proceedings of Meetings on Acoustics Ica2013}, \emph{19}, 060108.

\leavevmode\vadjust pre{\hypertarget{ref-Peelle2018}{}}%
Peelle, J. E. (2018). {Listening effort: How the cognitive consequences of acoustic challenge are reflected in brain and behavior}. \emph{Ear and Hearing}, \emph{39}(2), 204--214. \url{https://doi.org/10.1097/AUD.0000000000000494}

\leavevmode\vadjust pre{\hypertarget{ref-Peelle2005}{}}%
Peelle, J. E., \& Wingfield, A. (2005). {Dissociations in perceptual learning revealed by adult age differences in adaptation to time-compressed speech}. \emph{Journal of Experimental Psychology: Human Perception and Performance}, \emph{31}(6), 1315--1330. \url{https://doi.org/10.1037/0096-1523.31.6.1315}

\leavevmode\vadjust pre{\hypertarget{ref-Peirce2019}{}}%
Peirce, J., Gray, J. R., Simpson, S., MacAskill, M., Höchenberger, R., Sogo, H., Kastman, E., \& Lindeløv, J. K. (2019). {PsychoPy2: Experiments in behavior made easy}. \emph{Behavior Research Methods}, \emph{51}(1), 195--203. \url{https://doi.org/10.3758/s13428-018-01193-y}

\leavevmode\vadjust pre{\hypertarget{ref-Pickering2018}{}}%
Pickering, M. J., \& Gambi, C. (2018). Predicting while comprehending language: A theory and review. \emph{Psychological Bulletin}, \emph{144}(10), 1002--1044. \url{https://doi.org/10.1037/bul0000158}

\leavevmode\vadjust pre{\hypertarget{ref-Pierce1987}{}}%
Pierce, A. G. J., \& Ollason, J. G. (1987). {Eight reasons why optimal foraging theory is a complete waste of time}. \emph{Oikos}, \emph{49}(1), 111--117. \url{https://www.jstor.org/stable/3565560}

\leavevmode\vadjust pre{\hypertarget{ref-Pinker2005a}{}}%
Pinker, S., \& Jackendoff, R. (2005). The faculty of language: what's special about it? \emph{Cognition}, \emph{95}(2), 201--236. \url{https://doi.org/10.1016/j.cognition.2004.08.004}

\leavevmode\vadjust pre{\hypertarget{ref-Poldrack1998}{}}%
Poldrack, R., Protopapas, A., Nagarajan, S., Tallal, P., Merzenich, M., Temple, E., \& Gabrieli, J. (1998). Auditory processing of temporally compressed speech: An fMRI study. \emph{Journal of Cognitive Neuroscience}, \emph{10}, 126--126.

\leavevmode\vadjust pre{\hypertarget{ref-Prolific}{}}%
Prolific. (2014). \emph{Prolific academic}. \url{https://www.prolific.co}.

\leavevmode\vadjust pre{\hypertarget{ref-Pusse2016}{}}%
Pusse, F., Sayeed, A., \& Demberg, V. (2016). {LingoTurk: Managing crowdsourced tasks for psycholinguistics}. \emph{Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Demonstrations}, 57--61. \url{https://doi.org/10.18653/v1/n16-3012}

\leavevmode\vadjust pre{\hypertarget{ref-Rayner2006}{}}%
Rayner, K., Reichle, E. D., Stroud, M. J., Williams, C. C., \& Pollatsek, A. (2006). The effect of word frequency, word predictability, and font difficulty on the eye movements of young and older readers. \emph{Psychology and Aging}, \emph{21}(3), 448.

\leavevmode\vadjust pre{\hypertarget{ref-Reips2021}{}}%
Reips, U.-D. (2021). Web-based research in psychology. \emph{Zeitschrift f{ü}r Psychologie}.

\leavevmode\vadjust pre{\hypertarget{ref-Richards2011}{}}%
Richards, S. A., Whittingham, M. J., \& Stephens, P. A. (2011). Model selection and model averaging in behavioural ecology: the utility of the IT-AIC framework. \emph{Behavioral Ecology and Sociobiology}, \emph{65}(1), 77--89. \url{https://doi.org/10.1007/s00265-010-1035-8}

\leavevmode\vadjust pre{\hypertarget{ref-Roberts2011}{}}%
Roberts, B., Summers, R. J., \& Bailey, P. J. (2011). The intelligibility of noise-vocoded speech: Spectral information available from acrosschannel comparison of amplitude envelopes. \emph{Proceedings of the Royal Society B: Biological Sciences}, \emph{278}(1711), 1595--1600. \url{https://doi.org/10.1098/rspb.2010.1554}

\leavevmode\vadjust pre{\hypertarget{ref-Robinson2018}{}}%
Robinson, C. W., Moore Jr, R. L., \& Crook, T. A. (2018). Bimodal presentation speeds up auditory processing and slows down visual processing. \emph{Frontiers in Psychology}, \emph{9}, 2454.

\leavevmode\vadjust pre{\hypertarget{ref-Rodero2016}{}}%
Rodero, E. (2016). {Influence of speech rate and information density on recognition: The moderate dynamic mechanism}. \emph{Media Psychology}, \emph{19}(2), 224--242. \url{https://doi.org/10.1080/15213269.2014.1002942}

\leavevmode\vadjust pre{\hypertarget{ref-Rommers2015}{}}%
Rommers, J., Meyer, A. S., \& Huettig, F. (2015). Verbal and nonverbal predictors of language-mediated anticipatory eye movements. \emph{Attention, Perception, \& Psychophysics}, \emph{77}(3), 720--730.

\leavevmode\vadjust pre{\hypertarget{ref-Roennberg2013}{}}%
Rönnberg, J., Lunner, T., Zekveld, A., Sörqvist, P., Danielsson, H., Lyxell, B., Dahlström, Ö., Signoret, C., Stenfelt, S., Pichora-Fuller, M. K., \& Rudner, M. (2013). {The Ease of Language Understanding (ELU) model: Theoretical, empirical, and clinical advances}. \emph{Frontiers in Systems Neuroscience}, \emph{7}(31), 1--17. \url{https://doi.org/10.3389/fnsys.2013.00031}

\leavevmode\vadjust pre{\hypertarget{ref-Rosen1999}{}}%
Rosen, S., Faulkner, A., \& Wilkinson, L. (1999). Adaptation by normal listeners to upward spectral shifts of speech: Implications for cochlear implants. \emph{The Journal of the Acoustical Society of America}, \emph{106}(6), 3629--3636. \url{https://doi.org/10.1121/1.428215}

\leavevmode\vadjust pre{\hypertarget{ref-Ryskin2021}{}}%
Ryskin, R., \& Fang, X. (2021). The many timescales of context in language processing. In \emph{Psychology of learning and motivation} (Vol. 75, pp. 201--243). Elsevier. \url{https://doi.org/10.1016/bs.plm.2021.08.001}

\leavevmode\vadjust pre{\hypertarget{ref-Ryskin2018}{}}%
Ryskin, R., Futrell, R., Kiran, S., \& Gibson, E. (2018). {Comprehenders model the nature of noise in the environment}. \emph{Cognition}, \emph{181}(July 2017), 141--150. \url{https://doi.org/10.1016/j.cognition.2018.08.018}

\leavevmode\vadjust pre{\hypertarget{ref-Samuel1996}{}}%
Samuel, A. G. (1996). Does lexical information influence the perceptual restoration of phonemes? \emph{Journal of Experimental Psychology: General}, \emph{125}(1), 28.

\leavevmode\vadjust pre{\hypertarget{ref-Samuel2009}{}}%
Samuel, A. G., \& Kraljic, T. (2009). Perceptual learning for speech. \emph{Attention, Perception, \& Psychophysics}, \emph{71}(6), 1207--1218. \url{https://doi.org/10.3758/app.71.6.1207}

\leavevmode\vadjust pre{\hypertarget{ref-Sanders2008}{}}%
Sanders, L. D., \& Astheimer, L. B. (2008). {Temporally selective attention modulates early perceptual processing: Event-related potential evidence}. \emph{Perception and Psychophysics}, \emph{70}(4), 732--742. \url{https://doi.org/10.3758/PP.70.4.732}

\leavevmode\vadjust pre{\hypertarget{ref-Sanderson2008}{}}%
Sanderson, S. K., \& Roberts, W. W. (2008). {The evolutionary forms of the religious life: A cross-cultural, quantitative analysis}. \emph{American Anthropologist}, \emph{110}(4), 454--466. \url{https://doi.org/10.1111/j.1548-1433.2008.00078.x}

\leavevmode\vadjust pre{\hypertarget{ref-Sanford2006}{}}%
Sanford, A. J., Sanford, A. J., Molle, J., \& Emmott, C. (2006). Shallow processing and attention capture in written and spoken discourse. \emph{Discourse Processes}, \emph{42}(2), 109--130.

\leavevmode\vadjust pre{\hypertarget{ref-Schlueter2014}{}}%
Schlueter, A., Lemke, U., Kollmeier, B., \& Holube, I. (2014). {Intelligibility of time-compressed speech: The effect of uniform versus non-uniform time-compression algorithms}. \emph{The Journal of the Acoustical Society of America}, \emph{135}(3), 1541--1555. \url{https://doi.org/10.1121/1.4863654}

\leavevmode\vadjust pre{\hypertarget{ref-Schneider2001}{}}%
Schneider, B. A., \& Pichora-Fuller, M. K. (2001). Age-related changes in temporal processing: Implications for listening comprehension. \emph{Seminars in Hearing}, \emph{22}(3), 227--239.

\leavevmode\vadjust pre{\hypertarget{ref-Scholman2020}{}}%
Scholman, M. C., Demberg, V., \& Sanders, T. J. (2020). Individual differences in expecting coherence relations: Exploring the variability in sensitivity to contextual signals in discourse. \emph{Discourse Processes}, \emph{57}(10), 844--861.

\leavevmode\vadjust pre{\hypertarget{ref-Schwarz1978}{}}%
Schwarz, G. (1978). Estimating the dimension of a model. \emph{The Annals of Statistics}, 461--464.

\leavevmode\vadjust pre{\hypertarget{ref-Seow2022}{}}%
Seow, T. X. F., \& Hauser, T. U. (2022). {Reliability of web-based affective auditory stimulus presentation}. \emph{Behavior Research Methods}, \emph{54}(1), 378--392. \url{https://doi.org/10.3758/s13428-021-01643-0}

\leavevmode\vadjust pre{\hypertarget{ref-Seth2013}{}}%
Seth, A. K. (2013). Interoceptive inference, emotion, and the embodied self. \emph{Trends in Cognitive Sciences}, \emph{17}(11), 565--573. \url{https://doi.org/10.1016/j.tics.2013.09.007}

\leavevmode\vadjust pre{\hypertarget{ref-Shannon1948}{}}%
Shannon, C. E. (1948). A Mathematical Theory of Communication. \emph{Bell System Technical Journal}, \emph{27}(4), 623--656. \url{https://doi.org/10.1002/j.1538-7305.1948.tb00917.x}

\leavevmode\vadjust pre{\hypertarget{ref-Shannon2004}{}}%
Shannon, R. V., Fu, Q.-J., \& Galvin Iii, J. (2004). {The number of spectral channels required for speech recognition depends on the difficulty of the listening situation}. \emph{Acta Oto-Laryngologica}, \emph{124}(0), 50--54. \url{https://doi.org/10.1080/03655230410017562}

\leavevmode\vadjust pre{\hypertarget{ref-Shannon1995}{}}%
Shannon, R. V., Zeng, F.-G., Kamath, V., Wygonski, J., \& Ekelid, M. (1995). Speech Recognition with Primarily Temporal Cues. \emph{Science}, \emph{270}(5234), 303--304. \url{https://doi.org/10.1126/science.270.5234.303}

\leavevmode\vadjust pre{\hypertarget{ref-Shannon1998}{}}%
Shannon, R. V., Zeng, V., \& Wygonski, J. (1998). Speech recognition with altered spectral distribution of envelope cues. \emph{The Journal of the Acoustical Society of America}, \emph{104}(4), 2467--2476. \url{https://doi.org/10.1121/1.423774}

\leavevmode\vadjust pre{\hypertarget{ref-Sharit2003}{}}%
Sharit, J., Czaja, S. J., Nair, S., \& Lee, C. C. (2003). {Effects of age, speech rate, and environmental support in using telephone voice menu systems}. \emph{Human Factors}, \emph{45}(2), 234--251. \url{https://doi.org/10.1518/hfes.45.2.234.27245}

\leavevmode\vadjust pre{\hypertarget{ref-Sheldon2008a}{}}%
Sheldon, S., Pichora-Fuller, M. K., \& Schneider, B. A. (2008a). Priming and sentence context support listening to noise-vocoded speech by younger and older adults. \emph{The Journal of the Acoustical Society of America}, \emph{123}(1), 489--499. \url{https://doi.org/10.1121/1.2783762}

\leavevmode\vadjust pre{\hypertarget{ref-Sheldon2008b}{}}%
Sheldon, S., Pichora-Fuller, M. K., \& Schneider, B. A. (2008b). Effect of age, presentation method, and learning on identification of noise-vocoded words. \emph{The Journal of the Acoustical Society of America}, \emph{123}(1), 476--488. \url{https://doi.org/10.1121/1.2805676}

\leavevmode\vadjust pre{\hypertarget{ref-Simantiraki2020}{}}%
Simantiraki, O., \& Cooke, M. (2020). {Exploring listeners' speech rate preferences}. \emph{INTERSPEECH}, 1346--1350. \url{https://doi.org/10.21437/Interspeech.2020-1832}

\leavevmode\vadjust pre{\hypertarget{ref-Slattery2013}{}}%
Slattery, T. J., Sturt, P., Christianson, K., Yoshida, M., \& Ferreira, F. (2013). Lingering misinterpretations of garden path sentences arise from competing syntactic representations. \emph{Journal of Memory and Language}, \emph{69}(2), 104--120.

\leavevmode\vadjust pre{\hypertarget{ref-Smith2008}{}}%
Smith, N. J., \& Levy, R. (2008). Optimal processing times in reading: A formal model and empirical investigation. \emph{Proceedings of the Annual Meeting of the Cognitive Science Society}, \emph{30}.

\leavevmode\vadjust pre{\hypertarget{ref-Smith2011}{}}%
Smith, N., \& Levy, R. (2011). Cloze but no cigar: The complex relationship between cloze, corpus, and subjective probabilities in language processing. \emph{Proceedings of the Annual Meeting of the Cognitive Science Society}, \emph{33}.

\leavevmode\vadjust pre{\hypertarget{ref-Sohoglu2012}{}}%
Sohoglu, E., Peelle, J. E., Carlyon, R. P., \& Davis, M. H. (2012). {Predictive top-down integration of prior knowledge during speech perception}. \emph{Journal of Neuroscience}, \emph{32}(25), 8443--8453. \url{https://doi.org/10.1523/JNEUROSCI.5069-11.2012}

\leavevmode\vadjust pre{\hypertarget{ref-Sommers1994}{}}%
Sommers, M. S., Nygaard, L. C., \& Pisoni, D. B. (1994). Stimulus variability and spoken word recognition. I. Effects of variability in speaking rate and overall amplitude. \emph{The Journal of the Acoustical Society of America}, \emph{96}(3), 1314--1324. \url{https://doi.org/10.1121/1.411453}

\leavevmode\vadjust pre{\hypertarget{ref-Sommers2020}{}}%
Sommers, M. S., Spehar, B., Tye-Murray, N., Myerson, J., \& Hale, S. (2020). Age differences in the effects of speaking rate on auditory, visual, and auditory-visual speech perception. \emph{Ear and Hearing}, \emph{41}(3), 549--560.

\leavevmode\vadjust pre{\hypertarget{ref-Stadler2012}{}}%
Stadler, W., Ott, D. V. M., Springer, A., Schubotz, R. I., Schütz-Bosbach, S., \& Prinz, W. (2012). Repetitive TMS suggests a role of the human dorsal premotor cortex in action prediction. \emph{Frontiers in Human Neuroscience}, \emph{6}. \url{https://doi.org/10.3389/fnhum.2012.00020}

\leavevmode\vadjust pre{\hypertarget{ref-Staub2015}{}}%
Staub, A. (2015). The Effect of Lexical Predictability on Eye Movements in Reading: Critical Review and Theoretical Interpretation. \emph{Language and Linguistics Compass}, \emph{9}(8), 311--327. \url{https://doi.org/10.1111/lnc3.12151}

\leavevmode\vadjust pre{\hypertarget{ref-Staub2011}{}}%
Staub, A. (2011). {The effect of lexical predictability on distributions of eye fixation durations}. \emph{Psychonomic Bulletin and Review}, \emph{18}(2), 371--376. \url{https://doi.org/10.3758/s13423-010-0046-9}

\leavevmode\vadjust pre{\hypertarget{ref-Staub2015a}{}}%
Staub, A., Grant, M., Astheimer, L., \& Cohen, A. (2015). {The influence of cloze probability and item constraint on cloze task response time}. \emph{Journal of Memory and Language}, \emph{82}, 1--17. \url{https://doi.org/10.1016/j.jml.2015.02.004}

\leavevmode\vadjust pre{\hypertarget{ref-Stilp2020}{}}%
Stilp, C. (2020). {Acoustic context effects in speech perception}. \emph{Wiley Interdisciplinary Reviews: Cognitive Science}, \emph{11}(1), 1--18. \url{https://doi.org/10.1002/wcs.1517}

\leavevmode\vadjust pre{\hypertarget{ref-Strauss2013}{}}%
Strauß, A., Kotz, S. A., \& Obleser, J. (2013). Narrowed Expectancies under Degraded Speech: Revisiting the N400. \emph{Journal of Cognitive Neuroscience}, \emph{25}(8), 1383--1395. \url{https://doi.org/10.1162/jocn_a_00389}

\leavevmode\vadjust pre{\hypertarget{ref-Sturt2004}{}}%
Sturt, P., Sanford, A. J., Stewart, A., \& Dawydiak, E. (2004). Linguistic focus and good-enough representations: An application of the change-detection paradigm. \emph{Psychonomic Bulletin \& Review}, \emph{11}(5), 882--888.

\leavevmode\vadjust pre{\hypertarget{ref-Sutton1995}{}}%
Sutton, B., King, J., Hux, K., \& Beukelman, D. (1995). Younger and older adults' rate performance when listening to synthetic speech. \emph{Augmentative and Alternative Communication}, \emph{11}(3), 147--153.

\leavevmode\vadjust pre{\hypertarget{ref-Taleb2020}{}}%
Taleb, N. (2020). \emph{Assessing the intelligibility and acoustic changes of time-processed speech} {[}Masters thesis, Case Western Reserve University; OhioLINK Electronic Theses; Dissertations Center{]}. \url{http://rave.ohiolink.edu/etdc/view?acc_num=case1586637814204979}

\leavevmode\vadjust pre{\hypertarget{ref-Taylor1953}{}}%
Taylor, W. L. (1953). {``Cloze procedure''}: A new tool for measuring readability. \emph{Journalism Quarterly}, \emph{30}(4), 415--433.

\leavevmode\vadjust pre{\hypertarget{ref-Thornton2007}{}}%
Thornton, A. R. D., Harmer, M., \& Lavoie, B. A. (2007). {Selective attention increases the temporal precision of the auditory N100 event-related potential}. \emph{Hearing Research}, \emph{230}(1-2), 73--79. \url{https://doi.org/10.1016/j.heares.2007.04.004}

\leavevmode\vadjust pre{\hypertarget{ref-Toth2020}{}}%
Tóth, B., Honbolygó, F., Szalárdy, O., Orosz, G., Farkas, D., \& Winkler, I. (2020). {The effects of speech processing units on auditory stream segregation and selective attention in a multi-talker (cocktail party) situation}. \emph{Cortex}, \emph{130}, 387--400. \url{https://doi.org/10.1016/j.cortex.2020.06.007}

\leavevmode\vadjust pre{\hypertarget{ref-Tuthill2018}{}}%
Tuthill, J. C., \& Azim, E. (2018). Proprioception. \emph{Current Biology}, \emph{28}(5), R194--R203.

\leavevmode\vadjust pre{\hypertarget{ref-Vaden2013}{}}%
Vaden, K. I., Kuchinsky, S. E., Cute, S. L., Ahlstrom, J. B., Dubno, J. R., \& Eckert, M. A. (2013). {The cingulo-opercular network provides word-recognition benefit}. \emph{Journal of Neuroscience}, \emph{33}(48), 18979--18986. \url{https://doi.org/10.1523/JNEUROSCI.1417-13.2013}

\leavevmode\vadjust pre{\hypertarget{ref-Vagharchakian2012}{}}%
Vagharchakian, L., Dehaene-Lambertz, G., Pallier, C., \& Dehaene, S. (2012). {A temporal bottleneck in the language comprehension network}. \emph{Journal of Neuroscience}, \emph{32}(26), 9089--9102. \url{https://doi.org/10.1523/JNEUROSCI.5685-11.2012}

\leavevmode\vadjust pre{\hypertarget{ref-vanOs2021}{}}%
van Os, M., Kray, J., \& Demberg, V. (2021). {Recognition of minipairs in (un)predictive sentence contexts in two types of noise}. \emph{Proceedings of the Annual Meeting of the Cognitive Science Society}, \emph{43}(43), 2943--2949.

\leavevmode\vadjust pre{\hypertarget{ref-VanPetten2012}{}}%
Van Petten, C., \& Luka, B. J. (2012). {Prediction during language comprehension: Benefits, costs, and ERP components}. \emph{International Journal of Psychophysiology}, \emph{83}(2), 176--190. \url{https://doi.org/10.1016/j.ijpsycho.2011.09.015}

\leavevmode\vadjust pre{\hypertarget{ref-Vasishth2022}{}}%
Vasishth, S., Schad, D., Bürki, A., \& Kliegl, R. (2022). Hypothetical repeated sampling and the t-test. In \emph{Linear mixed models in linguistics and psychology: A comprehensive introduction (DRAFT)}.

\leavevmode\vadjust pre{\hypertarget{ref-Verhagen2018}{}}%
Verhagen, V., Mos, M., Backus, A., \& Schilperoord, J. (2018). Predictive language processing revealing usage-based variation. \emph{Language and Cognition}, \emph{10}(2), 329--373.

\leavevmode\vadjust pre{\hypertarget{ref-Verhelst1993}{}}%
Verhelst, W., \& Roelands, M. (1993). {Overlap-add technique based on waveform similarity (WSOLA) for high quality time-scale modification of speech}. \emph{IEEE International Conference on Acoustics, Speech and Signal Processing}, \emph{2}, 554--557. \url{https://doi.org/10.1109/icassp.1993.319366}

\leavevmode\vadjust pre{\hypertarget{ref-Warren1970}{}}%
Warren, R. M. (1970). Perceptual restoration of missing speech sounds. \emph{Science}, \emph{167}(3917), 392--393.

\leavevmode\vadjust pre{\hypertarget{ref-Welch1996}{}}%
Welch, N., \& Krantz, J. H. (1996). {The World-Wide Web as a medium for psychoacoustical demonstrations and experiments: Experience and results}. \emph{Behavior Research Methods, Instruments, and Computers}, \emph{28}(2), 192--196. \url{https://doi.org/10.3758/bf03204764}

\leavevmode\vadjust pre{\hypertarget{ref-Wild2012}{}}%
Wild, C. J., Yusuf, A., Wilson, D. E., Peelle, J. E., Davis, M. H., \& Johnsrude, I. S. (2012). {Effortful listening: The processing of degraded speech depends critically on attention}. \emph{Journal of Neuroscience}, \emph{32}(40), 14010--14021. \url{https://doi.org/10.1523/JNEUROSCI.1528-12.2012}

\leavevmode\vadjust pre{\hypertarget{ref-Wingfield2006}{}}%
Wingfield, A., McCoy, S. L., Peelle, J. E., Tun, P. A., \& Cox, C. L. (2006). Effects of Adult Aging and Hearing Loss on Comprehension of Rapid Speech Varying in Syntactic Complexity. \emph{Journal of the American Academy of Audiology}, \emph{17}(07), 487--497. \url{https://doi.org/10.3766/jaaa.17.7.4}

\leavevmode\vadjust pre{\hypertarget{ref-Wingfield1999}{}}%
Wingfield, A., Tun, P. A., Koh, C. K., \& Rosen, M. J. (1999). {Regaining lost time: Adult aging and the effect of time restoration on recall of time-compressed speech}. \emph{Psychology and Aging}, \emph{14}(3), 380--389. \url{https://doi.org/10.1037/0882-7974.14.3.380}

\leavevmode\vadjust pre{\hypertarget{ref-Winn2016}{}}%
Winn, M. (2016). Rapid release from listening effort resulting from semantic context, and effects of spectral degradation and cochlear implants. \emph{Trends in Hearing}, \emph{20}, 1--17. \url{https://doi.org/10.1177/2331216516669723}

\leavevmode\vadjust pre{\hypertarget{ref-Winn2021}{}}%
Winn, M. B., \& Teece, K. H. (2021). {Slower speaking rate reduces listening effort among listeners with cochlear implants}. \emph{Ear and Hearing}, \emph{42}(3), 584. \url{https://doi.org/10.1097/aud.0000000000000958}

\leavevmode\vadjust pre{\hypertarget{ref-Wlotko2012}{}}%
Wlotko, E. W., \& Federmeier, K. D. (2012). Age-related changes in the impact of contextual strength on multiple aspects of sentence comprehension. \emph{Psychophysiology}, \emph{49}(6), 770--785. \url{https://doi.org/10.1111/j.1469-8986.2012.01366.x}

\leavevmode\vadjust pre{\hypertarget{ref-Wlotko2015}{}}%
Wlotko, E. W., \& Federmeier, K. D. (2015). {Time for prediction? The effect of presentation rate on predictive sentence comprehension during word-by-word reading}. \emph{Cortex}, \emph{68}, 20--32. \url{https://doi.org/10.1016/j.cortex.2015.03.014}

\leavevmode\vadjust pre{\hypertarget{ref-Woods2017}{}}%
Woods, K. J. P., Siegel, M. H., Traer, J., \& McDermott, J. H. (2017). {Headphone screening to facilitate web-based auditory experiments}. \emph{Attention, Perception, and Psychophysics}, \emph{79}(7), 2064--2072. \url{https://doi.org/10.3758/s13414-017-1361-2}

\leavevmode\vadjust pre{\hypertarget{ref-Wostmann2016}{}}%
Wöstmann, M., \& Obleser, J. (2016). Acoustic detail but not predictability of task-irrelevant speech disrupts working memory. \emph{Frontiers in Human Neuroscience}, \emph{10}, 538.

\leavevmode\vadjust pre{\hypertarget{ref-Xiang2015}{}}%
Xiang, M., \& Kuperberg, G. (2015). {Reversing expectations during discourse comprehension}. \emph{Language, Cognition and Neuroscience}, \emph{30}(6), 648--672. \url{https://doi.org/10.1080/23273798.2014.995679}

\end{CSLReferences}

%%%%% REFERENCES


\end{document}
